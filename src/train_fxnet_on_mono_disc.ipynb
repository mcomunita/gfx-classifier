{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import dataset.dataset as dataset\n",
    "import datasplit.datasplit as datasplit\n",
    "import model.models as models\n",
    "import trainer.trainer as trainer\n",
    "import utils.utils as utils\n",
    "\n",
    "torch.cuda.device_count()\n",
    "cuda0 = torch.device('cuda:0')\n",
    "cuda1 = torch.device('cuda:1')\n",
    "cuda2 = torch.device('cuda:2')\n",
    "cuda3 = torch.device('cuda:3')\n",
    "device = torch.device(cuda0 if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "source": [
    "# INIT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "# dataset\n",
    "root = '/Volumes/Macintosh HD/DATASETS/GUITAR-FX/Mono_Discrete'\n",
    "excl_folders = ['MT2'] # effects to exclude from the dataset\n",
    "spectra_folder= 'mel_22050_1024_512' # folder containing features\n",
    "proc_settings_csv = 'proc_settings.csv'\n",
    "max_num_settings=3 # maximum number of controls across dataset (e.g. [level, gain, tone] = 3)\n",
    "\n",
    "dataset = dataset.FxDataset(root=root,\n",
    "                            excl_folders=excl_folders, \n",
    "                            spectra_folder=spectra_folder, \n",
    "                            processed_settings_csv=proc_settings_csv,\n",
    "                            max_num_settings=max_num_settings,\n",
    "                            transform=transform)\n",
    "# initialise data structures\n",
    "dataset.init_dataset()\n",
    "# generate mel features - necessary only the first time\n",
    "# dataset.generate_mel()\n",
    "\n",
    "# split\n",
    "# set test_train_split=0.0 and val_train_split=0.0 to test pre-trained model\n",
    "split = datasplit.DataSplit(dataset, test_train_split=0.8, val_train_split=0.1, shuffle=True)\n",
    "\n",
    "# loaders\n",
    "train_loader, val_loader, test_loader = split.get_split(batch_size=100)\n",
    "\n",
    "print('dataset size: ', len(dataset))\n",
    "print('train set size: ', len(split.train_sampler))\n",
    "print('val set size: ', len(split.val_sampler))\n",
    "print('test set size: ', len(split.test_sampler))\n",
    "dataset.fx_to_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN FxNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "fxnet = models.FxNet(n_classes=dataset.num_fx).to(device)\n",
    "# optimizer\n",
    "optimizer_fxnet = optim.Adam(fxnet.parameters(), lr=0.001)\n",
    "# loss function\n",
    "loss_func_fxnet = nn.CrossEntropyLoss()\n",
    "\n",
    "print(fxnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE\n",
    "models_folder = '../../saved/models'\n",
    "model_name = '20201027_fxnet_mono_disc_best'\n",
    "results_folder = '../../saved/results'\n",
    "results_subfolder = '20201027_fxnet_mono_disc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 0\t[5000/88956 (6%)]\tTotal Loss: 20.1745\tAvg Loss: 0.0040\n",
      "Train Epoch: 0\t[10000/88956 (11%)]\tTotal Loss: 39.5251\tAvg Loss: 0.0040\n",
      "Train Epoch: 0\t[15000/88956 (17%)]\tTotal Loss: 58.8135\tAvg Loss: 0.0039\n",
      "Train Epoch: 0\t[20000/88956 (22%)]\tTotal Loss: 78.1765\tAvg Loss: 0.0039\n",
      "Train Epoch: 0\t[25000/88956 (28%)]\tTotal Loss: 96.5571\tAvg Loss: 0.0039\n",
      "Train Epoch: 0\t[30000/88956 (34%)]\tTotal Loss: 114.4308\tAvg Loss: 0.0038\n",
      "Train Epoch: 0\t[35000/88956 (39%)]\tTotal Loss: 132.5372\tAvg Loss: 0.0038\n",
      "Train Epoch: 0\t[40000/88956 (45%)]\tTotal Loss: 150.8651\tAvg Loss: 0.0038\n",
      "Train Epoch: 0\t[45000/88956 (51%)]\tTotal Loss: 169.2256\tAvg Loss: 0.0038\n",
      "Train Epoch: 0\t[50000/88956 (56%)]\tTotal Loss: 186.2961\tAvg Loss: 0.0037\n",
      "Train Epoch: 0\t[55000/88956 (62%)]\tTotal Loss: 203.1346\tAvg Loss: 0.0037\n",
      "Train Epoch: 0\t[60000/88956 (67%)]\tTotal Loss: 219.7104\tAvg Loss: 0.0037\n",
      "Train Epoch: 0\t[65000/88956 (73%)]\tTotal Loss: 236.8891\tAvg Loss: 0.0036\n",
      "Train Epoch: 0\t[70000/88956 (79%)]\tTotal Loss: 253.6727\tAvg Loss: 0.0036\n",
      "Train Epoch: 0\t[75000/88956 (84%)]\tTotal Loss: 269.8672\tAvg Loss: 0.0036\n",
      "Train Epoch: 0\t[80000/88956 (90%)]\tTotal Loss: 285.9464\tAvg Loss: 0.0036\n",
      "Train Epoch: 0\t[85000/88956 (96%)]\tTotal Loss: 303.2450\tAvg Loss: 0.0036\n",
      "====> Epoch: 0\tTotal Loss: 316.7145\t Avg Loss: 0.0036\tCorrect: 73278/88956\tPercentage Correct: 82.38\n",
      "====> Val Loss: 40.8011\t Avg Loss: 0.0041\tCorrect: 7898/9885\tPercentage Correct: 79.90\n",
      "====> Test Loss: 102.0441\t Avg Loss: 0.0041\tCorrect: 19736/24711\tPercentage Correct: 79.87\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 1\t[5000/88956 (6%)]\tTotal Loss: 15.2044\tAvg Loss: 0.0030\n",
      "Train Epoch: 1\t[10000/88956 (11%)]\tTotal Loss: 29.2475\tAvg Loss: 0.0029\n",
      "Train Epoch: 1\t[15000/88956 (17%)]\tTotal Loss: 44.1815\tAvg Loss: 0.0029\n",
      "Train Epoch: 1\t[20000/88956 (22%)]\tTotal Loss: 59.4600\tAvg Loss: 0.0030\n",
      "Train Epoch: 1\t[25000/88956 (28%)]\tTotal Loss: 75.6264\tAvg Loss: 0.0030\n",
      "Train Epoch: 1\t[30000/88956 (34%)]\tTotal Loss: 90.7611\tAvg Loss: 0.0030\n",
      "Train Epoch: 1\t[35000/88956 (39%)]\tTotal Loss: 105.6783\tAvg Loss: 0.0030\n",
      "Train Epoch: 1\t[40000/88956 (45%)]\tTotal Loss: 120.1978\tAvg Loss: 0.0030\n",
      "Train Epoch: 1\t[45000/88956 (51%)]\tTotal Loss: 134.4802\tAvg Loss: 0.0030\n",
      "Train Epoch: 1\t[50000/88956 (56%)]\tTotal Loss: 148.7051\tAvg Loss: 0.0030\n",
      "Train Epoch: 1\t[55000/88956 (62%)]\tTotal Loss: 162.9887\tAvg Loss: 0.0030\n",
      "Train Epoch: 1\t[60000/88956 (67%)]\tTotal Loss: 177.6174\tAvg Loss: 0.0030\n",
      "Train Epoch: 1\t[65000/88956 (73%)]\tTotal Loss: 191.8943\tAvg Loss: 0.0030\n",
      "Train Epoch: 1\t[70000/88956 (79%)]\tTotal Loss: 206.3761\tAvg Loss: 0.0029\n",
      "Train Epoch: 1\t[75000/88956 (84%)]\tTotal Loss: 221.0124\tAvg Loss: 0.0029\n",
      "Train Epoch: 1\t[80000/88956 (90%)]\tTotal Loss: 234.9830\tAvg Loss: 0.0029\n",
      "Train Epoch: 1\t[85000/88956 (96%)]\tTotal Loss: 247.8121\tAvg Loss: 0.0029\n",
      "====> Epoch: 1\tTotal Loss: 258.5508\t Avg Loss: 0.0029\tCorrect: 75034/88956\tPercentage Correct: 84.35\n",
      "====> Val Loss: 44.0614\t Avg Loss: 0.0045\tCorrect: 7782/9885\tPercentage Correct: 78.73\n",
      "====> Test Loss: 104.1407\t Avg Loss: 0.0042\tCorrect: 19768/24711\tPercentage Correct: 80.00\n",
      "Train Epoch: 2\t[5000/88956 (6%)]\tTotal Loss: 12.7438\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[10000/88956 (11%)]\tTotal Loss: 25.5131\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[15000/88956 (17%)]\tTotal Loss: 38.6654\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[20000/88956 (22%)]\tTotal Loss: 52.1391\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[25000/88956 (28%)]\tTotal Loss: 65.3239\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[30000/88956 (34%)]\tTotal Loss: 78.3624\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[35000/88956 (39%)]\tTotal Loss: 91.3966\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[40000/88956 (45%)]\tTotal Loss: 104.7810\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[45000/88956 (51%)]\tTotal Loss: 117.5231\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[50000/88956 (56%)]\tTotal Loss: 130.5670\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[55000/88956 (62%)]\tTotal Loss: 143.6854\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[60000/88956 (67%)]\tTotal Loss: 156.1707\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[65000/88956 (73%)]\tTotal Loss: 169.6093\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[70000/88956 (79%)]\tTotal Loss: 183.1917\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[75000/88956 (84%)]\tTotal Loss: 197.1751\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[80000/88956 (90%)]\tTotal Loss: 210.9120\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[85000/88956 (96%)]\tTotal Loss: 224.0690\tAvg Loss: 0.0026\n",
      "====> Epoch: 2\tTotal Loss: 234.3339\t Avg Loss: 0.0026\tCorrect: 75806/88956\tPercentage Correct: 85.22\n",
      "====> Val Loss: 27.0063\t Avg Loss: 0.0027\tCorrect: 8408/9885\tPercentage Correct: 85.06\n",
      "====> Test Loss: 65.8260\t Avg Loss: 0.0027\tCorrect: 21059/24711\tPercentage Correct: 85.22\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 3\t[5000/88956 (6%)]\tTotal Loss: 11.9629\tAvg Loss: 0.0024\n",
      "Train Epoch: 3\t[10000/88956 (11%)]\tTotal Loss: 24.0388\tAvg Loss: 0.0024\n",
      "Train Epoch: 3\t[15000/88956 (17%)]\tTotal Loss: 36.1480\tAvg Loss: 0.0024\n",
      "Train Epoch: 3\t[20000/88956 (22%)]\tTotal Loss: 47.8045\tAvg Loss: 0.0024\n",
      "Train Epoch: 3\t[25000/88956 (28%)]\tTotal Loss: 60.0484\tAvg Loss: 0.0024\n",
      "Train Epoch: 3\t[30000/88956 (34%)]\tTotal Loss: 72.0814\tAvg Loss: 0.0024\n",
      "Train Epoch: 3\t[35000/88956 (39%)]\tTotal Loss: 84.0804\tAvg Loss: 0.0024\n",
      "Train Epoch: 3\t[40000/88956 (45%)]\tTotal Loss: 96.1589\tAvg Loss: 0.0024\n",
      "Train Epoch: 3\t[45000/88956 (51%)]\tTotal Loss: 108.6129\tAvg Loss: 0.0024\n",
      "Train Epoch: 3\t[50000/88956 (56%)]\tTotal Loss: 120.6863\tAvg Loss: 0.0024\n",
      "Train Epoch: 3\t[55000/88956 (62%)]\tTotal Loss: 132.9566\tAvg Loss: 0.0024\n",
      "Train Epoch: 3\t[60000/88956 (67%)]\tTotal Loss: 145.2578\tAvg Loss: 0.0024\n",
      "Train Epoch: 3\t[65000/88956 (73%)]\tTotal Loss: 156.4041\tAvg Loss: 0.0024\n",
      "Train Epoch: 3\t[70000/88956 (79%)]\tTotal Loss: 169.0186\tAvg Loss: 0.0024\n",
      "Train Epoch: 3\t[75000/88956 (84%)]\tTotal Loss: 181.0541\tAvg Loss: 0.0024\n",
      "Train Epoch: 3\t[80000/88956 (90%)]\tTotal Loss: 192.9427\tAvg Loss: 0.0024\n",
      "Train Epoch: 3\t[85000/88956 (96%)]\tTotal Loss: 205.7989\tAvg Loss: 0.0024\n",
      "====> Epoch: 3\tTotal Loss: 215.5810\t Avg Loss: 0.0024\tCorrect: 76598/88956\tPercentage Correct: 86.11\n",
      "====> Val Loss: 37.4302\t Avg Loss: 0.0038\tCorrect: 8001/9885\tPercentage Correct: 80.94\n",
      "====> Test Loss: 91.5756\t Avg Loss: 0.0037\tCorrect: 19982/24711\tPercentage Correct: 80.86\n",
      "Train Epoch: 4\t[5000/88956 (6%)]\tTotal Loss: 12.2677\tAvg Loss: 0.0025\n",
      "Train Epoch: 4\t[10000/88956 (11%)]\tTotal Loss: 23.6250\tAvg Loss: 0.0024\n",
      "Train Epoch: 4\t[15000/88956 (17%)]\tTotal Loss: 34.8205\tAvg Loss: 0.0023\n",
      "Train Epoch: 4\t[20000/88956 (22%)]\tTotal Loss: 46.2949\tAvg Loss: 0.0023\n",
      "Train Epoch: 4\t[25000/88956 (28%)]\tTotal Loss: 58.0386\tAvg Loss: 0.0023\n",
      "Train Epoch: 4\t[30000/88956 (34%)]\tTotal Loss: 69.2300\tAvg Loss: 0.0023\n",
      "Train Epoch: 4\t[35000/88956 (39%)]\tTotal Loss: 80.5676\tAvg Loss: 0.0023\n",
      "Train Epoch: 4\t[40000/88956 (45%)]\tTotal Loss: 91.6540\tAvg Loss: 0.0023\n",
      "Train Epoch: 4\t[45000/88956 (51%)]\tTotal Loss: 103.3388\tAvg Loss: 0.0023\n",
      "Train Epoch: 4\t[50000/88956 (56%)]\tTotal Loss: 114.5948\tAvg Loss: 0.0023\n",
      "Train Epoch: 4\t[55000/88956 (62%)]\tTotal Loss: 126.0601\tAvg Loss: 0.0023\n",
      "Train Epoch: 4\t[60000/88956 (67%)]\tTotal Loss: 137.0028\tAvg Loss: 0.0023\n",
      "Train Epoch: 4\t[65000/88956 (73%)]\tTotal Loss: 147.9094\tAvg Loss: 0.0023\n",
      "Train Epoch: 4\t[70000/88956 (79%)]\tTotal Loss: 160.1654\tAvg Loss: 0.0023\n",
      "Train Epoch: 4\t[75000/88956 (84%)]\tTotal Loss: 171.7938\tAvg Loss: 0.0023\n",
      "Train Epoch: 4\t[80000/88956 (90%)]\tTotal Loss: 184.0178\tAvg Loss: 0.0023\n",
      "Train Epoch: 4\t[85000/88956 (96%)]\tTotal Loss: 195.6919\tAvg Loss: 0.0023\n",
      "====> Epoch: 4\tTotal Loss: 204.6200\t Avg Loss: 0.0023\tCorrect: 76877/88956\tPercentage Correct: 86.42\n",
      "====> Val Loss: 76.8350\t Avg Loss: 0.0078\tCorrect: 7133/9885\tPercentage Correct: 72.16\n",
      "====> Test Loss: 207.3856\t Avg Loss: 0.0084\tCorrect: 17572/24711\tPercentage Correct: 71.11\n",
      "Train Epoch: 5\t[5000/88956 (6%)]\tTotal Loss: 11.3137\tAvg Loss: 0.0023\n",
      "Train Epoch: 5\t[10000/88956 (11%)]\tTotal Loss: 22.3484\tAvg Loss: 0.0022\n",
      "Train Epoch: 5\t[15000/88956 (17%)]\tTotal Loss: 33.1093\tAvg Loss: 0.0022\n",
      "Train Epoch: 5\t[20000/88956 (22%)]\tTotal Loss: 43.7364\tAvg Loss: 0.0022\n",
      "Train Epoch: 5\t[25000/88956 (28%)]\tTotal Loss: 54.3295\tAvg Loss: 0.0022\n",
      "Train Epoch: 5\t[30000/88956 (34%)]\tTotal Loss: 66.2360\tAvg Loss: 0.0022\n",
      "Train Epoch: 5\t[35000/88956 (39%)]\tTotal Loss: 77.3314\tAvg Loss: 0.0022\n",
      "Train Epoch: 5\t[40000/88956 (45%)]\tTotal Loss: 88.4528\tAvg Loss: 0.0022\n",
      "Train Epoch: 5\t[45000/88956 (51%)]\tTotal Loss: 99.9018\tAvg Loss: 0.0022\n",
      "Train Epoch: 5\t[50000/88956 (56%)]\tTotal Loss: 110.8901\tAvg Loss: 0.0022\n",
      "Train Epoch: 5\t[55000/88956 (62%)]\tTotal Loss: 122.3305\tAvg Loss: 0.0022\n",
      "Train Epoch: 5\t[60000/88956 (67%)]\tTotal Loss: 134.4147\tAvg Loss: 0.0022\n",
      "Train Epoch: 5\t[65000/88956 (73%)]\tTotal Loss: 145.7011\tAvg Loss: 0.0022\n",
      "Train Epoch: 5\t[70000/88956 (79%)]\tTotal Loss: 157.3588\tAvg Loss: 0.0022\n",
      "Train Epoch: 5\t[75000/88956 (84%)]\tTotal Loss: 169.0524\tAvg Loss: 0.0023\n",
      "Train Epoch: 5\t[80000/88956 (90%)]\tTotal Loss: 180.3054\tAvg Loss: 0.0023\n",
      "Train Epoch: 5\t[85000/88956 (96%)]\tTotal Loss: 192.1507\tAvg Loss: 0.0023\n",
      "====> Epoch: 5\tTotal Loss: 201.2819\t Avg Loss: 0.0023\tCorrect: 76898/88956\tPercentage Correct: 86.44\n",
      "====> Val Loss: 43.9467\t Avg Loss: 0.0044\tCorrect: 7803/9885\tPercentage Correct: 78.94\n",
      "====> Test Loss: 108.7246\t Avg Loss: 0.0044\tCorrect: 19592/24711\tPercentage Correct: 79.28\n",
      "Train Epoch: 6\t[5000/88956 (6%)]\tTotal Loss: 10.5315\tAvg Loss: 0.0021\n",
      "Train Epoch: 6\t[10000/88956 (11%)]\tTotal Loss: 21.1012\tAvg Loss: 0.0021\n",
      "Train Epoch: 6\t[15000/88956 (17%)]\tTotal Loss: 31.4290\tAvg Loss: 0.0021\n",
      "Train Epoch: 6\t[20000/88956 (22%)]\tTotal Loss: 41.4923\tAvg Loss: 0.0021\n",
      "Train Epoch: 6\t[25000/88956 (28%)]\tTotal Loss: 52.2292\tAvg Loss: 0.0021\n",
      "Train Epoch: 6\t[30000/88956 (34%)]\tTotal Loss: 62.8406\tAvg Loss: 0.0021\n",
      "Train Epoch: 6\t[35000/88956 (39%)]\tTotal Loss: 74.0854\tAvg Loss: 0.0021\n",
      "Train Epoch: 6\t[40000/88956 (45%)]\tTotal Loss: 84.5277\tAvg Loss: 0.0021\n",
      "Train Epoch: 6\t[45000/88956 (51%)]\tTotal Loss: 95.6365\tAvg Loss: 0.0021\n",
      "Train Epoch: 6\t[50000/88956 (56%)]\tTotal Loss: 107.1890\tAvg Loss: 0.0021\n",
      "Train Epoch: 6\t[55000/88956 (62%)]\tTotal Loss: 117.7625\tAvg Loss: 0.0021\n",
      "Train Epoch: 6\t[60000/88956 (67%)]\tTotal Loss: 128.8041\tAvg Loss: 0.0021\n",
      "Train Epoch: 6\t[65000/88956 (73%)]\tTotal Loss: 140.0760\tAvg Loss: 0.0022\n",
      "Train Epoch: 6\t[70000/88956 (79%)]\tTotal Loss: 150.9001\tAvg Loss: 0.0022\n",
      "Train Epoch: 6\t[75000/88956 (84%)]\tTotal Loss: 162.9379\tAvg Loss: 0.0022\n",
      "Train Epoch: 6\t[80000/88956 (90%)]\tTotal Loss: 173.2999\tAvg Loss: 0.0022\n",
      "Train Epoch: 6\t[85000/88956 (96%)]\tTotal Loss: 184.4868\tAvg Loss: 0.0022\n",
      "====> Epoch: 6\tTotal Loss: 192.9269\t Avg Loss: 0.0022\tCorrect: 77144/88956\tPercentage Correct: 86.72\n",
      "====> Val Loss: 27.5753\t Avg Loss: 0.0028\tCorrect: 8378/9885\tPercentage Correct: 84.75\n",
      "====> Test Loss: 67.1676\t Avg Loss: 0.0027\tCorrect: 21046/24711\tPercentage Correct: 85.17\n",
      "Train Epoch: 7\t[5000/88956 (6%)]\tTotal Loss: 10.3799\tAvg Loss: 0.0021\n",
      "Train Epoch: 7\t[10000/88956 (11%)]\tTotal Loss: 20.3712\tAvg Loss: 0.0020\n",
      "Train Epoch: 7\t[15000/88956 (17%)]\tTotal Loss: 30.7401\tAvg Loss: 0.0020\n",
      "Train Epoch: 7\t[20000/88956 (22%)]\tTotal Loss: 40.6952\tAvg Loss: 0.0020\n",
      "Train Epoch: 7\t[25000/88956 (28%)]\tTotal Loss: 51.3203\tAvg Loss: 0.0021\n",
      "Train Epoch: 7\t[30000/88956 (34%)]\tTotal Loss: 61.4433\tAvg Loss: 0.0020\n",
      "Train Epoch: 7\t[35000/88956 (39%)]\tTotal Loss: 71.7626\tAvg Loss: 0.0021\n",
      "Train Epoch: 7\t[40000/88956 (45%)]\tTotal Loss: 82.6400\tAvg Loss: 0.0021\n",
      "Train Epoch: 7\t[45000/88956 (51%)]\tTotal Loss: 93.1849\tAvg Loss: 0.0021\n",
      "Train Epoch: 7\t[50000/88956 (56%)]\tTotal Loss: 103.5020\tAvg Loss: 0.0021\n",
      "Train Epoch: 7\t[55000/88956 (62%)]\tTotal Loss: 113.9731\tAvg Loss: 0.0021\n",
      "Train Epoch: 7\t[60000/88956 (67%)]\tTotal Loss: 124.7532\tAvg Loss: 0.0021\n",
      "Train Epoch: 7\t[65000/88956 (73%)]\tTotal Loss: 135.9896\tAvg Loss: 0.0021\n",
      "Train Epoch: 7\t[70000/88956 (79%)]\tTotal Loss: 147.4401\tAvg Loss: 0.0021\n",
      "Train Epoch: 7\t[75000/88956 (84%)]\tTotal Loss: 158.0873\tAvg Loss: 0.0021\n",
      "Train Epoch: 7\t[80000/88956 (90%)]\tTotal Loss: 168.8683\tAvg Loss: 0.0021\n",
      "Train Epoch: 7\t[85000/88956 (96%)]\tTotal Loss: 179.7149\tAvg Loss: 0.0021\n",
      "====> Epoch: 7\tTotal Loss: 187.7409\t Avg Loss: 0.0021\tCorrect: 77517/88956\tPercentage Correct: 87.14\n",
      "====> Val Loss: 36.1321\t Avg Loss: 0.0037\tCorrect: 8099/9885\tPercentage Correct: 81.93\n",
      "====> Test Loss: 90.8239\t Avg Loss: 0.0037\tCorrect: 20248/24711\tPercentage Correct: 81.94\n",
      "Train Epoch: 8\t[5000/88956 (6%)]\tTotal Loss: 10.8010\tAvg Loss: 0.0022\n",
      "Train Epoch: 8\t[10000/88956 (11%)]\tTotal Loss: 20.6645\tAvg Loss: 0.0021\n",
      "Train Epoch: 8\t[15000/88956 (17%)]\tTotal Loss: 30.5329\tAvg Loss: 0.0020\n",
      "Train Epoch: 8\t[20000/88956 (22%)]\tTotal Loss: 40.0969\tAvg Loss: 0.0020\n",
      "Train Epoch: 8\t[25000/88956 (28%)]\tTotal Loss: 49.8571\tAvg Loss: 0.0020\n",
      "Train Epoch: 8\t[30000/88956 (34%)]\tTotal Loss: 59.6437\tAvg Loss: 0.0020\n",
      "Train Epoch: 8\t[35000/88956 (39%)]\tTotal Loss: 69.5505\tAvg Loss: 0.0020\n",
      "Train Epoch: 8\t[40000/88956 (45%)]\tTotal Loss: 79.5109\tAvg Loss: 0.0020\n",
      "Train Epoch: 8\t[45000/88956 (51%)]\tTotal Loss: 90.2600\tAvg Loss: 0.0020\n",
      "Train Epoch: 8\t[50000/88956 (56%)]\tTotal Loss: 100.0939\tAvg Loss: 0.0020\n",
      "Train Epoch: 8\t[55000/88956 (62%)]\tTotal Loss: 110.9123\tAvg Loss: 0.0020\n",
      "Train Epoch: 8\t[60000/88956 (67%)]\tTotal Loss: 121.3741\tAvg Loss: 0.0020\n",
      "Train Epoch: 8\t[65000/88956 (73%)]\tTotal Loss: 131.5177\tAvg Loss: 0.0020\n",
      "Train Epoch: 8\t[70000/88956 (79%)]\tTotal Loss: 141.8029\tAvg Loss: 0.0020\n",
      "Train Epoch: 8\t[75000/88956 (84%)]\tTotal Loss: 152.0568\tAvg Loss: 0.0020\n",
      "Train Epoch: 8\t[80000/88956 (90%)]\tTotal Loss: 162.7047\tAvg Loss: 0.0020\n",
      "Train Epoch: 8\t[85000/88956 (96%)]\tTotal Loss: 173.0929\tAvg Loss: 0.0020\n",
      "====> Epoch: 8\tTotal Loss: 181.1735\t Avg Loss: 0.0020\tCorrect: 77699/88956\tPercentage Correct: 87.35\n",
      "====> Val Loss: 74.2636\t Avg Loss: 0.0075\tCorrect: 7192/9885\tPercentage Correct: 72.76\n",
      "====> Test Loss: 185.3196\t Avg Loss: 0.0075\tCorrect: 18077/24711\tPercentage Correct: 73.15\n",
      "Train Epoch: 9\t[5000/88956 (6%)]\tTotal Loss: 10.3508\tAvg Loss: 0.0021\n",
      "Train Epoch: 9\t[10000/88956 (11%)]\tTotal Loss: 20.5370\tAvg Loss: 0.0021\n",
      "Train Epoch: 9\t[15000/88956 (17%)]\tTotal Loss: 30.8539\tAvg Loss: 0.0021\n",
      "Train Epoch: 9\t[20000/88956 (22%)]\tTotal Loss: 41.0751\tAvg Loss: 0.0021\n",
      "Train Epoch: 9\t[25000/88956 (28%)]\tTotal Loss: 51.5981\tAvg Loss: 0.0021\n",
      "Train Epoch: 9\t[30000/88956 (34%)]\tTotal Loss: 61.8099\tAvg Loss: 0.0021\n",
      "Train Epoch: 9\t[35000/88956 (39%)]\tTotal Loss: 71.9774\tAvg Loss: 0.0021\n",
      "Train Epoch: 9\t[40000/88956 (45%)]\tTotal Loss: 82.4740\tAvg Loss: 0.0021\n",
      "Train Epoch: 9\t[45000/88956 (51%)]\tTotal Loss: 92.5668\tAvg Loss: 0.0021\n",
      "Train Epoch: 9\t[50000/88956 (56%)]\tTotal Loss: 102.8977\tAvg Loss: 0.0021\n",
      "Train Epoch: 9\t[55000/88956 (62%)]\tTotal Loss: 113.2230\tAvg Loss: 0.0021\n",
      "Train Epoch: 9\t[60000/88956 (67%)]\tTotal Loss: 123.1469\tAvg Loss: 0.0021\n",
      "Train Epoch: 9\t[65000/88956 (73%)]\tTotal Loss: 133.4311\tAvg Loss: 0.0021\n",
      "Train Epoch: 9\t[70000/88956 (79%)]\tTotal Loss: 143.7124\tAvg Loss: 0.0021\n",
      "Train Epoch: 9\t[75000/88956 (84%)]\tTotal Loss: 153.9072\tAvg Loss: 0.0021\n",
      "Train Epoch: 9\t[80000/88956 (90%)]\tTotal Loss: 163.9718\tAvg Loss: 0.0020\n",
      "Train Epoch: 9\t[85000/88956 (96%)]\tTotal Loss: 173.9331\tAvg Loss: 0.0020\n",
      "====> Epoch: 9\tTotal Loss: 181.9459\t Avg Loss: 0.0020\tCorrect: 77644/88956\tPercentage Correct: 87.28\n",
      "====> Val Loss: 22.2573\t Avg Loss: 0.0023\tCorrect: 8501/9885\tPercentage Correct: 86.00\n",
      "====> Test Loss: 55.1834\t Avg Loss: 0.0022\tCorrect: 21354/24711\tPercentage Correct: 86.41\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 10\t[5000/88956 (6%)]\tTotal Loss: 9.7718\tAvg Loss: 0.0020\n",
      "Train Epoch: 10\t[10000/88956 (11%)]\tTotal Loss: 19.7053\tAvg Loss: 0.0020\n",
      "Train Epoch: 10\t[15000/88956 (17%)]\tTotal Loss: 29.7066\tAvg Loss: 0.0020\n",
      "Train Epoch: 10\t[20000/88956 (22%)]\tTotal Loss: 38.8875\tAvg Loss: 0.0019\n",
      "Train Epoch: 10\t[25000/88956 (28%)]\tTotal Loss: 48.7950\tAvg Loss: 0.0020\n",
      "Train Epoch: 10\t[30000/88956 (34%)]\tTotal Loss: 58.9367\tAvg Loss: 0.0020\n",
      "Train Epoch: 10\t[35000/88956 (39%)]\tTotal Loss: 68.8334\tAvg Loss: 0.0020\n",
      "Train Epoch: 10\t[40000/88956 (45%)]\tTotal Loss: 78.7122\tAvg Loss: 0.0020\n",
      "Train Epoch: 10\t[45000/88956 (51%)]\tTotal Loss: 88.3721\tAvg Loss: 0.0020\n",
      "Train Epoch: 10\t[50000/88956 (56%)]\tTotal Loss: 98.2483\tAvg Loss: 0.0020\n",
      "Train Epoch: 10\t[55000/88956 (62%)]\tTotal Loss: 108.3067\tAvg Loss: 0.0020\n",
      "Train Epoch: 10\t[60000/88956 (67%)]\tTotal Loss: 118.8974\tAvg Loss: 0.0020\n",
      "Train Epoch: 10\t[65000/88956 (73%)]\tTotal Loss: 129.7435\tAvg Loss: 0.0020\n",
      "Train Epoch: 10\t[70000/88956 (79%)]\tTotal Loss: 140.2969\tAvg Loss: 0.0020\n",
      "Train Epoch: 10\t[75000/88956 (84%)]\tTotal Loss: 150.6648\tAvg Loss: 0.0020\n",
      "Train Epoch: 10\t[80000/88956 (90%)]\tTotal Loss: 160.5101\tAvg Loss: 0.0020\n",
      "Train Epoch: 10\t[85000/88956 (96%)]\tTotal Loss: 170.2575\tAvg Loss: 0.0020\n",
      "====> Epoch: 10\tTotal Loss: 177.9352\t Avg Loss: 0.0020\tCorrect: 77836/88956\tPercentage Correct: 87.50\n",
      "====> Val Loss: 97.3492\t Avg Loss: 0.0098\tCorrect: 7054/9885\tPercentage Correct: 71.36\n",
      "====> Test Loss: 244.6869\t Avg Loss: 0.0099\tCorrect: 17689/24711\tPercentage Correct: 71.58\n",
      "Train Epoch: 11\t[5000/88956 (6%)]\tTotal Loss: 9.6526\tAvg Loss: 0.0019\n",
      "Train Epoch: 11\t[10000/88956 (11%)]\tTotal Loss: 19.3602\tAvg Loss: 0.0019\n",
      "Train Epoch: 11\t[15000/88956 (17%)]\tTotal Loss: 28.7766\tAvg Loss: 0.0019\n",
      "Train Epoch: 11\t[20000/88956 (22%)]\tTotal Loss: 38.4189\tAvg Loss: 0.0019\n",
      "Train Epoch: 11\t[25000/88956 (28%)]\tTotal Loss: 48.6288\tAvg Loss: 0.0019\n",
      "Train Epoch: 11\t[30000/88956 (34%)]\tTotal Loss: 57.9980\tAvg Loss: 0.0019\n",
      "Train Epoch: 11\t[35000/88956 (39%)]\tTotal Loss: 67.8723\tAvg Loss: 0.0019\n",
      "Train Epoch: 11\t[40000/88956 (45%)]\tTotal Loss: 77.8949\tAvg Loss: 0.0019\n",
      "Train Epoch: 11\t[45000/88956 (51%)]\tTotal Loss: 87.3378\tAvg Loss: 0.0019\n",
      "Train Epoch: 11\t[50000/88956 (56%)]\tTotal Loss: 97.4465\tAvg Loss: 0.0019\n",
      "Train Epoch: 11\t[55000/88956 (62%)]\tTotal Loss: 107.3726\tAvg Loss: 0.0020\n",
      "Train Epoch: 11\t[60000/88956 (67%)]\tTotal Loss: 117.0113\tAvg Loss: 0.0020\n",
      "Train Epoch: 11\t[65000/88956 (73%)]\tTotal Loss: 126.4956\tAvg Loss: 0.0019\n",
      "Train Epoch: 11\t[70000/88956 (79%)]\tTotal Loss: 136.0687\tAvg Loss: 0.0019\n",
      "Train Epoch: 11\t[75000/88956 (84%)]\tTotal Loss: 145.9922\tAvg Loss: 0.0019\n",
      "Train Epoch: 11\t[80000/88956 (90%)]\tTotal Loss: 155.8254\tAvg Loss: 0.0019\n",
      "Train Epoch: 11\t[85000/88956 (96%)]\tTotal Loss: 165.3645\tAvg Loss: 0.0019\n",
      "====> Epoch: 11\tTotal Loss: 173.1023\t Avg Loss: 0.0019\tCorrect: 77874/88956\tPercentage Correct: 87.54\n",
      "====> Val Loss: 23.9926\t Avg Loss: 0.0024\tCorrect: 8473/9885\tPercentage Correct: 85.72\n",
      "====> Test Loss: 59.7124\t Avg Loss: 0.0024\tCorrect: 21267/24711\tPercentage Correct: 86.06\n",
      "Train Epoch: 12\t[5000/88956 (6%)]\tTotal Loss: 9.2353\tAvg Loss: 0.0018\n",
      "Train Epoch: 12\t[10000/88956 (11%)]\tTotal Loss: 18.8710\tAvg Loss: 0.0019\n",
      "Train Epoch: 12\t[15000/88956 (17%)]\tTotal Loss: 28.2926\tAvg Loss: 0.0019\n",
      "Train Epoch: 12\t[20000/88956 (22%)]\tTotal Loss: 37.7550\tAvg Loss: 0.0019\n",
      "Train Epoch: 12\t[25000/88956 (28%)]\tTotal Loss: 47.4745\tAvg Loss: 0.0019\n",
      "Train Epoch: 12\t[30000/88956 (34%)]\tTotal Loss: 57.4287\tAvg Loss: 0.0019\n",
      "Train Epoch: 12\t[35000/88956 (39%)]\tTotal Loss: 67.4095\tAvg Loss: 0.0019\n",
      "Train Epoch: 12\t[40000/88956 (45%)]\tTotal Loss: 77.3126\tAvg Loss: 0.0019\n",
      "Train Epoch: 12\t[45000/88956 (51%)]\tTotal Loss: 87.0082\tAvg Loss: 0.0019\n",
      "Train Epoch: 12\t[50000/88956 (56%)]\tTotal Loss: 97.1583\tAvg Loss: 0.0019\n",
      "Train Epoch: 12\t[55000/88956 (62%)]\tTotal Loss: 107.0814\tAvg Loss: 0.0019\n",
      "Train Epoch: 12\t[60000/88956 (67%)]\tTotal Loss: 116.6431\tAvg Loss: 0.0019\n",
      "Train Epoch: 12\t[65000/88956 (73%)]\tTotal Loss: 126.9148\tAvg Loss: 0.0020\n",
      "Train Epoch: 12\t[70000/88956 (79%)]\tTotal Loss: 137.0057\tAvg Loss: 0.0020\n",
      "Train Epoch: 12\t[75000/88956 (84%)]\tTotal Loss: 146.6143\tAvg Loss: 0.0020\n",
      "Train Epoch: 12\t[80000/88956 (90%)]\tTotal Loss: 156.1985\tAvg Loss: 0.0020\n",
      "Train Epoch: 12\t[85000/88956 (96%)]\tTotal Loss: 165.8598\tAvg Loss: 0.0020\n",
      "====> Epoch: 12\tTotal Loss: 173.7170\t Avg Loss: 0.0020\tCorrect: 78037/88956\tPercentage Correct: 87.73\n",
      "====> Val Loss: 125.2255\t Avg Loss: 0.0127\tCorrect: 6637/9885\tPercentage Correct: 67.14\n",
      "====> Test Loss: 323.9501\t Avg Loss: 0.0131\tCorrect: 16514/24711\tPercentage Correct: 66.83\n",
      "Train Epoch: 13\t[5000/88956 (6%)]\tTotal Loss: 9.9421\tAvg Loss: 0.0020\n",
      "Train Epoch: 13\t[10000/88956 (11%)]\tTotal Loss: 19.0477\tAvg Loss: 0.0019\n",
      "Train Epoch: 13\t[15000/88956 (17%)]\tTotal Loss: 28.6714\tAvg Loss: 0.0019\n",
      "Train Epoch: 13\t[20000/88956 (22%)]\tTotal Loss: 38.3990\tAvg Loss: 0.0019\n",
      "Train Epoch: 13\t[25000/88956 (28%)]\tTotal Loss: 47.7767\tAvg Loss: 0.0019\n",
      "Train Epoch: 13\t[30000/88956 (34%)]\tTotal Loss: 56.8667\tAvg Loss: 0.0019\n",
      "Train Epoch: 13\t[35000/88956 (39%)]\tTotal Loss: 66.4321\tAvg Loss: 0.0019\n",
      "Train Epoch: 13\t[40000/88956 (45%)]\tTotal Loss: 76.0162\tAvg Loss: 0.0019\n",
      "Train Epoch: 13\t[45000/88956 (51%)]\tTotal Loss: 86.1566\tAvg Loss: 0.0019\n",
      "Train Epoch: 13\t[50000/88956 (56%)]\tTotal Loss: 96.2255\tAvg Loss: 0.0019\n",
      "Train Epoch: 13\t[55000/88956 (62%)]\tTotal Loss: 105.8441\tAvg Loss: 0.0019\n",
      "Train Epoch: 13\t[60000/88956 (67%)]\tTotal Loss: 115.4019\tAvg Loss: 0.0019\n",
      "Train Epoch: 13\t[65000/88956 (73%)]\tTotal Loss: 125.0219\tAvg Loss: 0.0019\n",
      "Train Epoch: 13\t[70000/88956 (79%)]\tTotal Loss: 134.7427\tAvg Loss: 0.0019\n",
      "Train Epoch: 13\t[75000/88956 (84%)]\tTotal Loss: 144.4048\tAvg Loss: 0.0019\n",
      "Train Epoch: 13\t[80000/88956 (90%)]\tTotal Loss: 154.2168\tAvg Loss: 0.0019\n",
      "Train Epoch: 13\t[85000/88956 (96%)]\tTotal Loss: 164.1775\tAvg Loss: 0.0019\n",
      "====> Epoch: 13\tTotal Loss: 171.9600\t Avg Loss: 0.0019\tCorrect: 77863/88956\tPercentage Correct: 87.53\n",
      "====> Val Loss: 138.1380\t Avg Loss: 0.0140\tCorrect: 6580/9885\tPercentage Correct: 66.57\n",
      "====> Test Loss: 341.3945\t Avg Loss: 0.0138\tCorrect: 16624/24711\tPercentage Correct: 67.27\n",
      "Train Epoch: 14\t[5000/88956 (6%)]\tTotal Loss: 9.5779\tAvg Loss: 0.0019\n",
      "Train Epoch: 14\t[10000/88956 (11%)]\tTotal Loss: 18.4379\tAvg Loss: 0.0018\n",
      "Train Epoch: 14\t[15000/88956 (17%)]\tTotal Loss: 28.0021\tAvg Loss: 0.0019\n",
      "Train Epoch: 14\t[20000/88956 (22%)]\tTotal Loss: 37.4739\tAvg Loss: 0.0019\n",
      "Train Epoch: 14\t[25000/88956 (28%)]\tTotal Loss: 46.9584\tAvg Loss: 0.0019\n",
      "Train Epoch: 14\t[30000/88956 (34%)]\tTotal Loss: 56.9965\tAvg Loss: 0.0019\n",
      "Train Epoch: 14\t[35000/88956 (39%)]\tTotal Loss: 66.7060\tAvg Loss: 0.0019\n",
      "Train Epoch: 14\t[40000/88956 (45%)]\tTotal Loss: 75.9241\tAvg Loss: 0.0019\n",
      "Train Epoch: 14\t[45000/88956 (51%)]\tTotal Loss: 86.2185\tAvg Loss: 0.0019\n",
      "Train Epoch: 14\t[50000/88956 (56%)]\tTotal Loss: 96.8008\tAvg Loss: 0.0019\n",
      "Train Epoch: 14\t[55000/88956 (62%)]\tTotal Loss: 106.9277\tAvg Loss: 0.0019\n",
      "Train Epoch: 14\t[60000/88956 (67%)]\tTotal Loss: 116.6747\tAvg Loss: 0.0019\n",
      "Train Epoch: 14\t[65000/88956 (73%)]\tTotal Loss: 126.1937\tAvg Loss: 0.0019\n",
      "Train Epoch: 14\t[70000/88956 (79%)]\tTotal Loss: 135.4678\tAvg Loss: 0.0019\n",
      "Train Epoch: 14\t[75000/88956 (84%)]\tTotal Loss: 144.3891\tAvg Loss: 0.0019\n",
      "Train Epoch: 14\t[80000/88956 (90%)]\tTotal Loss: 154.0897\tAvg Loss: 0.0019\n",
      "Train Epoch: 14\t[85000/88956 (96%)]\tTotal Loss: 163.7311\tAvg Loss: 0.0019\n",
      "====> Epoch: 14\tTotal Loss: 171.2339\t Avg Loss: 0.0019\tCorrect: 77968/88956\tPercentage Correct: 87.65\n",
      "====> Val Loss: 24.2030\t Avg Loss: 0.0024\tCorrect: 8441/9885\tPercentage Correct: 85.39\n",
      "====> Test Loss: 60.6540\t Avg Loss: 0.0025\tCorrect: 21218/24711\tPercentage Correct: 85.86\n",
      "Train Epoch: 15\t[5000/88956 (6%)]\tTotal Loss: 9.3382\tAvg Loss: 0.0019\n",
      "Train Epoch: 15\t[10000/88956 (11%)]\tTotal Loss: 18.9286\tAvg Loss: 0.0019\n",
      "Train Epoch: 15\t[15000/88956 (17%)]\tTotal Loss: 28.2213\tAvg Loss: 0.0019\n",
      "Train Epoch: 15\t[20000/88956 (22%)]\tTotal Loss: 37.5350\tAvg Loss: 0.0019\n",
      "Train Epoch: 15\t[25000/88956 (28%)]\tTotal Loss: 46.7466\tAvg Loss: 0.0019\n",
      "Train Epoch: 15\t[30000/88956 (34%)]\tTotal Loss: 56.2966\tAvg Loss: 0.0019\n",
      "Train Epoch: 15\t[35000/88956 (39%)]\tTotal Loss: 65.9187\tAvg Loss: 0.0019\n",
      "Train Epoch: 15\t[40000/88956 (45%)]\tTotal Loss: 75.3235\tAvg Loss: 0.0019\n",
      "Train Epoch: 15\t[45000/88956 (51%)]\tTotal Loss: 84.1308\tAvg Loss: 0.0019\n",
      "Train Epoch: 15\t[50000/88956 (56%)]\tTotal Loss: 93.2798\tAvg Loss: 0.0019\n",
      "Train Epoch: 15\t[55000/88956 (62%)]\tTotal Loss: 102.6015\tAvg Loss: 0.0019\n",
      "Train Epoch: 15\t[60000/88956 (67%)]\tTotal Loss: 112.4174\tAvg Loss: 0.0019\n",
      "Train Epoch: 15\t[65000/88956 (73%)]\tTotal Loss: 121.6186\tAvg Loss: 0.0019\n",
      "Train Epoch: 15\t[70000/88956 (79%)]\tTotal Loss: 131.0186\tAvg Loss: 0.0019\n",
      "Train Epoch: 15\t[75000/88956 (84%)]\tTotal Loss: 140.6319\tAvg Loss: 0.0019\n",
      "Train Epoch: 15\t[80000/88956 (90%)]\tTotal Loss: 150.6029\tAvg Loss: 0.0019\n",
      "Train Epoch: 15\t[85000/88956 (96%)]\tTotal Loss: 159.9939\tAvg Loss: 0.0019\n",
      "====> Epoch: 15\tTotal Loss: 167.3334\t Avg Loss: 0.0019\tCorrect: 78128/88956\tPercentage Correct: 87.83\n",
      "====> Val Loss: 28.5056\t Avg Loss: 0.0029\tCorrect: 8352/9885\tPercentage Correct: 84.49\n",
      "====> Test Loss: 70.9031\t Avg Loss: 0.0029\tCorrect: 20908/24711\tPercentage Correct: 84.61\n",
      "Train Epoch: 16\t[5000/88956 (6%)]\tTotal Loss: 9.7690\tAvg Loss: 0.0020\n",
      "Train Epoch: 16\t[10000/88956 (11%)]\tTotal Loss: 19.3114\tAvg Loss: 0.0019\n",
      "Train Epoch: 16\t[15000/88956 (17%)]\tTotal Loss: 28.6134\tAvg Loss: 0.0019\n",
      "Train Epoch: 16\t[20000/88956 (22%)]\tTotal Loss: 37.8598\tAvg Loss: 0.0019\n",
      "Train Epoch: 16\t[25000/88956 (28%)]\tTotal Loss: 47.0349\tAvg Loss: 0.0019\n",
      "Train Epoch: 16\t[30000/88956 (34%)]\tTotal Loss: 55.6947\tAvg Loss: 0.0019\n",
      "Train Epoch: 16\t[35000/88956 (39%)]\tTotal Loss: 64.6438\tAvg Loss: 0.0018\n",
      "Train Epoch: 16\t[40000/88956 (45%)]\tTotal Loss: 73.5935\tAvg Loss: 0.0018\n",
      "Train Epoch: 16\t[45000/88956 (51%)]\tTotal Loss: 82.8223\tAvg Loss: 0.0018\n",
      "Train Epoch: 16\t[50000/88956 (56%)]\tTotal Loss: 91.7652\tAvg Loss: 0.0018\n",
      "Train Epoch: 16\t[55000/88956 (62%)]\tTotal Loss: 101.7990\tAvg Loss: 0.0019\n",
      "Train Epoch: 16\t[60000/88956 (67%)]\tTotal Loss: 111.4885\tAvg Loss: 0.0019\n",
      "Train Epoch: 16\t[65000/88956 (73%)]\tTotal Loss: 120.5559\tAvg Loss: 0.0019\n",
      "Train Epoch: 16\t[70000/88956 (79%)]\tTotal Loss: 130.1535\tAvg Loss: 0.0019\n",
      "Train Epoch: 16\t[75000/88956 (84%)]\tTotal Loss: 139.5176\tAvg Loss: 0.0019\n",
      "Train Epoch: 16\t[80000/88956 (90%)]\tTotal Loss: 148.3404\tAvg Loss: 0.0019\n",
      "Train Epoch: 16\t[85000/88956 (96%)]\tTotal Loss: 157.3333\tAvg Loss: 0.0019\n",
      "====> Epoch: 16\tTotal Loss: 164.4927\t Avg Loss: 0.0018\tCorrect: 78304/88956\tPercentage Correct: 88.03\n",
      "====> Val Loss: 21.4554\t Avg Loss: 0.0022\tCorrect: 8545/9885\tPercentage Correct: 86.44\n",
      "====> Test Loss: 52.9368\t Avg Loss: 0.0021\tCorrect: 21482/24711\tPercentage Correct: 86.93\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 17\t[5000/88956 (6%)]\tTotal Loss: 8.9243\tAvg Loss: 0.0018\n",
      "Train Epoch: 17\t[10000/88956 (11%)]\tTotal Loss: 17.9271\tAvg Loss: 0.0018\n",
      "Train Epoch: 17\t[15000/88956 (17%)]\tTotal Loss: 27.2778\tAvg Loss: 0.0018\n",
      "Train Epoch: 17\t[20000/88956 (22%)]\tTotal Loss: 36.4143\tAvg Loss: 0.0018\n",
      "Train Epoch: 17\t[25000/88956 (28%)]\tTotal Loss: 45.5932\tAvg Loss: 0.0018\n",
      "Train Epoch: 17\t[30000/88956 (34%)]\tTotal Loss: 54.7368\tAvg Loss: 0.0018\n",
      "Train Epoch: 17\t[35000/88956 (39%)]\tTotal Loss: 63.7044\tAvg Loss: 0.0018\n",
      "Train Epoch: 17\t[40000/88956 (45%)]\tTotal Loss: 72.9900\tAvg Loss: 0.0018\n",
      "Train Epoch: 17\t[45000/88956 (51%)]\tTotal Loss: 82.3761\tAvg Loss: 0.0018\n",
      "Train Epoch: 17\t[50000/88956 (56%)]\tTotal Loss: 91.7480\tAvg Loss: 0.0018\n",
      "Train Epoch: 17\t[55000/88956 (62%)]\tTotal Loss: 101.1823\tAvg Loss: 0.0018\n",
      "Train Epoch: 17\t[60000/88956 (67%)]\tTotal Loss: 110.1466\tAvg Loss: 0.0018\n",
      "Train Epoch: 17\t[65000/88956 (73%)]\tTotal Loss: 119.9865\tAvg Loss: 0.0018\n",
      "Train Epoch: 17\t[70000/88956 (79%)]\tTotal Loss: 129.6909\tAvg Loss: 0.0019\n",
      "Train Epoch: 17\t[75000/88956 (84%)]\tTotal Loss: 139.1173\tAvg Loss: 0.0019\n",
      "Train Epoch: 17\t[80000/88956 (90%)]\tTotal Loss: 149.0034\tAvg Loss: 0.0019\n",
      "Train Epoch: 17\t[85000/88956 (96%)]\tTotal Loss: 158.2756\tAvg Loss: 0.0019\n",
      "====> Epoch: 17\tTotal Loss: 165.4908\t Avg Loss: 0.0019\tCorrect: 78335/88956\tPercentage Correct: 88.06\n",
      "====> Val Loss: 30.0953\t Avg Loss: 0.0030\tCorrect: 8343/9885\tPercentage Correct: 84.40\n",
      "====> Test Loss: 77.9514\t Avg Loss: 0.0032\tCorrect: 20765/24711\tPercentage Correct: 84.03\n",
      "Train Epoch: 18\t[5000/88956 (6%)]\tTotal Loss: 9.8836\tAvg Loss: 0.0020\n",
      "Train Epoch: 18\t[10000/88956 (11%)]\tTotal Loss: 18.7458\tAvg Loss: 0.0019\n",
      "Train Epoch: 18\t[15000/88956 (17%)]\tTotal Loss: 27.6972\tAvg Loss: 0.0018\n",
      "Train Epoch: 18\t[20000/88956 (22%)]\tTotal Loss: 36.4294\tAvg Loss: 0.0018\n",
      "Train Epoch: 18\t[25000/88956 (28%)]\tTotal Loss: 45.4949\tAvg Loss: 0.0018\n",
      "Train Epoch: 18\t[30000/88956 (34%)]\tTotal Loss: 54.0655\tAvg Loss: 0.0018\n",
      "Train Epoch: 18\t[35000/88956 (39%)]\tTotal Loss: 64.1794\tAvg Loss: 0.0018\n",
      "Train Epoch: 18\t[40000/88956 (45%)]\tTotal Loss: 73.0744\tAvg Loss: 0.0018\n",
      "Train Epoch: 18\t[45000/88956 (51%)]\tTotal Loss: 83.0598\tAvg Loss: 0.0018\n",
      "Train Epoch: 18\t[50000/88956 (56%)]\tTotal Loss: 92.8096\tAvg Loss: 0.0019\n",
      "Train Epoch: 18\t[55000/88956 (62%)]\tTotal Loss: 101.9511\tAvg Loss: 0.0019\n",
      "Train Epoch: 18\t[60000/88956 (67%)]\tTotal Loss: 111.2622\tAvg Loss: 0.0019\n",
      "Train Epoch: 18\t[65000/88956 (73%)]\tTotal Loss: 120.4733\tAvg Loss: 0.0019\n",
      "Train Epoch: 18\t[70000/88956 (79%)]\tTotal Loss: 129.7111\tAvg Loss: 0.0019\n",
      "Train Epoch: 18\t[75000/88956 (84%)]\tTotal Loss: 139.1599\tAvg Loss: 0.0019\n",
      "Train Epoch: 18\t[80000/88956 (90%)]\tTotal Loss: 148.4689\tAvg Loss: 0.0019\n",
      "Train Epoch: 18\t[85000/88956 (96%)]\tTotal Loss: 157.5188\tAvg Loss: 0.0019\n",
      "====> Epoch: 18\tTotal Loss: 165.1988\t Avg Loss: 0.0019\tCorrect: 78260/88956\tPercentage Correct: 87.98\n",
      "====> Val Loss: 26.0200\t Avg Loss: 0.0026\tCorrect: 8410/9885\tPercentage Correct: 85.08\n",
      "====> Test Loss: 65.4016\t Avg Loss: 0.0026\tCorrect: 21035/24711\tPercentage Correct: 85.12\n",
      "Train Epoch: 19\t[5000/88956 (6%)]\tTotal Loss: 9.2451\tAvg Loss: 0.0018\n",
      "Train Epoch: 19\t[10000/88956 (11%)]\tTotal Loss: 18.0225\tAvg Loss: 0.0018\n",
      "Train Epoch: 19\t[15000/88956 (17%)]\tTotal Loss: 27.0606\tAvg Loss: 0.0018\n",
      "Train Epoch: 19\t[20000/88956 (22%)]\tTotal Loss: 36.0122\tAvg Loss: 0.0018\n",
      "Train Epoch: 19\t[25000/88956 (28%)]\tTotal Loss: 45.0748\tAvg Loss: 0.0018\n",
      "Train Epoch: 19\t[30000/88956 (34%)]\tTotal Loss: 54.7564\tAvg Loss: 0.0018\n",
      "Train Epoch: 19\t[35000/88956 (39%)]\tTotal Loss: 63.7180\tAvg Loss: 0.0018\n",
      "Train Epoch: 19\t[40000/88956 (45%)]\tTotal Loss: 72.6857\tAvg Loss: 0.0018\n",
      "Train Epoch: 19\t[45000/88956 (51%)]\tTotal Loss: 82.0966\tAvg Loss: 0.0018\n",
      "Train Epoch: 19\t[50000/88956 (56%)]\tTotal Loss: 91.6244\tAvg Loss: 0.0018\n",
      "Train Epoch: 19\t[55000/88956 (62%)]\tTotal Loss: 100.7488\tAvg Loss: 0.0018\n",
      "Train Epoch: 19\t[60000/88956 (67%)]\tTotal Loss: 109.9196\tAvg Loss: 0.0018\n",
      "Train Epoch: 19\t[65000/88956 (73%)]\tTotal Loss: 119.4985\tAvg Loss: 0.0018\n",
      "Train Epoch: 19\t[70000/88956 (79%)]\tTotal Loss: 129.1976\tAvg Loss: 0.0018\n",
      "Train Epoch: 19\t[75000/88956 (84%)]\tTotal Loss: 138.9829\tAvg Loss: 0.0019\n",
      "Train Epoch: 19\t[80000/88956 (90%)]\tTotal Loss: 147.8268\tAvg Loss: 0.0018\n",
      "Train Epoch: 19\t[85000/88956 (96%)]\tTotal Loss: 157.4625\tAvg Loss: 0.0019\n",
      "====> Epoch: 19\tTotal Loss: 164.6077\t Avg Loss: 0.0019\tCorrect: 78380/88956\tPercentage Correct: 88.11\n",
      "====> Val Loss: 34.8364\t Avg Loss: 0.0035\tCorrect: 8228/9885\tPercentage Correct: 83.24\n",
      "====> Test Loss: 90.8938\t Avg Loss: 0.0037\tCorrect: 20549/24711\tPercentage Correct: 83.16\n",
      "Train Epoch: 20\t[5000/88956 (6%)]\tTotal Loss: 8.9095\tAvg Loss: 0.0018\n",
      "Train Epoch: 20\t[10000/88956 (11%)]\tTotal Loss: 17.6056\tAvg Loss: 0.0018\n",
      "Train Epoch: 20\t[15000/88956 (17%)]\tTotal Loss: 26.7371\tAvg Loss: 0.0018\n",
      "Train Epoch: 20\t[20000/88956 (22%)]\tTotal Loss: 35.6815\tAvg Loss: 0.0018\n",
      "Train Epoch: 20\t[25000/88956 (28%)]\tTotal Loss: 44.3377\tAvg Loss: 0.0018\n",
      "Train Epoch: 20\t[30000/88956 (34%)]\tTotal Loss: 53.2799\tAvg Loss: 0.0018\n",
      "Train Epoch: 20\t[35000/88956 (39%)]\tTotal Loss: 62.5681\tAvg Loss: 0.0018\n",
      "Train Epoch: 20\t[40000/88956 (45%)]\tTotal Loss: 71.2492\tAvg Loss: 0.0018\n",
      "Train Epoch: 20\t[45000/88956 (51%)]\tTotal Loss: 80.3186\tAvg Loss: 0.0018\n",
      "Train Epoch: 20\t[50000/88956 (56%)]\tTotal Loss: 90.0936\tAvg Loss: 0.0018\n",
      "Train Epoch: 20\t[55000/88956 (62%)]\tTotal Loss: 99.3918\tAvg Loss: 0.0018\n",
      "Train Epoch: 20\t[60000/88956 (67%)]\tTotal Loss: 108.7883\tAvg Loss: 0.0018\n",
      "Train Epoch: 20\t[65000/88956 (73%)]\tTotal Loss: 117.6558\tAvg Loss: 0.0018\n",
      "Train Epoch: 20\t[70000/88956 (79%)]\tTotal Loss: 126.7436\tAvg Loss: 0.0018\n",
      "Train Epoch: 20\t[75000/88956 (84%)]\tTotal Loss: 136.3700\tAvg Loss: 0.0018\n",
      "Train Epoch: 20\t[80000/88956 (90%)]\tTotal Loss: 145.5058\tAvg Loss: 0.0018\n",
      "Train Epoch: 20\t[85000/88956 (96%)]\tTotal Loss: 154.9173\tAvg Loss: 0.0018\n",
      "====> Epoch: 20\tTotal Loss: 162.3730\t Avg Loss: 0.0018\tCorrect: 78519/88956\tPercentage Correct: 88.27\n",
      "====> Val Loss: 52.5582\t Avg Loss: 0.0053\tCorrect: 7839/9885\tPercentage Correct: 79.30\n",
      "====> Test Loss: 141.3497\t Avg Loss: 0.0057\tCorrect: 19445/24711\tPercentage Correct: 78.69\n",
      "Train Epoch: 21\t[5000/88956 (6%)]\tTotal Loss: 9.0403\tAvg Loss: 0.0018\n",
      "Train Epoch: 21\t[10000/88956 (11%)]\tTotal Loss: 18.1665\tAvg Loss: 0.0018\n",
      "Train Epoch: 21\t[15000/88956 (17%)]\tTotal Loss: 27.1555\tAvg Loss: 0.0018\n",
      "Train Epoch: 21\t[20000/88956 (22%)]\tTotal Loss: 36.5033\tAvg Loss: 0.0018\n",
      "Train Epoch: 21\t[25000/88956 (28%)]\tTotal Loss: 45.3890\tAvg Loss: 0.0018\n",
      "Train Epoch: 21\t[30000/88956 (34%)]\tTotal Loss: 54.2568\tAvg Loss: 0.0018\n",
      "Train Epoch: 21\t[35000/88956 (39%)]\tTotal Loss: 63.7097\tAvg Loss: 0.0018\n",
      "Train Epoch: 21\t[40000/88956 (45%)]\tTotal Loss: 72.9097\tAvg Loss: 0.0018\n",
      "Train Epoch: 21\t[45000/88956 (51%)]\tTotal Loss: 81.7988\tAvg Loss: 0.0018\n",
      "Train Epoch: 21\t[50000/88956 (56%)]\tTotal Loss: 90.8765\tAvg Loss: 0.0018\n",
      "Train Epoch: 21\t[55000/88956 (62%)]\tTotal Loss: 99.8050\tAvg Loss: 0.0018\n",
      "Train Epoch: 21\t[60000/88956 (67%)]\tTotal Loss: 108.8482\tAvg Loss: 0.0018\n",
      "Train Epoch: 21\t[65000/88956 (73%)]\tTotal Loss: 117.6588\tAvg Loss: 0.0018\n",
      "Train Epoch: 21\t[70000/88956 (79%)]\tTotal Loss: 126.1559\tAvg Loss: 0.0018\n",
      "Train Epoch: 21\t[75000/88956 (84%)]\tTotal Loss: 134.7612\tAvg Loss: 0.0018\n",
      "Train Epoch: 21\t[80000/88956 (90%)]\tTotal Loss: 144.3743\tAvg Loss: 0.0018\n",
      "Train Epoch: 21\t[85000/88956 (96%)]\tTotal Loss: 153.5692\tAvg Loss: 0.0018\n",
      "====> Epoch: 21\tTotal Loss: 161.0416\t Avg Loss: 0.0018\tCorrect: 78390/88956\tPercentage Correct: 88.12\n",
      "====> Val Loss: 21.6251\t Avg Loss: 0.0022\tCorrect: 8523/9885\tPercentage Correct: 86.22\n",
      "====> Test Loss: 54.7143\t Avg Loss: 0.0022\tCorrect: 21302/24711\tPercentage Correct: 86.20\n",
      "Train Epoch: 22\t[5000/88956 (6%)]\tTotal Loss: 9.3759\tAvg Loss: 0.0019\n",
      "Train Epoch: 22\t[10000/88956 (11%)]\tTotal Loss: 18.2392\tAvg Loss: 0.0018\n",
      "Train Epoch: 22\t[15000/88956 (17%)]\tTotal Loss: 26.8561\tAvg Loss: 0.0018\n",
      "Train Epoch: 22\t[20000/88956 (22%)]\tTotal Loss: 35.6325\tAvg Loss: 0.0018\n",
      "Train Epoch: 22\t[25000/88956 (28%)]\tTotal Loss: 44.5408\tAvg Loss: 0.0018\n",
      "Train Epoch: 22\t[30000/88956 (34%)]\tTotal Loss: 53.7276\tAvg Loss: 0.0018\n",
      "Train Epoch: 22\t[35000/88956 (39%)]\tTotal Loss: 62.7911\tAvg Loss: 0.0018\n",
      "Train Epoch: 22\t[40000/88956 (45%)]\tTotal Loss: 71.7390\tAvg Loss: 0.0018\n",
      "Train Epoch: 22\t[45000/88956 (51%)]\tTotal Loss: 81.2849\tAvg Loss: 0.0018\n",
      "Train Epoch: 22\t[50000/88956 (56%)]\tTotal Loss: 90.0084\tAvg Loss: 0.0018\n",
      "Train Epoch: 22\t[55000/88956 (62%)]\tTotal Loss: 98.9437\tAvg Loss: 0.0018\n",
      "Train Epoch: 22\t[60000/88956 (67%)]\tTotal Loss: 107.8993\tAvg Loss: 0.0018\n",
      "Train Epoch: 22\t[65000/88956 (73%)]\tTotal Loss: 116.6169\tAvg Loss: 0.0018\n",
      "Train Epoch: 22\t[70000/88956 (79%)]\tTotal Loss: 125.9756\tAvg Loss: 0.0018\n",
      "Train Epoch: 22\t[75000/88956 (84%)]\tTotal Loss: 135.1326\tAvg Loss: 0.0018\n",
      "Train Epoch: 22\t[80000/88956 (90%)]\tTotal Loss: 144.1626\tAvg Loss: 0.0018\n",
      "Train Epoch: 22\t[85000/88956 (96%)]\tTotal Loss: 153.1214\tAvg Loss: 0.0018\n",
      "====> Epoch: 22\tTotal Loss: 160.2679\t Avg Loss: 0.0018\tCorrect: 78501/88956\tPercentage Correct: 88.25\n",
      "====> Val Loss: 22.2329\t Avg Loss: 0.0022\tCorrect: 8546/9885\tPercentage Correct: 86.45\n",
      "====> Test Loss: 55.2424\t Avg Loss: 0.0022\tCorrect: 21386/24711\tPercentage Correct: 86.54\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 23\t[5000/88956 (6%)]\tTotal Loss: 9.1303\tAvg Loss: 0.0018\n",
      "Train Epoch: 23\t[10000/88956 (11%)]\tTotal Loss: 17.9777\tAvg Loss: 0.0018\n",
      "Train Epoch: 23\t[15000/88956 (17%)]\tTotal Loss: 26.6730\tAvg Loss: 0.0018\n",
      "Train Epoch: 23\t[20000/88956 (22%)]\tTotal Loss: 35.0750\tAvg Loss: 0.0018\n",
      "Train Epoch: 23\t[25000/88956 (28%)]\tTotal Loss: 43.8193\tAvg Loss: 0.0018\n",
      "Train Epoch: 23\t[30000/88956 (34%)]\tTotal Loss: 53.0429\tAvg Loss: 0.0018\n",
      "Train Epoch: 23\t[35000/88956 (39%)]\tTotal Loss: 61.6922\tAvg Loss: 0.0018\n",
      "Train Epoch: 23\t[40000/88956 (45%)]\tTotal Loss: 70.6049\tAvg Loss: 0.0018\n",
      "Train Epoch: 23\t[45000/88956 (51%)]\tTotal Loss: 79.8952\tAvg Loss: 0.0018\n",
      "Train Epoch: 23\t[50000/88956 (56%)]\tTotal Loss: 88.7872\tAvg Loss: 0.0018\n",
      "Train Epoch: 23\t[55000/88956 (62%)]\tTotal Loss: 97.5958\tAvg Loss: 0.0018\n",
      "Train Epoch: 23\t[60000/88956 (67%)]\tTotal Loss: 106.3628\tAvg Loss: 0.0018\n",
      "Train Epoch: 23\t[65000/88956 (73%)]\tTotal Loss: 115.5793\tAvg Loss: 0.0018\n",
      "Train Epoch: 23\t[70000/88956 (79%)]\tTotal Loss: 124.9416\tAvg Loss: 0.0018\n",
      "Train Epoch: 23\t[75000/88956 (84%)]\tTotal Loss: 133.9573\tAvg Loss: 0.0018\n",
      "Train Epoch: 23\t[80000/88956 (90%)]\tTotal Loss: 143.7595\tAvg Loss: 0.0018\n",
      "Train Epoch: 23\t[85000/88956 (96%)]\tTotal Loss: 152.6732\tAvg Loss: 0.0018\n",
      "====> Epoch: 23\tTotal Loss: 159.9421\t Avg Loss: 0.0018\tCorrect: 78565/88956\tPercentage Correct: 88.32\n",
      "====> Val Loss: 28.2441\t Avg Loss: 0.0029\tCorrect: 8358/9885\tPercentage Correct: 84.55\n",
      "====> Test Loss: 70.9254\t Avg Loss: 0.0029\tCorrect: 20974/24711\tPercentage Correct: 84.88\n",
      "Train Epoch: 24\t[5000/88956 (6%)]\tTotal Loss: 9.2953\tAvg Loss: 0.0019\n",
      "Train Epoch: 24\t[10000/88956 (11%)]\tTotal Loss: 18.1339\tAvg Loss: 0.0018\n",
      "Train Epoch: 24\t[15000/88956 (17%)]\tTotal Loss: 26.7607\tAvg Loss: 0.0018\n",
      "Train Epoch: 24\t[20000/88956 (22%)]\tTotal Loss: 35.3927\tAvg Loss: 0.0018\n",
      "Train Epoch: 24\t[25000/88956 (28%)]\tTotal Loss: 44.1388\tAvg Loss: 0.0018\n",
      "Train Epoch: 24\t[30000/88956 (34%)]\tTotal Loss: 52.7752\tAvg Loss: 0.0018\n",
      "Train Epoch: 24\t[35000/88956 (39%)]\tTotal Loss: 61.2841\tAvg Loss: 0.0018\n",
      "Train Epoch: 24\t[40000/88956 (45%)]\tTotal Loss: 69.8977\tAvg Loss: 0.0017\n",
      "Train Epoch: 24\t[45000/88956 (51%)]\tTotal Loss: 78.6355\tAvg Loss: 0.0017\n",
      "Train Epoch: 24\t[50000/88956 (56%)]\tTotal Loss: 87.1642\tAvg Loss: 0.0017\n",
      "Train Epoch: 24\t[55000/88956 (62%)]\tTotal Loss: 96.4347\tAvg Loss: 0.0018\n",
      "Train Epoch: 24\t[60000/88956 (67%)]\tTotal Loss: 105.2514\tAvg Loss: 0.0018\n",
      "Train Epoch: 24\t[65000/88956 (73%)]\tTotal Loss: 114.5421\tAvg Loss: 0.0018\n",
      "Train Epoch: 24\t[70000/88956 (79%)]\tTotal Loss: 123.9377\tAvg Loss: 0.0018\n",
      "Train Epoch: 24\t[75000/88956 (84%)]\tTotal Loss: 133.5674\tAvg Loss: 0.0018\n",
      "Train Epoch: 24\t[80000/88956 (90%)]\tTotal Loss: 143.0792\tAvg Loss: 0.0018\n",
      "Train Epoch: 24\t[85000/88956 (96%)]\tTotal Loss: 151.5779\tAvg Loss: 0.0018\n",
      "====> Epoch: 24\tTotal Loss: 158.7515\t Avg Loss: 0.0018\tCorrect: 78560/88956\tPercentage Correct: 88.31\n",
      "====> Val Loss: 22.5672\t Avg Loss: 0.0023\tCorrect: 8529/9885\tPercentage Correct: 86.28\n",
      "====> Test Loss: 56.6287\t Avg Loss: 0.0023\tCorrect: 21398/24711\tPercentage Correct: 86.59\n",
      "Train Epoch: 25\t[5000/88956 (6%)]\tTotal Loss: 9.0600\tAvg Loss: 0.0018\n",
      "Train Epoch: 25\t[10000/88956 (11%)]\tTotal Loss: 17.5343\tAvg Loss: 0.0018\n",
      "Train Epoch: 25\t[15000/88956 (17%)]\tTotal Loss: 26.2944\tAvg Loss: 0.0018\n",
      "Train Epoch: 25\t[20000/88956 (22%)]\tTotal Loss: 34.8380\tAvg Loss: 0.0017\n",
      "Train Epoch: 25\t[25000/88956 (28%)]\tTotal Loss: 43.8872\tAvg Loss: 0.0018\n",
      "Train Epoch: 25\t[30000/88956 (34%)]\tTotal Loss: 52.6590\tAvg Loss: 0.0018\n",
      "Train Epoch: 25\t[35000/88956 (39%)]\tTotal Loss: 61.1043\tAvg Loss: 0.0017\n",
      "Train Epoch: 25\t[40000/88956 (45%)]\tTotal Loss: 69.9337\tAvg Loss: 0.0017\n",
      "Train Epoch: 25\t[45000/88956 (51%)]\tTotal Loss: 79.0829\tAvg Loss: 0.0018\n",
      "Train Epoch: 25\t[50000/88956 (56%)]\tTotal Loss: 87.6294\tAvg Loss: 0.0018\n",
      "Train Epoch: 25\t[55000/88956 (62%)]\tTotal Loss: 96.5184\tAvg Loss: 0.0018\n",
      "Train Epoch: 25\t[60000/88956 (67%)]\tTotal Loss: 105.4925\tAvg Loss: 0.0018\n",
      "Train Epoch: 25\t[65000/88956 (73%)]\tTotal Loss: 113.9678\tAvg Loss: 0.0018\n",
      "Train Epoch: 25\t[70000/88956 (79%)]\tTotal Loss: 122.7430\tAvg Loss: 0.0018\n",
      "Train Epoch: 25\t[75000/88956 (84%)]\tTotal Loss: 131.3973\tAvg Loss: 0.0018\n",
      "Train Epoch: 25\t[80000/88956 (90%)]\tTotal Loss: 139.9526\tAvg Loss: 0.0017\n",
      "Train Epoch: 25\t[85000/88956 (96%)]\tTotal Loss: 148.9955\tAvg Loss: 0.0018\n",
      "====> Epoch: 25\tTotal Loss: 155.8150\t Avg Loss: 0.0018\tCorrect: 78717/88956\tPercentage Correct: 88.49\n",
      "====> Val Loss: 28.9775\t Avg Loss: 0.0029\tCorrect: 8310/9885\tPercentage Correct: 84.07\n",
      "====> Test Loss: 72.8513\t Avg Loss: 0.0029\tCorrect: 20886/24711\tPercentage Correct: 84.52\n",
      "Train Epoch: 26\t[5000/88956 (6%)]\tTotal Loss: 8.9405\tAvg Loss: 0.0018\n",
      "Train Epoch: 26\t[10000/88956 (11%)]\tTotal Loss: 18.1676\tAvg Loss: 0.0018\n",
      "Train Epoch: 26\t[15000/88956 (17%)]\tTotal Loss: 26.6927\tAvg Loss: 0.0018\n",
      "Train Epoch: 26\t[20000/88956 (22%)]\tTotal Loss: 35.6477\tAvg Loss: 0.0018\n",
      "Train Epoch: 26\t[25000/88956 (28%)]\tTotal Loss: 44.4922\tAvg Loss: 0.0018\n",
      "Train Epoch: 26\t[30000/88956 (34%)]\tTotal Loss: 53.0922\tAvg Loss: 0.0018\n",
      "Train Epoch: 26\t[35000/88956 (39%)]\tTotal Loss: 62.0519\tAvg Loss: 0.0018\n",
      "Train Epoch: 26\t[40000/88956 (45%)]\tTotal Loss: 70.6550\tAvg Loss: 0.0018\n",
      "Train Epoch: 26\t[45000/88956 (51%)]\tTotal Loss: 79.4573\tAvg Loss: 0.0018\n",
      "Train Epoch: 26\t[50000/88956 (56%)]\tTotal Loss: 88.2464\tAvg Loss: 0.0018\n",
      "Train Epoch: 26\t[55000/88956 (62%)]\tTotal Loss: 96.9822\tAvg Loss: 0.0018\n",
      "Train Epoch: 26\t[60000/88956 (67%)]\tTotal Loss: 105.4609\tAvg Loss: 0.0018\n",
      "Train Epoch: 26\t[65000/88956 (73%)]\tTotal Loss: 114.5045\tAvg Loss: 0.0018\n",
      "Train Epoch: 26\t[70000/88956 (79%)]\tTotal Loss: 123.5340\tAvg Loss: 0.0018\n",
      "Train Epoch: 26\t[75000/88956 (84%)]\tTotal Loss: 133.0256\tAvg Loss: 0.0018\n",
      "Train Epoch: 26\t[80000/88956 (90%)]\tTotal Loss: 142.3980\tAvg Loss: 0.0018\n",
      "Train Epoch: 26\t[85000/88956 (96%)]\tTotal Loss: 151.4179\tAvg Loss: 0.0018\n",
      "====> Epoch: 26\tTotal Loss: 158.3168\t Avg Loss: 0.0018\tCorrect: 78605/88956\tPercentage Correct: 88.36\n",
      "====> Val Loss: 23.6613\t Avg Loss: 0.0024\tCorrect: 8459/9885\tPercentage Correct: 85.57\n",
      "====> Test Loss: 58.0977\t Avg Loss: 0.0024\tCorrect: 21283/24711\tPercentage Correct: 86.13\n",
      "Train Epoch: 27\t[5000/88956 (6%)]\tTotal Loss: 9.0111\tAvg Loss: 0.0018\n",
      "Train Epoch: 27\t[10000/88956 (11%)]\tTotal Loss: 17.8956\tAvg Loss: 0.0018\n",
      "Train Epoch: 27\t[15000/88956 (17%)]\tTotal Loss: 25.7715\tAvg Loss: 0.0017\n",
      "Train Epoch: 27\t[20000/88956 (22%)]\tTotal Loss: 34.4827\tAvg Loss: 0.0017\n",
      "Train Epoch: 27\t[25000/88956 (28%)]\tTotal Loss: 43.4496\tAvg Loss: 0.0017\n",
      "Train Epoch: 27\t[30000/88956 (34%)]\tTotal Loss: 52.3548\tAvg Loss: 0.0017\n",
      "Train Epoch: 27\t[35000/88956 (39%)]\tTotal Loss: 61.4176\tAvg Loss: 0.0018\n",
      "Train Epoch: 27\t[40000/88956 (45%)]\tTotal Loss: 70.5699\tAvg Loss: 0.0018\n",
      "Train Epoch: 27\t[45000/88956 (51%)]\tTotal Loss: 79.4930\tAvg Loss: 0.0018\n",
      "Train Epoch: 27\t[50000/88956 (56%)]\tTotal Loss: 88.2470\tAvg Loss: 0.0018\n",
      "Train Epoch: 27\t[55000/88956 (62%)]\tTotal Loss: 97.3579\tAvg Loss: 0.0018\n",
      "Train Epoch: 27\t[60000/88956 (67%)]\tTotal Loss: 106.4711\tAvg Loss: 0.0018\n",
      "Train Epoch: 27\t[65000/88956 (73%)]\tTotal Loss: 115.3425\tAvg Loss: 0.0018\n",
      "Train Epoch: 27\t[70000/88956 (79%)]\tTotal Loss: 123.9549\tAvg Loss: 0.0018\n",
      "Train Epoch: 27\t[75000/88956 (84%)]\tTotal Loss: 132.3341\tAvg Loss: 0.0018\n",
      "Train Epoch: 27\t[80000/88956 (90%)]\tTotal Loss: 140.8273\tAvg Loss: 0.0018\n",
      "Train Epoch: 27\t[85000/88956 (96%)]\tTotal Loss: 149.6285\tAvg Loss: 0.0018\n",
      "====> Epoch: 27\tTotal Loss: 156.6470\t Avg Loss: 0.0018\tCorrect: 78608/88956\tPercentage Correct: 88.37\n",
      "====> Val Loss: 23.1094\t Avg Loss: 0.0023\tCorrect: 8443/9885\tPercentage Correct: 85.41\n",
      "====> Test Loss: 55.6707\t Avg Loss: 0.0023\tCorrect: 21286/24711\tPercentage Correct: 86.14\n",
      "Train Epoch: 28\t[5000/88956 (6%)]\tTotal Loss: 8.6708\tAvg Loss: 0.0017\n",
      "Train Epoch: 28\t[10000/88956 (11%)]\tTotal Loss: 17.1148\tAvg Loss: 0.0017\n",
      "Train Epoch: 28\t[15000/88956 (17%)]\tTotal Loss: 25.3272\tAvg Loss: 0.0017\n",
      "Train Epoch: 28\t[20000/88956 (22%)]\tTotal Loss: 33.8047\tAvg Loss: 0.0017\n",
      "Train Epoch: 28\t[25000/88956 (28%)]\tTotal Loss: 42.0760\tAvg Loss: 0.0017\n",
      "Train Epoch: 28\t[30000/88956 (34%)]\tTotal Loss: 50.6884\tAvg Loss: 0.0017\n",
      "Train Epoch: 28\t[35000/88956 (39%)]\tTotal Loss: 59.3276\tAvg Loss: 0.0017\n",
      "Train Epoch: 28\t[40000/88956 (45%)]\tTotal Loss: 68.1284\tAvg Loss: 0.0017\n",
      "Train Epoch: 28\t[45000/88956 (51%)]\tTotal Loss: 76.6444\tAvg Loss: 0.0017\n",
      "Train Epoch: 28\t[50000/88956 (56%)]\tTotal Loss: 85.3919\tAvg Loss: 0.0017\n",
      "Train Epoch: 28\t[55000/88956 (62%)]\tTotal Loss: 94.2493\tAvg Loss: 0.0017\n",
      "Train Epoch: 28\t[60000/88956 (67%)]\tTotal Loss: 103.1182\tAvg Loss: 0.0017\n",
      "Train Epoch: 28\t[65000/88956 (73%)]\tTotal Loss: 112.0091\tAvg Loss: 0.0017\n",
      "Train Epoch: 28\t[70000/88956 (79%)]\tTotal Loss: 120.9710\tAvg Loss: 0.0017\n",
      "Train Epoch: 28\t[75000/88956 (84%)]\tTotal Loss: 129.9147\tAvg Loss: 0.0017\n",
      "Train Epoch: 28\t[80000/88956 (90%)]\tTotal Loss: 139.1035\tAvg Loss: 0.0017\n",
      "Train Epoch: 28\t[85000/88956 (96%)]\tTotal Loss: 147.8463\tAvg Loss: 0.0017\n",
      "====> Epoch: 28\tTotal Loss: 155.1419\t Avg Loss: 0.0017\tCorrect: 78743/88956\tPercentage Correct: 88.52\n",
      "====> Val Loss: 59.4744\t Avg Loss: 0.0060\tCorrect: 7865/9885\tPercentage Correct: 79.56\n",
      "====> Test Loss: 155.8827\t Avg Loss: 0.0063\tCorrect: 19524/24711\tPercentage Correct: 79.01\n",
      "Train Epoch: 29\t[5000/88956 (6%)]\tTotal Loss: 8.8688\tAvg Loss: 0.0018\n",
      "Train Epoch: 29\t[10000/88956 (11%)]\tTotal Loss: 17.4491\tAvg Loss: 0.0017\n",
      "Train Epoch: 29\t[15000/88956 (17%)]\tTotal Loss: 25.8115\tAvg Loss: 0.0017\n",
      "Train Epoch: 29\t[20000/88956 (22%)]\tTotal Loss: 34.8820\tAvg Loss: 0.0017\n",
      "Train Epoch: 29\t[25000/88956 (28%)]\tTotal Loss: 43.4245\tAvg Loss: 0.0017\n",
      "Train Epoch: 29\t[30000/88956 (34%)]\tTotal Loss: 52.1666\tAvg Loss: 0.0017\n",
      "Train Epoch: 29\t[35000/88956 (39%)]\tTotal Loss: 60.8949\tAvg Loss: 0.0017\n",
      "Train Epoch: 29\t[40000/88956 (45%)]\tTotal Loss: 69.3249\tAvg Loss: 0.0017\n",
      "Train Epoch: 29\t[45000/88956 (51%)]\tTotal Loss: 77.8263\tAvg Loss: 0.0017\n",
      "Train Epoch: 29\t[50000/88956 (56%)]\tTotal Loss: 86.4331\tAvg Loss: 0.0017\n",
      "Train Epoch: 29\t[55000/88956 (62%)]\tTotal Loss: 94.5858\tAvg Loss: 0.0017\n",
      "Train Epoch: 29\t[60000/88956 (67%)]\tTotal Loss: 103.3647\tAvg Loss: 0.0017\n",
      "Train Epoch: 29\t[65000/88956 (73%)]\tTotal Loss: 111.7302\tAvg Loss: 0.0017\n",
      "Train Epoch: 29\t[70000/88956 (79%)]\tTotal Loss: 120.4230\tAvg Loss: 0.0017\n",
      "Train Epoch: 29\t[75000/88956 (84%)]\tTotal Loss: 129.2901\tAvg Loss: 0.0017\n",
      "Train Epoch: 29\t[80000/88956 (90%)]\tTotal Loss: 138.5765\tAvg Loss: 0.0017\n",
      "Train Epoch: 29\t[85000/88956 (96%)]\tTotal Loss: 147.2045\tAvg Loss: 0.0017\n",
      "====> Epoch: 29\tTotal Loss: 154.2308\t Avg Loss: 0.0017\tCorrect: 78854/88956\tPercentage Correct: 88.64\n",
      "====> Val Loss: 21.9637\t Avg Loss: 0.0022\tCorrect: 8570/9885\tPercentage Correct: 86.70\n",
      "====> Test Loss: 54.5151\t Avg Loss: 0.0022\tCorrect: 21485/24711\tPercentage Correct: 86.95\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 30\t[5000/88956 (6%)]\tTotal Loss: 8.7945\tAvg Loss: 0.0018\n",
      "Train Epoch: 30\t[10000/88956 (11%)]\tTotal Loss: 17.6383\tAvg Loss: 0.0018\n",
      "Train Epoch: 30\t[15000/88956 (17%)]\tTotal Loss: 26.0627\tAvg Loss: 0.0017\n",
      "Train Epoch: 30\t[20000/88956 (22%)]\tTotal Loss: 34.7085\tAvg Loss: 0.0017\n",
      "Train Epoch: 30\t[25000/88956 (28%)]\tTotal Loss: 43.1193\tAvg Loss: 0.0017\n",
      "Train Epoch: 30\t[30000/88956 (34%)]\tTotal Loss: 51.8913\tAvg Loss: 0.0017\n",
      "Train Epoch: 30\t[35000/88956 (39%)]\tTotal Loss: 60.0188\tAvg Loss: 0.0017\n",
      "Train Epoch: 30\t[40000/88956 (45%)]\tTotal Loss: 68.4594\tAvg Loss: 0.0017\n",
      "Train Epoch: 30\t[45000/88956 (51%)]\tTotal Loss: 77.2290\tAvg Loss: 0.0017\n",
      "Train Epoch: 30\t[50000/88956 (56%)]\tTotal Loss: 85.5600\tAvg Loss: 0.0017\n",
      "Train Epoch: 30\t[55000/88956 (62%)]\tTotal Loss: 94.4283\tAvg Loss: 0.0017\n",
      "Train Epoch: 30\t[60000/88956 (67%)]\tTotal Loss: 102.8466\tAvg Loss: 0.0017\n",
      "Train Epoch: 30\t[65000/88956 (73%)]\tTotal Loss: 111.7504\tAvg Loss: 0.0017\n",
      "Train Epoch: 30\t[70000/88956 (79%)]\tTotal Loss: 120.7869\tAvg Loss: 0.0017\n",
      "Train Epoch: 30\t[75000/88956 (84%)]\tTotal Loss: 130.3727\tAvg Loss: 0.0017\n",
      "Train Epoch: 30\t[80000/88956 (90%)]\tTotal Loss: 139.5581\tAvg Loss: 0.0017\n",
      "Train Epoch: 30\t[85000/88956 (96%)]\tTotal Loss: 148.6177\tAvg Loss: 0.0017\n",
      "====> Epoch: 30\tTotal Loss: 155.9957\t Avg Loss: 0.0018\tCorrect: 78694/88956\tPercentage Correct: 88.46\n",
      "====> Val Loss: 22.2313\t Avg Loss: 0.0022\tCorrect: 8561/9885\tPercentage Correct: 86.61\n",
      "====> Test Loss: 54.4221\t Avg Loss: 0.0022\tCorrect: 21480/24711\tPercentage Correct: 86.92\n",
      "Train Epoch: 31\t[5000/88956 (6%)]\tTotal Loss: 8.5917\tAvg Loss: 0.0017\n",
      "Train Epoch: 31\t[10000/88956 (11%)]\tTotal Loss: 17.6278\tAvg Loss: 0.0018\n",
      "Train Epoch: 31\t[15000/88956 (17%)]\tTotal Loss: 25.8374\tAvg Loss: 0.0017\n",
      "Train Epoch: 31\t[20000/88956 (22%)]\tTotal Loss: 34.1447\tAvg Loss: 0.0017\n",
      "Train Epoch: 31\t[25000/88956 (28%)]\tTotal Loss: 42.6146\tAvg Loss: 0.0017\n",
      "Train Epoch: 31\t[30000/88956 (34%)]\tTotal Loss: 51.1518\tAvg Loss: 0.0017\n",
      "Train Epoch: 31\t[35000/88956 (39%)]\tTotal Loss: 60.1339\tAvg Loss: 0.0017\n",
      "Train Epoch: 31\t[40000/88956 (45%)]\tTotal Loss: 68.9588\tAvg Loss: 0.0017\n",
      "Train Epoch: 31\t[45000/88956 (51%)]\tTotal Loss: 77.5868\tAvg Loss: 0.0017\n",
      "Train Epoch: 31\t[50000/88956 (56%)]\tTotal Loss: 86.5234\tAvg Loss: 0.0017\n",
      "Train Epoch: 31\t[55000/88956 (62%)]\tTotal Loss: 95.2350\tAvg Loss: 0.0017\n",
      "Train Epoch: 31\t[60000/88956 (67%)]\tTotal Loss: 103.8217\tAvg Loss: 0.0017\n",
      "Train Epoch: 31\t[65000/88956 (73%)]\tTotal Loss: 112.7623\tAvg Loss: 0.0017\n",
      "Train Epoch: 31\t[70000/88956 (79%)]\tTotal Loss: 122.1980\tAvg Loss: 0.0017\n",
      "Train Epoch: 31\t[75000/88956 (84%)]\tTotal Loss: 131.0772\tAvg Loss: 0.0017\n",
      "Train Epoch: 31\t[80000/88956 (90%)]\tTotal Loss: 139.9475\tAvg Loss: 0.0017\n",
      "Train Epoch: 31\t[85000/88956 (96%)]\tTotal Loss: 148.9485\tAvg Loss: 0.0018\n",
      "====> Epoch: 31\tTotal Loss: 156.0489\t Avg Loss: 0.0018\tCorrect: 78784/88956\tPercentage Correct: 88.57\n",
      "====> Val Loss: 33.4116\t Avg Loss: 0.0034\tCorrect: 8140/9885\tPercentage Correct: 82.35\n",
      "====> Test Loss: 85.7995\t Avg Loss: 0.0035\tCorrect: 20377/24711\tPercentage Correct: 82.46\n",
      "Train Epoch: 32\t[5000/88956 (6%)]\tTotal Loss: 8.7348\tAvg Loss: 0.0017\n",
      "Train Epoch: 32\t[10000/88956 (11%)]\tTotal Loss: 17.3613\tAvg Loss: 0.0017\n",
      "Train Epoch: 32\t[15000/88956 (17%)]\tTotal Loss: 25.7893\tAvg Loss: 0.0017\n",
      "Train Epoch: 32\t[20000/88956 (22%)]\tTotal Loss: 34.1617\tAvg Loss: 0.0017\n",
      "Train Epoch: 32\t[25000/88956 (28%)]\tTotal Loss: 42.7673\tAvg Loss: 0.0017\n",
      "Train Epoch: 32\t[30000/88956 (34%)]\tTotal Loss: 51.1113\tAvg Loss: 0.0017\n",
      "Train Epoch: 32\t[35000/88956 (39%)]\tTotal Loss: 59.5876\tAvg Loss: 0.0017\n",
      "Train Epoch: 32\t[40000/88956 (45%)]\tTotal Loss: 67.7888\tAvg Loss: 0.0017\n",
      "Train Epoch: 32\t[45000/88956 (51%)]\tTotal Loss: 76.0583\tAvg Loss: 0.0017\n",
      "Train Epoch: 32\t[50000/88956 (56%)]\tTotal Loss: 84.9566\tAvg Loss: 0.0017\n",
      "Train Epoch: 32\t[55000/88956 (62%)]\tTotal Loss: 93.3934\tAvg Loss: 0.0017\n",
      "Train Epoch: 32\t[60000/88956 (67%)]\tTotal Loss: 101.5526\tAvg Loss: 0.0017\n",
      "Train Epoch: 32\t[65000/88956 (73%)]\tTotal Loss: 110.1723\tAvg Loss: 0.0017\n",
      "Train Epoch: 32\t[70000/88956 (79%)]\tTotal Loss: 118.9043\tAvg Loss: 0.0017\n",
      "Train Epoch: 32\t[75000/88956 (84%)]\tTotal Loss: 127.8463\tAvg Loss: 0.0017\n",
      "Train Epoch: 32\t[80000/88956 (90%)]\tTotal Loss: 136.7257\tAvg Loss: 0.0017\n",
      "Train Epoch: 32\t[85000/88956 (96%)]\tTotal Loss: 145.3111\tAvg Loss: 0.0017\n",
      "====> Epoch: 32\tTotal Loss: 151.6790\t Avg Loss: 0.0017\tCorrect: 78858/88956\tPercentage Correct: 88.65\n",
      "====> Val Loss: 23.0149\t Avg Loss: 0.0023\tCorrect: 8590/9885\tPercentage Correct: 86.90\n",
      "====> Test Loss: 58.1017\t Avg Loss: 0.0024\tCorrect: 21325/24711\tPercentage Correct: 86.30\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 33\t[5000/88956 (6%)]\tTotal Loss: 8.9078\tAvg Loss: 0.0018\n",
      "Train Epoch: 33\t[10000/88956 (11%)]\tTotal Loss: 17.7151\tAvg Loss: 0.0018\n",
      "Train Epoch: 33\t[15000/88956 (17%)]\tTotal Loss: 26.6256\tAvg Loss: 0.0018\n",
      "Train Epoch: 33\t[20000/88956 (22%)]\tTotal Loss: 35.0795\tAvg Loss: 0.0018\n",
      "Train Epoch: 33\t[25000/88956 (28%)]\tTotal Loss: 43.8032\tAvg Loss: 0.0018\n",
      "Train Epoch: 33\t[30000/88956 (34%)]\tTotal Loss: 51.8675\tAvg Loss: 0.0017\n",
      "Train Epoch: 33\t[35000/88956 (39%)]\tTotal Loss: 60.7624\tAvg Loss: 0.0017\n",
      "Train Epoch: 33\t[40000/88956 (45%)]\tTotal Loss: 69.4309\tAvg Loss: 0.0017\n",
      "Train Epoch: 33\t[45000/88956 (51%)]\tTotal Loss: 77.5436\tAvg Loss: 0.0017\n",
      "Train Epoch: 33\t[50000/88956 (56%)]\tTotal Loss: 85.8228\tAvg Loss: 0.0017\n",
      "Train Epoch: 33\t[55000/88956 (62%)]\tTotal Loss: 93.9378\tAvg Loss: 0.0017\n",
      "Train Epoch: 33\t[60000/88956 (67%)]\tTotal Loss: 102.5385\tAvg Loss: 0.0017\n",
      "Train Epoch: 33\t[65000/88956 (73%)]\tTotal Loss: 111.1938\tAvg Loss: 0.0017\n",
      "Train Epoch: 33\t[70000/88956 (79%)]\tTotal Loss: 120.1352\tAvg Loss: 0.0017\n",
      "Train Epoch: 33\t[75000/88956 (84%)]\tTotal Loss: 128.6994\tAvg Loss: 0.0017\n",
      "Train Epoch: 33\t[80000/88956 (90%)]\tTotal Loss: 137.2164\tAvg Loss: 0.0017\n",
      "Train Epoch: 33\t[85000/88956 (96%)]\tTotal Loss: 145.5812\tAvg Loss: 0.0017\n",
      "====> Epoch: 33\tTotal Loss: 152.4410\t Avg Loss: 0.0017\tCorrect: 78718/88956\tPercentage Correct: 88.49\n",
      "====> Val Loss: 58.9728\t Avg Loss: 0.0060\tCorrect: 7775/9885\tPercentage Correct: 78.65\n",
      "====> Test Loss: 150.7826\t Avg Loss: 0.0061\tCorrect: 19450/24711\tPercentage Correct: 78.71\n",
      "Train Epoch: 34\t[5000/88956 (6%)]\tTotal Loss: 8.3549\tAvg Loss: 0.0017\n",
      "Train Epoch: 34\t[10000/88956 (11%)]\tTotal Loss: 16.3931\tAvg Loss: 0.0016\n",
      "Train Epoch: 34\t[15000/88956 (17%)]\tTotal Loss: 24.3018\tAvg Loss: 0.0016\n",
      "Train Epoch: 34\t[20000/88956 (22%)]\tTotal Loss: 32.2607\tAvg Loss: 0.0016\n",
      "Train Epoch: 34\t[25000/88956 (28%)]\tTotal Loss: 41.0989\tAvg Loss: 0.0016\n",
      "Train Epoch: 34\t[30000/88956 (34%)]\tTotal Loss: 49.8910\tAvg Loss: 0.0017\n",
      "Train Epoch: 34\t[35000/88956 (39%)]\tTotal Loss: 58.3111\tAvg Loss: 0.0017\n",
      "Train Epoch: 34\t[40000/88956 (45%)]\tTotal Loss: 67.1903\tAvg Loss: 0.0017\n",
      "Train Epoch: 34\t[45000/88956 (51%)]\tTotal Loss: 76.0728\tAvg Loss: 0.0017\n",
      "Train Epoch: 34\t[50000/88956 (56%)]\tTotal Loss: 84.5929\tAvg Loss: 0.0017\n",
      "Train Epoch: 34\t[55000/88956 (62%)]\tTotal Loss: 92.9776\tAvg Loss: 0.0017\n",
      "Train Epoch: 34\t[60000/88956 (67%)]\tTotal Loss: 101.6693\tAvg Loss: 0.0017\n",
      "Train Epoch: 34\t[65000/88956 (73%)]\tTotal Loss: 110.6213\tAvg Loss: 0.0017\n",
      "Train Epoch: 34\t[70000/88956 (79%)]\tTotal Loss: 119.3734\tAvg Loss: 0.0017\n",
      "Train Epoch: 34\t[75000/88956 (84%)]\tTotal Loss: 128.3000\tAvg Loss: 0.0017\n",
      "Train Epoch: 34\t[80000/88956 (90%)]\tTotal Loss: 137.1446\tAvg Loss: 0.0017\n",
      "Train Epoch: 34\t[85000/88956 (96%)]\tTotal Loss: 145.3863\tAvg Loss: 0.0017\n",
      "====> Epoch: 34\tTotal Loss: 152.3059\t Avg Loss: 0.0017\tCorrect: 78955/88956\tPercentage Correct: 88.76\n",
      "====> Val Loss: 25.0639\t Avg Loss: 0.0025\tCorrect: 8427/9885\tPercentage Correct: 85.25\n",
      "====> Test Loss: 63.4538\t Avg Loss: 0.0026\tCorrect: 21153/24711\tPercentage Correct: 85.60\n",
      "Train Epoch: 35\t[5000/88956 (6%)]\tTotal Loss: 8.7177\tAvg Loss: 0.0017\n",
      "Train Epoch: 35\t[10000/88956 (11%)]\tTotal Loss: 17.4251\tAvg Loss: 0.0017\n",
      "Train Epoch: 35\t[15000/88956 (17%)]\tTotal Loss: 26.1651\tAvg Loss: 0.0017\n",
      "Train Epoch: 35\t[20000/88956 (22%)]\tTotal Loss: 34.1824\tAvg Loss: 0.0017\n",
      "Train Epoch: 35\t[25000/88956 (28%)]\tTotal Loss: 42.5399\tAvg Loss: 0.0017\n",
      "Train Epoch: 35\t[30000/88956 (34%)]\tTotal Loss: 50.9093\tAvg Loss: 0.0017\n",
      "Train Epoch: 35\t[35000/88956 (39%)]\tTotal Loss: 59.2934\tAvg Loss: 0.0017\n",
      "Train Epoch: 35\t[40000/88956 (45%)]\tTotal Loss: 67.5695\tAvg Loss: 0.0017\n",
      "Train Epoch: 35\t[45000/88956 (51%)]\tTotal Loss: 75.8854\tAvg Loss: 0.0017\n",
      "Train Epoch: 35\t[50000/88956 (56%)]\tTotal Loss: 84.5901\tAvg Loss: 0.0017\n",
      "Train Epoch: 35\t[55000/88956 (62%)]\tTotal Loss: 93.3467\tAvg Loss: 0.0017\n",
      "Train Epoch: 35\t[60000/88956 (67%)]\tTotal Loss: 101.8158\tAvg Loss: 0.0017\n",
      "Train Epoch: 35\t[65000/88956 (73%)]\tTotal Loss: 110.1320\tAvg Loss: 0.0017\n",
      "Train Epoch: 35\t[70000/88956 (79%)]\tTotal Loss: 118.6759\tAvg Loss: 0.0017\n",
      "Train Epoch: 35\t[75000/88956 (84%)]\tTotal Loss: 127.4480\tAvg Loss: 0.0017\n",
      "Train Epoch: 35\t[80000/88956 (90%)]\tTotal Loss: 136.5825\tAvg Loss: 0.0017\n",
      "Train Epoch: 35\t[85000/88956 (96%)]\tTotal Loss: 145.2123\tAvg Loss: 0.0017\n",
      "====> Epoch: 35\tTotal Loss: 151.8773\t Avg Loss: 0.0017\tCorrect: 78881/88956\tPercentage Correct: 88.67\n",
      "====> Val Loss: 22.0443\t Avg Loss: 0.0022\tCorrect: 8513/9885\tPercentage Correct: 86.12\n",
      "====> Test Loss: 54.0709\t Avg Loss: 0.0022\tCorrect: 21345/24711\tPercentage Correct: 86.38\n",
      "Train Epoch: 36\t[5000/88956 (6%)]\tTotal Loss: 7.8840\tAvg Loss: 0.0016\n",
      "Train Epoch: 36\t[10000/88956 (11%)]\tTotal Loss: 16.0577\tAvg Loss: 0.0016\n",
      "Train Epoch: 36\t[15000/88956 (17%)]\tTotal Loss: 24.5334\tAvg Loss: 0.0016\n",
      "Train Epoch: 36\t[20000/88956 (22%)]\tTotal Loss: 33.0156\tAvg Loss: 0.0017\n",
      "Train Epoch: 36\t[25000/88956 (28%)]\tTotal Loss: 41.2525\tAvg Loss: 0.0017\n",
      "Train Epoch: 36\t[30000/88956 (34%)]\tTotal Loss: 49.9417\tAvg Loss: 0.0017\n",
      "Train Epoch: 36\t[35000/88956 (39%)]\tTotal Loss: 58.7215\tAvg Loss: 0.0017\n",
      "Train Epoch: 36\t[40000/88956 (45%)]\tTotal Loss: 67.4777\tAvg Loss: 0.0017\n",
      "Train Epoch: 36\t[45000/88956 (51%)]\tTotal Loss: 76.3217\tAvg Loss: 0.0017\n",
      "Train Epoch: 36\t[50000/88956 (56%)]\tTotal Loss: 84.7541\tAvg Loss: 0.0017\n",
      "Train Epoch: 36\t[55000/88956 (62%)]\tTotal Loss: 93.0784\tAvg Loss: 0.0017\n",
      "Train Epoch: 36\t[60000/88956 (67%)]\tTotal Loss: 101.3902\tAvg Loss: 0.0017\n",
      "Train Epoch: 36\t[65000/88956 (73%)]\tTotal Loss: 110.0294\tAvg Loss: 0.0017\n",
      "Train Epoch: 36\t[70000/88956 (79%)]\tTotal Loss: 118.9727\tAvg Loss: 0.0017\n",
      "Train Epoch: 36\t[75000/88956 (84%)]\tTotal Loss: 127.4804\tAvg Loss: 0.0017\n",
      "Train Epoch: 36\t[80000/88956 (90%)]\tTotal Loss: 135.9967\tAvg Loss: 0.0017\n",
      "Train Epoch: 36\t[85000/88956 (96%)]\tTotal Loss: 144.8018\tAvg Loss: 0.0017\n",
      "====> Epoch: 36\tTotal Loss: 151.3225\t Avg Loss: 0.0017\tCorrect: 78917/88956\tPercentage Correct: 88.71\n",
      "====> Val Loss: 46.0321\t Avg Loss: 0.0047\tCorrect: 8118/9885\tPercentage Correct: 82.12\n",
      "====> Test Loss: 121.4954\t Avg Loss: 0.0049\tCorrect: 20259/24711\tPercentage Correct: 81.98\n",
      "Train Epoch: 37\t[5000/88956 (6%)]\tTotal Loss: 8.1891\tAvg Loss: 0.0016\n",
      "Train Epoch: 37\t[10000/88956 (11%)]\tTotal Loss: 16.2988\tAvg Loss: 0.0016\n",
      "Train Epoch: 37\t[15000/88956 (17%)]\tTotal Loss: 24.7137\tAvg Loss: 0.0016\n",
      "Train Epoch: 37\t[20000/88956 (22%)]\tTotal Loss: 32.9647\tAvg Loss: 0.0016\n",
      "Train Epoch: 37\t[25000/88956 (28%)]\tTotal Loss: 41.5425\tAvg Loss: 0.0017\n",
      "Train Epoch: 37\t[30000/88956 (34%)]\tTotal Loss: 49.8952\tAvg Loss: 0.0017\n",
      "Train Epoch: 37\t[35000/88956 (39%)]\tTotal Loss: 58.4460\tAvg Loss: 0.0017\n",
      "Train Epoch: 37\t[40000/88956 (45%)]\tTotal Loss: 66.9877\tAvg Loss: 0.0017\n",
      "Train Epoch: 37\t[45000/88956 (51%)]\tTotal Loss: 75.3816\tAvg Loss: 0.0017\n",
      "Train Epoch: 37\t[50000/88956 (56%)]\tTotal Loss: 83.7291\tAvg Loss: 0.0017\n",
      "Train Epoch: 37\t[55000/88956 (62%)]\tTotal Loss: 92.7110\tAvg Loss: 0.0017\n",
      "Train Epoch: 37\t[60000/88956 (67%)]\tTotal Loss: 101.4596\tAvg Loss: 0.0017\n",
      "Train Epoch: 37\t[65000/88956 (73%)]\tTotal Loss: 110.1588\tAvg Loss: 0.0017\n",
      "Train Epoch: 37\t[70000/88956 (79%)]\tTotal Loss: 118.8477\tAvg Loss: 0.0017\n",
      "Train Epoch: 37\t[75000/88956 (84%)]\tTotal Loss: 127.6156\tAvg Loss: 0.0017\n",
      "Train Epoch: 37\t[80000/88956 (90%)]\tTotal Loss: 136.3665\tAvg Loss: 0.0017\n",
      "Train Epoch: 37\t[85000/88956 (96%)]\tTotal Loss: 144.6309\tAvg Loss: 0.0017\n",
      "====> Epoch: 37\tTotal Loss: 151.3274\t Avg Loss: 0.0017\tCorrect: 78947/88956\tPercentage Correct: 88.75\n",
      "====> Val Loss: 21.6729\t Avg Loss: 0.0022\tCorrect: 8504/9885\tPercentage Correct: 86.03\n",
      "====> Test Loss: 53.5313\t Avg Loss: 0.0022\tCorrect: 21359/24711\tPercentage Correct: 86.44\n",
      "Train Epoch: 38\t[5000/88956 (6%)]\tTotal Loss: 8.6109\tAvg Loss: 0.0017\n",
      "Train Epoch: 38\t[10000/88956 (11%)]\tTotal Loss: 16.8372\tAvg Loss: 0.0017\n",
      "Train Epoch: 38\t[15000/88956 (17%)]\tTotal Loss: 25.1514\tAvg Loss: 0.0017\n",
      "Train Epoch: 38\t[20000/88956 (22%)]\tTotal Loss: 33.5134\tAvg Loss: 0.0017\n",
      "Train Epoch: 38\t[25000/88956 (28%)]\tTotal Loss: 42.1326\tAvg Loss: 0.0017\n",
      "Train Epoch: 38\t[30000/88956 (34%)]\tTotal Loss: 50.4358\tAvg Loss: 0.0017\n",
      "Train Epoch: 38\t[35000/88956 (39%)]\tTotal Loss: 58.8638\tAvg Loss: 0.0017\n",
      "Train Epoch: 38\t[40000/88956 (45%)]\tTotal Loss: 67.5927\tAvg Loss: 0.0017\n",
      "Train Epoch: 38\t[45000/88956 (51%)]\tTotal Loss: 75.8367\tAvg Loss: 0.0017\n",
      "Train Epoch: 38\t[50000/88956 (56%)]\tTotal Loss: 84.2494\tAvg Loss: 0.0017\n",
      "Train Epoch: 38\t[55000/88956 (62%)]\tTotal Loss: 92.7111\tAvg Loss: 0.0017\n",
      "Train Epoch: 38\t[60000/88956 (67%)]\tTotal Loss: 100.8942\tAvg Loss: 0.0017\n",
      "Train Epoch: 38\t[65000/88956 (73%)]\tTotal Loss: 109.6149\tAvg Loss: 0.0017\n",
      "Train Epoch: 38\t[70000/88956 (79%)]\tTotal Loss: 118.0507\tAvg Loss: 0.0017\n",
      "Train Epoch: 38\t[75000/88956 (84%)]\tTotal Loss: 126.5981\tAvg Loss: 0.0017\n",
      "Train Epoch: 38\t[80000/88956 (90%)]\tTotal Loss: 135.6108\tAvg Loss: 0.0017\n",
      "Train Epoch: 38\t[85000/88956 (96%)]\tTotal Loss: 144.3569\tAvg Loss: 0.0017\n",
      "====> Epoch: 38\tTotal Loss: 151.0234\t Avg Loss: 0.0017\tCorrect: 78927/88956\tPercentage Correct: 88.73\n",
      "====> Val Loss: 27.7843\t Avg Loss: 0.0028\tCorrect: 8316/9885\tPercentage Correct: 84.13\n",
      "====> Test Loss: 69.8674\t Avg Loss: 0.0028\tCorrect: 20830/24711\tPercentage Correct: 84.29\n",
      "Train Epoch: 39\t[5000/88956 (6%)]\tTotal Loss: 8.3977\tAvg Loss: 0.0017\n",
      "Train Epoch: 39\t[10000/88956 (11%)]\tTotal Loss: 16.6897\tAvg Loss: 0.0017\n",
      "Train Epoch: 39\t[15000/88956 (17%)]\tTotal Loss: 25.5023\tAvg Loss: 0.0017\n",
      "Train Epoch: 39\t[20000/88956 (22%)]\tTotal Loss: 33.9747\tAvg Loss: 0.0017\n",
      "Train Epoch: 39\t[25000/88956 (28%)]\tTotal Loss: 42.6052\tAvg Loss: 0.0017\n",
      "Train Epoch: 39\t[30000/88956 (34%)]\tTotal Loss: 50.8224\tAvg Loss: 0.0017\n",
      "Train Epoch: 39\t[35000/88956 (39%)]\tTotal Loss: 59.4106\tAvg Loss: 0.0017\n",
      "Train Epoch: 39\t[40000/88956 (45%)]\tTotal Loss: 68.0583\tAvg Loss: 0.0017\n",
      "Train Epoch: 39\t[45000/88956 (51%)]\tTotal Loss: 76.4873\tAvg Loss: 0.0017\n",
      "Train Epoch: 39\t[50000/88956 (56%)]\tTotal Loss: 84.9604\tAvg Loss: 0.0017\n",
      "Train Epoch: 39\t[55000/88956 (62%)]\tTotal Loss: 93.4432\tAvg Loss: 0.0017\n",
      "Train Epoch: 39\t[60000/88956 (67%)]\tTotal Loss: 102.2012\tAvg Loss: 0.0017\n",
      "Train Epoch: 39\t[65000/88956 (73%)]\tTotal Loss: 110.8904\tAvg Loss: 0.0017\n",
      "Train Epoch: 39\t[70000/88956 (79%)]\tTotal Loss: 119.6260\tAvg Loss: 0.0017\n",
      "Train Epoch: 39\t[75000/88956 (84%)]\tTotal Loss: 127.8216\tAvg Loss: 0.0017\n",
      "Train Epoch: 39\t[80000/88956 (90%)]\tTotal Loss: 136.1898\tAvg Loss: 0.0017\n",
      "Train Epoch: 39\t[85000/88956 (96%)]\tTotal Loss: 144.7338\tAvg Loss: 0.0017\n",
      "====> Epoch: 39\tTotal Loss: 151.1151\t Avg Loss: 0.0017\tCorrect: 78894/88956\tPercentage Correct: 88.69\n",
      "====> Val Loss: 21.3748\t Avg Loss: 0.0022\tCorrect: 8505/9885\tPercentage Correct: 86.04\n",
      "====> Test Loss: 52.8147\t Avg Loss: 0.0021\tCorrect: 21414/24711\tPercentage Correct: 86.66\n",
      "Train Epoch: 40\t[5000/88956 (6%)]\tTotal Loss: 8.3368\tAvg Loss: 0.0017\n",
      "Train Epoch: 40\t[10000/88956 (11%)]\tTotal Loss: 16.1598\tAvg Loss: 0.0016\n",
      "Train Epoch: 40\t[15000/88956 (17%)]\tTotal Loss: 24.2740\tAvg Loss: 0.0016\n",
      "Train Epoch: 40\t[20000/88956 (22%)]\tTotal Loss: 32.4440\tAvg Loss: 0.0016\n",
      "Train Epoch: 40\t[25000/88956 (28%)]\tTotal Loss: 40.8277\tAvg Loss: 0.0016\n",
      "Train Epoch: 40\t[30000/88956 (34%)]\tTotal Loss: 48.9461\tAvg Loss: 0.0016\n",
      "Train Epoch: 40\t[35000/88956 (39%)]\tTotal Loss: 56.9895\tAvg Loss: 0.0016\n",
      "Train Epoch: 40\t[40000/88956 (45%)]\tTotal Loss: 65.3593\tAvg Loss: 0.0016\n",
      "Train Epoch: 40\t[45000/88956 (51%)]\tTotal Loss: 73.3507\tAvg Loss: 0.0016\n",
      "Train Epoch: 40\t[50000/88956 (56%)]\tTotal Loss: 81.8987\tAvg Loss: 0.0016\n",
      "Train Epoch: 40\t[55000/88956 (62%)]\tTotal Loss: 90.7504\tAvg Loss: 0.0017\n",
      "Train Epoch: 40\t[60000/88956 (67%)]\tTotal Loss: 99.1647\tAvg Loss: 0.0017\n",
      "Train Epoch: 40\t[65000/88956 (73%)]\tTotal Loss: 107.9115\tAvg Loss: 0.0017\n",
      "Train Epoch: 40\t[70000/88956 (79%)]\tTotal Loss: 116.3468\tAvg Loss: 0.0017\n",
      "Train Epoch: 40\t[75000/88956 (84%)]\tTotal Loss: 124.8866\tAvg Loss: 0.0017\n",
      "Train Epoch: 40\t[80000/88956 (90%)]\tTotal Loss: 133.5209\tAvg Loss: 0.0017\n",
      "Train Epoch: 40\t[85000/88956 (96%)]\tTotal Loss: 141.8999\tAvg Loss: 0.0017\n",
      "====> Epoch: 40\tTotal Loss: 148.9046\t Avg Loss: 0.0017\tCorrect: 79014/88956\tPercentage Correct: 88.82\n",
      "====> Val Loss: 50.7611\t Avg Loss: 0.0051\tCorrect: 7900/9885\tPercentage Correct: 79.92\n",
      "====> Test Loss: 118.9667\t Avg Loss: 0.0048\tCorrect: 19999/24711\tPercentage Correct: 80.93\n",
      "Train Epoch: 41\t[5000/88956 (6%)]\tTotal Loss: 8.5838\tAvg Loss: 0.0017\n",
      "Train Epoch: 41\t[10000/88956 (11%)]\tTotal Loss: 16.8754\tAvg Loss: 0.0017\n",
      "Train Epoch: 41\t[15000/88956 (17%)]\tTotal Loss: 24.5987\tAvg Loss: 0.0016\n",
      "Train Epoch: 41\t[20000/88956 (22%)]\tTotal Loss: 33.0748\tAvg Loss: 0.0017\n",
      "Train Epoch: 41\t[25000/88956 (28%)]\tTotal Loss: 41.2456\tAvg Loss: 0.0016\n",
      "Train Epoch: 41\t[30000/88956 (34%)]\tTotal Loss: 49.8621\tAvg Loss: 0.0017\n",
      "Train Epoch: 41\t[35000/88956 (39%)]\tTotal Loss: 58.3215\tAvg Loss: 0.0017\n",
      "Train Epoch: 41\t[40000/88956 (45%)]\tTotal Loss: 67.2507\tAvg Loss: 0.0017\n",
      "Train Epoch: 41\t[45000/88956 (51%)]\tTotal Loss: 75.5984\tAvg Loss: 0.0017\n",
      "Train Epoch: 41\t[50000/88956 (56%)]\tTotal Loss: 83.7905\tAvg Loss: 0.0017\n",
      "Train Epoch: 41\t[55000/88956 (62%)]\tTotal Loss: 92.3526\tAvg Loss: 0.0017\n",
      "Train Epoch: 41\t[60000/88956 (67%)]\tTotal Loss: 100.8176\tAvg Loss: 0.0017\n",
      "Train Epoch: 41\t[65000/88956 (73%)]\tTotal Loss: 109.0265\tAvg Loss: 0.0017\n",
      "Train Epoch: 41\t[70000/88956 (79%)]\tTotal Loss: 117.6061\tAvg Loss: 0.0017\n",
      "Train Epoch: 41\t[75000/88956 (84%)]\tTotal Loss: 125.8048\tAvg Loss: 0.0017\n",
      "Train Epoch: 41\t[80000/88956 (90%)]\tTotal Loss: 133.9120\tAvg Loss: 0.0017\n",
      "Train Epoch: 41\t[85000/88956 (96%)]\tTotal Loss: 142.4693\tAvg Loss: 0.0017\n",
      "====> Epoch: 41\tTotal Loss: 148.9930\t Avg Loss: 0.0017\tCorrect: 79048/88956\tPercentage Correct: 88.86\n",
      "====> Val Loss: 26.2995\t Avg Loss: 0.0027\tCorrect: 8464/9885\tPercentage Correct: 85.62\n",
      "====> Test Loss: 66.7128\t Avg Loss: 0.0027\tCorrect: 21063/24711\tPercentage Correct: 85.24\n",
      "Train Epoch: 42\t[5000/88956 (6%)]\tTotal Loss: 8.2003\tAvg Loss: 0.0016\n",
      "Train Epoch: 42\t[10000/88956 (11%)]\tTotal Loss: 16.3925\tAvg Loss: 0.0016\n",
      "Train Epoch: 42\t[15000/88956 (17%)]\tTotal Loss: 24.8799\tAvg Loss: 0.0017\n",
      "Train Epoch: 42\t[20000/88956 (22%)]\tTotal Loss: 33.1953\tAvg Loss: 0.0017\n",
      "Train Epoch: 42\t[25000/88956 (28%)]\tTotal Loss: 41.3541\tAvg Loss: 0.0017\n",
      "Train Epoch: 42\t[30000/88956 (34%)]\tTotal Loss: 49.8656\tAvg Loss: 0.0017\n",
      "Train Epoch: 42\t[35000/88956 (39%)]\tTotal Loss: 57.9630\tAvg Loss: 0.0017\n",
      "Train Epoch: 42\t[40000/88956 (45%)]\tTotal Loss: 66.5024\tAvg Loss: 0.0017\n",
      "Train Epoch: 42\t[45000/88956 (51%)]\tTotal Loss: 75.0883\tAvg Loss: 0.0017\n",
      "Train Epoch: 42\t[50000/88956 (56%)]\tTotal Loss: 83.6200\tAvg Loss: 0.0017\n",
      "Train Epoch: 42\t[55000/88956 (62%)]\tTotal Loss: 91.7820\tAvg Loss: 0.0017\n",
      "Train Epoch: 42\t[60000/88956 (67%)]\tTotal Loss: 100.4192\tAvg Loss: 0.0017\n",
      "Train Epoch: 42\t[65000/88956 (73%)]\tTotal Loss: 108.6937\tAvg Loss: 0.0017\n",
      "Train Epoch: 42\t[70000/88956 (79%)]\tTotal Loss: 116.8948\tAvg Loss: 0.0017\n",
      "Train Epoch: 42\t[75000/88956 (84%)]\tTotal Loss: 125.3762\tAvg Loss: 0.0017\n",
      "Train Epoch: 42\t[80000/88956 (90%)]\tTotal Loss: 133.6877\tAvg Loss: 0.0017\n",
      "Train Epoch: 42\t[85000/88956 (96%)]\tTotal Loss: 142.1976\tAvg Loss: 0.0017\n",
      "====> Epoch: 42\tTotal Loss: 149.0568\t Avg Loss: 0.0017\tCorrect: 78952/88956\tPercentage Correct: 88.75\n",
      "====> Val Loss: 26.1859\t Avg Loss: 0.0026\tCorrect: 8450/9885\tPercentage Correct: 85.48\n",
      "====> Test Loss: 64.7626\t Avg Loss: 0.0026\tCorrect: 21276/24711\tPercentage Correct: 86.10\n",
      "Train Epoch: 43\t[5000/88956 (6%)]\tTotal Loss: 8.5672\tAvg Loss: 0.0017\n",
      "Train Epoch: 43\t[10000/88956 (11%)]\tTotal Loss: 16.8857\tAvg Loss: 0.0017\n",
      "Train Epoch: 43\t[15000/88956 (17%)]\tTotal Loss: 25.2549\tAvg Loss: 0.0017\n",
      "Train Epoch: 43\t[20000/88956 (22%)]\tTotal Loss: 33.6627\tAvg Loss: 0.0017\n",
      "Train Epoch: 43\t[25000/88956 (28%)]\tTotal Loss: 42.1789\tAvg Loss: 0.0017\n",
      "Train Epoch: 43\t[30000/88956 (34%)]\tTotal Loss: 50.8911\tAvg Loss: 0.0017\n",
      "Train Epoch: 43\t[35000/88956 (39%)]\tTotal Loss: 59.1014\tAvg Loss: 0.0017\n",
      "Train Epoch: 43\t[40000/88956 (45%)]\tTotal Loss: 67.5981\tAvg Loss: 0.0017\n",
      "Train Epoch: 43\t[45000/88956 (51%)]\tTotal Loss: 76.0988\tAvg Loss: 0.0017\n",
      "Train Epoch: 43\t[50000/88956 (56%)]\tTotal Loss: 84.6877\tAvg Loss: 0.0017\n",
      "Train Epoch: 43\t[55000/88956 (62%)]\tTotal Loss: 93.3310\tAvg Loss: 0.0017\n",
      "Train Epoch: 43\t[60000/88956 (67%)]\tTotal Loss: 101.7486\tAvg Loss: 0.0017\n",
      "Train Epoch: 43\t[65000/88956 (73%)]\tTotal Loss: 109.8524\tAvg Loss: 0.0017\n",
      "Train Epoch: 43\t[70000/88956 (79%)]\tTotal Loss: 118.3103\tAvg Loss: 0.0017\n",
      "Train Epoch: 43\t[75000/88956 (84%)]\tTotal Loss: 126.8708\tAvg Loss: 0.0017\n",
      "Train Epoch: 43\t[80000/88956 (90%)]\tTotal Loss: 135.3248\tAvg Loss: 0.0017\n",
      "Train Epoch: 43\t[85000/88956 (96%)]\tTotal Loss: 143.5830\tAvg Loss: 0.0017\n",
      "====> Epoch: 43\tTotal Loss: 150.7002\t Avg Loss: 0.0017\tCorrect: 78930/88956\tPercentage Correct: 88.73\n",
      "====> Val Loss: 26.6333\t Avg Loss: 0.0027\tCorrect: 8445/9885\tPercentage Correct: 85.43\n",
      "====> Test Loss: 68.6825\t Avg Loss: 0.0028\tCorrect: 21090/24711\tPercentage Correct: 85.35\n",
      "Train Epoch: 44\t[5000/88956 (6%)]\tTotal Loss: 8.4927\tAvg Loss: 0.0017\n",
      "Train Epoch: 44\t[10000/88956 (11%)]\tTotal Loss: 16.9258\tAvg Loss: 0.0017\n",
      "Train Epoch: 44\t[15000/88956 (17%)]\tTotal Loss: 25.3153\tAvg Loss: 0.0017\n",
      "Train Epoch: 44\t[20000/88956 (22%)]\tTotal Loss: 33.8401\tAvg Loss: 0.0017\n",
      "Train Epoch: 44\t[25000/88956 (28%)]\tTotal Loss: 41.9246\tAvg Loss: 0.0017\n",
      "Train Epoch: 44\t[30000/88956 (34%)]\tTotal Loss: 50.1621\tAvg Loss: 0.0017\n",
      "Train Epoch: 44\t[35000/88956 (39%)]\tTotal Loss: 58.9994\tAvg Loss: 0.0017\n",
      "Train Epoch: 44\t[40000/88956 (45%)]\tTotal Loss: 68.0075\tAvg Loss: 0.0017\n",
      "Train Epoch: 44\t[45000/88956 (51%)]\tTotal Loss: 76.7433\tAvg Loss: 0.0017\n",
      "Train Epoch: 44\t[50000/88956 (56%)]\tTotal Loss: 84.8952\tAvg Loss: 0.0017\n",
      "Train Epoch: 44\t[55000/88956 (62%)]\tTotal Loss: 92.8219\tAvg Loss: 0.0017\n",
      "Train Epoch: 44\t[60000/88956 (67%)]\tTotal Loss: 101.0642\tAvg Loss: 0.0017\n",
      "Train Epoch: 44\t[65000/88956 (73%)]\tTotal Loss: 109.1866\tAvg Loss: 0.0017\n",
      "Train Epoch: 44\t[70000/88956 (79%)]\tTotal Loss: 117.4933\tAvg Loss: 0.0017\n",
      "Train Epoch: 44\t[75000/88956 (84%)]\tTotal Loss: 126.0166\tAvg Loss: 0.0017\n",
      "Train Epoch: 44\t[80000/88956 (90%)]\tTotal Loss: 134.2686\tAvg Loss: 0.0017\n",
      "Train Epoch: 44\t[85000/88956 (96%)]\tTotal Loss: 142.9417\tAvg Loss: 0.0017\n",
      "====> Epoch: 44\tTotal Loss: 149.3358\t Avg Loss: 0.0017\tCorrect: 79001/88956\tPercentage Correct: 88.81\n",
      "====> Val Loss: 30.5148\t Avg Loss: 0.0031\tCorrect: 8293/9885\tPercentage Correct: 83.89\n",
      "====> Test Loss: 74.0666\t Avg Loss: 0.0030\tCorrect: 20855/24711\tPercentage Correct: 84.40\n",
      "Train Epoch: 45\t[5000/88956 (6%)]\tTotal Loss: 8.5137\tAvg Loss: 0.0017\n",
      "Train Epoch: 45\t[10000/88956 (11%)]\tTotal Loss: 16.3874\tAvg Loss: 0.0016\n",
      "Train Epoch: 45\t[15000/88956 (17%)]\tTotal Loss: 24.3219\tAvg Loss: 0.0016\n",
      "Train Epoch: 45\t[20000/88956 (22%)]\tTotal Loss: 32.9840\tAvg Loss: 0.0016\n",
      "Train Epoch: 45\t[25000/88956 (28%)]\tTotal Loss: 41.3009\tAvg Loss: 0.0017\n",
      "Train Epoch: 45\t[30000/88956 (34%)]\tTotal Loss: 49.9366\tAvg Loss: 0.0017\n",
      "Train Epoch: 45\t[35000/88956 (39%)]\tTotal Loss: 58.4828\tAvg Loss: 0.0017\n",
      "Train Epoch: 45\t[40000/88956 (45%)]\tTotal Loss: 66.9474\tAvg Loss: 0.0017\n",
      "Train Epoch: 45\t[45000/88956 (51%)]\tTotal Loss: 75.0581\tAvg Loss: 0.0017\n",
      "Train Epoch: 45\t[50000/88956 (56%)]\tTotal Loss: 83.4743\tAvg Loss: 0.0017\n",
      "Train Epoch: 45\t[55000/88956 (62%)]\tTotal Loss: 91.7431\tAvg Loss: 0.0017\n",
      "Train Epoch: 45\t[60000/88956 (67%)]\tTotal Loss: 99.9183\tAvg Loss: 0.0017\n",
      "Train Epoch: 45\t[65000/88956 (73%)]\tTotal Loss: 108.5161\tAvg Loss: 0.0017\n",
      "Train Epoch: 45\t[70000/88956 (79%)]\tTotal Loss: 116.3950\tAvg Loss: 0.0017\n",
      "Train Epoch: 45\t[75000/88956 (84%)]\tTotal Loss: 124.8806\tAvg Loss: 0.0017\n",
      "Train Epoch: 45\t[80000/88956 (90%)]\tTotal Loss: 133.0601\tAvg Loss: 0.0017\n",
      "Train Epoch: 45\t[85000/88956 (96%)]\tTotal Loss: 141.2858\tAvg Loss: 0.0017\n",
      "====> Epoch: 45\tTotal Loss: 147.6948\t Avg Loss: 0.0017\tCorrect: 79049/88956\tPercentage Correct: 88.86\n",
      "====> Val Loss: 25.6034\t Avg Loss: 0.0026\tCorrect: 8412/9885\tPercentage Correct: 85.10\n",
      "====> Test Loss: 61.7174\t Avg Loss: 0.0025\tCorrect: 21159/24711\tPercentage Correct: 85.63\n",
      "Train Epoch: 46\t[5000/88956 (6%)]\tTotal Loss: 8.2335\tAvg Loss: 0.0016\n",
      "Train Epoch: 46\t[10000/88956 (11%)]\tTotal Loss: 16.2235\tAvg Loss: 0.0016\n",
      "Train Epoch: 46\t[15000/88956 (17%)]\tTotal Loss: 24.4603\tAvg Loss: 0.0016\n",
      "Train Epoch: 46\t[20000/88956 (22%)]\tTotal Loss: 32.6502\tAvg Loss: 0.0016\n",
      "Train Epoch: 46\t[25000/88956 (28%)]\tTotal Loss: 40.5707\tAvg Loss: 0.0016\n",
      "Train Epoch: 46\t[30000/88956 (34%)]\tTotal Loss: 48.7744\tAvg Loss: 0.0016\n",
      "Train Epoch: 46\t[35000/88956 (39%)]\tTotal Loss: 56.9196\tAvg Loss: 0.0016\n",
      "Train Epoch: 46\t[40000/88956 (45%)]\tTotal Loss: 65.6412\tAvg Loss: 0.0016\n",
      "Train Epoch: 46\t[45000/88956 (51%)]\tTotal Loss: 74.5162\tAvg Loss: 0.0017\n",
      "Train Epoch: 46\t[50000/88956 (56%)]\tTotal Loss: 82.7175\tAvg Loss: 0.0017\n",
      "Train Epoch: 46\t[55000/88956 (62%)]\tTotal Loss: 90.8601\tAvg Loss: 0.0017\n",
      "Train Epoch: 46\t[60000/88956 (67%)]\tTotal Loss: 99.1654\tAvg Loss: 0.0017\n",
      "Train Epoch: 46\t[65000/88956 (73%)]\tTotal Loss: 107.4681\tAvg Loss: 0.0017\n",
      "Train Epoch: 46\t[70000/88956 (79%)]\tTotal Loss: 115.8596\tAvg Loss: 0.0017\n",
      "Train Epoch: 46\t[75000/88956 (84%)]\tTotal Loss: 124.4064\tAvg Loss: 0.0017\n",
      "Train Epoch: 46\t[80000/88956 (90%)]\tTotal Loss: 132.5647\tAvg Loss: 0.0017\n",
      "Train Epoch: 46\t[85000/88956 (96%)]\tTotal Loss: 141.0618\tAvg Loss: 0.0017\n",
      "====> Epoch: 46\tTotal Loss: 147.8196\t Avg Loss: 0.0017\tCorrect: 79115/88956\tPercentage Correct: 88.94\n",
      "====> Val Loss: 106.5023\t Avg Loss: 0.0108\tCorrect: 7005/9885\tPercentage Correct: 70.86\n",
      "====> Test Loss: 262.6221\t Avg Loss: 0.0106\tCorrect: 17780/24711\tPercentage Correct: 71.95\n",
      "Train Epoch: 47\t[5000/88956 (6%)]\tTotal Loss: 8.7082\tAvg Loss: 0.0017\n",
      "Train Epoch: 47\t[10000/88956 (11%)]\tTotal Loss: 16.9004\tAvg Loss: 0.0017\n",
      "Train Epoch: 47\t[15000/88956 (17%)]\tTotal Loss: 25.0475\tAvg Loss: 0.0017\n",
      "Train Epoch: 47\t[20000/88956 (22%)]\tTotal Loss: 33.2215\tAvg Loss: 0.0017\n",
      "Train Epoch: 47\t[25000/88956 (28%)]\tTotal Loss: 41.4063\tAvg Loss: 0.0017\n",
      "Train Epoch: 47\t[30000/88956 (34%)]\tTotal Loss: 49.8558\tAvg Loss: 0.0017\n",
      "Train Epoch: 47\t[35000/88956 (39%)]\tTotal Loss: 57.9549\tAvg Loss: 0.0017\n",
      "Train Epoch: 47\t[40000/88956 (45%)]\tTotal Loss: 66.1074\tAvg Loss: 0.0017\n",
      "Train Epoch: 47\t[45000/88956 (51%)]\tTotal Loss: 74.2737\tAvg Loss: 0.0017\n",
      "Train Epoch: 47\t[50000/88956 (56%)]\tTotal Loss: 82.5706\tAvg Loss: 0.0017\n",
      "Train Epoch: 47\t[55000/88956 (62%)]\tTotal Loss: 90.4950\tAvg Loss: 0.0016\n",
      "Train Epoch: 47\t[60000/88956 (67%)]\tTotal Loss: 98.4677\tAvg Loss: 0.0016\n",
      "Train Epoch: 47\t[65000/88956 (73%)]\tTotal Loss: 106.9901\tAvg Loss: 0.0016\n",
      "Train Epoch: 47\t[70000/88956 (79%)]\tTotal Loss: 115.5411\tAvg Loss: 0.0017\n",
      "Train Epoch: 47\t[75000/88956 (84%)]\tTotal Loss: 123.7601\tAvg Loss: 0.0017\n",
      "Train Epoch: 47\t[80000/88956 (90%)]\tTotal Loss: 132.3193\tAvg Loss: 0.0017\n",
      "Train Epoch: 47\t[85000/88956 (96%)]\tTotal Loss: 140.5866\tAvg Loss: 0.0017\n",
      "====> Epoch: 47\tTotal Loss: 147.2248\t Avg Loss: 0.0017\tCorrect: 79109/88956\tPercentage Correct: 88.93\n",
      "====> Val Loss: 27.3337\t Avg Loss: 0.0028\tCorrect: 8357/9885\tPercentage Correct: 84.54\n",
      "====> Test Loss: 69.4413\t Avg Loss: 0.0028\tCorrect: 21033/24711\tPercentage Correct: 85.12\n",
      "Train Epoch: 48\t[5000/88956 (6%)]\tTotal Loss: 8.4415\tAvg Loss: 0.0017\n",
      "Train Epoch: 48\t[10000/88956 (11%)]\tTotal Loss: 16.8971\tAvg Loss: 0.0017\n",
      "Train Epoch: 48\t[15000/88956 (17%)]\tTotal Loss: 25.1537\tAvg Loss: 0.0017\n",
      "Train Epoch: 48\t[20000/88956 (22%)]\tTotal Loss: 33.4648\tAvg Loss: 0.0017\n",
      "Train Epoch: 48\t[25000/88956 (28%)]\tTotal Loss: 41.4512\tAvg Loss: 0.0017\n",
      "Train Epoch: 48\t[30000/88956 (34%)]\tTotal Loss: 49.1885\tAvg Loss: 0.0016\n",
      "Train Epoch: 48\t[35000/88956 (39%)]\tTotal Loss: 57.7098\tAvg Loss: 0.0016\n",
      "Train Epoch: 48\t[40000/88956 (45%)]\tTotal Loss: 66.0995\tAvg Loss: 0.0017\n",
      "Train Epoch: 48\t[45000/88956 (51%)]\tTotal Loss: 74.1347\tAvg Loss: 0.0016\n",
      "Train Epoch: 48\t[50000/88956 (56%)]\tTotal Loss: 82.7257\tAvg Loss: 0.0017\n",
      "Train Epoch: 48\t[55000/88956 (62%)]\tTotal Loss: 91.3582\tAvg Loss: 0.0017\n",
      "Train Epoch: 48\t[60000/88956 (67%)]\tTotal Loss: 99.6625\tAvg Loss: 0.0017\n",
      "Train Epoch: 48\t[65000/88956 (73%)]\tTotal Loss: 108.2909\tAvg Loss: 0.0017\n",
      "Train Epoch: 48\t[70000/88956 (79%)]\tTotal Loss: 116.3357\tAvg Loss: 0.0017\n",
      "Train Epoch: 48\t[75000/88956 (84%)]\tTotal Loss: 124.2497\tAvg Loss: 0.0017\n",
      "Train Epoch: 48\t[80000/88956 (90%)]\tTotal Loss: 132.8515\tAvg Loss: 0.0017\n",
      "Train Epoch: 48\t[85000/88956 (96%)]\tTotal Loss: 140.9966\tAvg Loss: 0.0017\n",
      "====> Epoch: 48\tTotal Loss: 147.6230\t Avg Loss: 0.0017\tCorrect: 78936/88956\tPercentage Correct: 88.74\n",
      "====> Val Loss: 25.0491\t Avg Loss: 0.0025\tCorrect: 8458/9885\tPercentage Correct: 85.56\n",
      "====> Test Loss: 60.6404\t Avg Loss: 0.0025\tCorrect: 21236/24711\tPercentage Correct: 85.94\n",
      "Train Epoch: 49\t[5000/88956 (6%)]\tTotal Loss: 8.0916\tAvg Loss: 0.0016\n",
      "Train Epoch: 49\t[10000/88956 (11%)]\tTotal Loss: 16.2016\tAvg Loss: 0.0016\n",
      "Train Epoch: 49\t[15000/88956 (17%)]\tTotal Loss: 23.9509\tAvg Loss: 0.0016\n",
      "Train Epoch: 49\t[20000/88956 (22%)]\tTotal Loss: 32.2394\tAvg Loss: 0.0016\n",
      "Train Epoch: 49\t[25000/88956 (28%)]\tTotal Loss: 40.2938\tAvg Loss: 0.0016\n",
      "Train Epoch: 49\t[30000/88956 (34%)]\tTotal Loss: 48.2974\tAvg Loss: 0.0016\n",
      "Train Epoch: 49\t[35000/88956 (39%)]\tTotal Loss: 56.4414\tAvg Loss: 0.0016\n",
      "Train Epoch: 49\t[40000/88956 (45%)]\tTotal Loss: 64.4034\tAvg Loss: 0.0016\n",
      "Train Epoch: 49\t[45000/88956 (51%)]\tTotal Loss: 72.6608\tAvg Loss: 0.0016\n",
      "Train Epoch: 49\t[50000/88956 (56%)]\tTotal Loss: 80.6567\tAvg Loss: 0.0016\n",
      "Train Epoch: 49\t[55000/88956 (62%)]\tTotal Loss: 89.0521\tAvg Loss: 0.0016\n",
      "Train Epoch: 49\t[60000/88956 (67%)]\tTotal Loss: 97.4754\tAvg Loss: 0.0016\n",
      "Train Epoch: 49\t[65000/88956 (73%)]\tTotal Loss: 105.9806\tAvg Loss: 0.0016\n",
      "Train Epoch: 49\t[70000/88956 (79%)]\tTotal Loss: 114.5789\tAvg Loss: 0.0016\n",
      "Train Epoch: 49\t[75000/88956 (84%)]\tTotal Loss: 123.0049\tAvg Loss: 0.0016\n",
      "Train Epoch: 49\t[80000/88956 (90%)]\tTotal Loss: 131.3960\tAvg Loss: 0.0016\n",
      "Train Epoch: 49\t[85000/88956 (96%)]\tTotal Loss: 139.7292\tAvg Loss: 0.0016\n",
      "====> Epoch: 49\tTotal Loss: 146.1007\t Avg Loss: 0.0016\tCorrect: 79206/88956\tPercentage Correct: 89.04\n",
      "====> Val Loss: 26.9169\t Avg Loss: 0.0027\tCorrect: 8431/9885\tPercentage Correct: 85.29\n",
      "====> Test Loss: 65.3528\t Avg Loss: 0.0026\tCorrect: 21075/24711\tPercentage Correct: 85.29\n",
      "Train Epoch: 50\t[5000/88956 (6%)]\tTotal Loss: 8.4484\tAvg Loss: 0.0017\n",
      "Train Epoch: 50\t[10000/88956 (11%)]\tTotal Loss: 16.5128\tAvg Loss: 0.0017\n",
      "Train Epoch: 50\t[15000/88956 (17%)]\tTotal Loss: 24.9191\tAvg Loss: 0.0017\n",
      "Train Epoch: 50\t[20000/88956 (22%)]\tTotal Loss: 32.8850\tAvg Loss: 0.0016\n",
      "Train Epoch: 50\t[25000/88956 (28%)]\tTotal Loss: 40.6139\tAvg Loss: 0.0016\n",
      "Train Epoch: 50\t[30000/88956 (34%)]\tTotal Loss: 49.0440\tAvg Loss: 0.0016\n",
      "Train Epoch: 50\t[35000/88956 (39%)]\tTotal Loss: 56.9975\tAvg Loss: 0.0016\n",
      "Train Epoch: 50\t[40000/88956 (45%)]\tTotal Loss: 64.9744\tAvg Loss: 0.0016\n",
      "Train Epoch: 50\t[45000/88956 (51%)]\tTotal Loss: 73.6746\tAvg Loss: 0.0016\n",
      "Train Epoch: 50\t[50000/88956 (56%)]\tTotal Loss: 81.7165\tAvg Loss: 0.0016\n",
      "Train Epoch: 50\t[55000/88956 (62%)]\tTotal Loss: 90.2380\tAvg Loss: 0.0016\n",
      "Train Epoch: 50\t[60000/88956 (67%)]\tTotal Loss: 98.8008\tAvg Loss: 0.0016\n",
      "Train Epoch: 50\t[65000/88956 (73%)]\tTotal Loss: 106.7772\tAvg Loss: 0.0016\n",
      "Train Epoch: 50\t[70000/88956 (79%)]\tTotal Loss: 115.0110\tAvg Loss: 0.0016\n",
      "Train Epoch: 50\t[75000/88956 (84%)]\tTotal Loss: 123.3894\tAvg Loss: 0.0016\n",
      "Train Epoch: 50\t[80000/88956 (90%)]\tTotal Loss: 131.7472\tAvg Loss: 0.0016\n",
      "Train Epoch: 50\t[85000/88956 (96%)]\tTotal Loss: 139.8822\tAvg Loss: 0.0016\n",
      "====> Epoch: 50\tTotal Loss: 145.9222\t Avg Loss: 0.0016\tCorrect: 79142/88956\tPercentage Correct: 88.97\n",
      "====> Val Loss: 44.5240\t Avg Loss: 0.0045\tCorrect: 8058/9885\tPercentage Correct: 81.52\n",
      "====> Test Loss: 108.8462\t Avg Loss: 0.0044\tCorrect: 20344/24711\tPercentage Correct: 82.33\n",
      "Train Epoch: 51\t[5000/88956 (6%)]\tTotal Loss: 8.3040\tAvg Loss: 0.0017\n",
      "Train Epoch: 51\t[10000/88956 (11%)]\tTotal Loss: 16.2954\tAvg Loss: 0.0016\n",
      "Train Epoch: 51\t[15000/88956 (17%)]\tTotal Loss: 24.4621\tAvg Loss: 0.0016\n",
      "Train Epoch: 51\t[20000/88956 (22%)]\tTotal Loss: 32.2748\tAvg Loss: 0.0016\n",
      "Train Epoch: 51\t[25000/88956 (28%)]\tTotal Loss: 40.6083\tAvg Loss: 0.0016\n",
      "Train Epoch: 51\t[30000/88956 (34%)]\tTotal Loss: 48.6126\tAvg Loss: 0.0016\n",
      "Train Epoch: 51\t[35000/88956 (39%)]\tTotal Loss: 56.7430\tAvg Loss: 0.0016\n",
      "Train Epoch: 51\t[40000/88956 (45%)]\tTotal Loss: 65.0831\tAvg Loss: 0.0016\n",
      "Train Epoch: 51\t[45000/88956 (51%)]\tTotal Loss: 73.8136\tAvg Loss: 0.0016\n",
      "Train Epoch: 51\t[50000/88956 (56%)]\tTotal Loss: 82.0153\tAvg Loss: 0.0016\n",
      "Train Epoch: 51\t[55000/88956 (62%)]\tTotal Loss: 90.9281\tAvg Loss: 0.0017\n",
      "Train Epoch: 51\t[60000/88956 (67%)]\tTotal Loss: 99.0740\tAvg Loss: 0.0017\n",
      "Train Epoch: 51\t[65000/88956 (73%)]\tTotal Loss: 107.0376\tAvg Loss: 0.0016\n",
      "Train Epoch: 51\t[70000/88956 (79%)]\tTotal Loss: 115.1952\tAvg Loss: 0.0016\n",
      "Train Epoch: 51\t[75000/88956 (84%)]\tTotal Loss: 123.1815\tAvg Loss: 0.0016\n",
      "Train Epoch: 51\t[80000/88956 (90%)]\tTotal Loss: 131.3884\tAvg Loss: 0.0016\n",
      "Train Epoch: 51\t[85000/88956 (96%)]\tTotal Loss: 139.6953\tAvg Loss: 0.0016\n",
      "====> Epoch: 51\tTotal Loss: 146.0109\t Avg Loss: 0.0016\tCorrect: 79197/88956\tPercentage Correct: 89.03\n",
      "====> Val Loss: 25.5620\t Avg Loss: 0.0026\tCorrect: 8423/9885\tPercentage Correct: 85.21\n",
      "====> Test Loss: 63.6579\t Avg Loss: 0.0026\tCorrect: 21206/24711\tPercentage Correct: 85.82\n",
      "Train Epoch: 52\t[5000/88956 (6%)]\tTotal Loss: 8.3469\tAvg Loss: 0.0017\n",
      "Train Epoch: 52\t[10000/88956 (11%)]\tTotal Loss: 16.6500\tAvg Loss: 0.0017\n",
      "Train Epoch: 52\t[15000/88956 (17%)]\tTotal Loss: 25.2410\tAvg Loss: 0.0017\n",
      "Train Epoch: 52\t[20000/88956 (22%)]\tTotal Loss: 33.3328\tAvg Loss: 0.0017\n",
      "Train Epoch: 52\t[25000/88956 (28%)]\tTotal Loss: 41.3023\tAvg Loss: 0.0017\n",
      "Train Epoch: 52\t[30000/88956 (34%)]\tTotal Loss: 49.6517\tAvg Loss: 0.0017\n",
      "Train Epoch: 52\t[35000/88956 (39%)]\tTotal Loss: 57.7449\tAvg Loss: 0.0016\n",
      "Train Epoch: 52\t[40000/88956 (45%)]\tTotal Loss: 65.6886\tAvg Loss: 0.0016\n",
      "Train Epoch: 52\t[45000/88956 (51%)]\tTotal Loss: 73.5896\tAvg Loss: 0.0016\n",
      "Train Epoch: 52\t[50000/88956 (56%)]\tTotal Loss: 81.9757\tAvg Loss: 0.0016\n",
      "Train Epoch: 52\t[55000/88956 (62%)]\tTotal Loss: 89.7522\tAvg Loss: 0.0016\n",
      "Train Epoch: 52\t[60000/88956 (67%)]\tTotal Loss: 98.1111\tAvg Loss: 0.0016\n",
      "Train Epoch: 52\t[65000/88956 (73%)]\tTotal Loss: 106.4872\tAvg Loss: 0.0016\n",
      "Train Epoch: 52\t[70000/88956 (79%)]\tTotal Loss: 115.0746\tAvg Loss: 0.0016\n",
      "Train Epoch: 52\t[75000/88956 (84%)]\tTotal Loss: 123.5161\tAvg Loss: 0.0016\n",
      "Train Epoch: 52\t[80000/88956 (90%)]\tTotal Loss: 132.0355\tAvg Loss: 0.0017\n",
      "Train Epoch: 52\t[85000/88956 (96%)]\tTotal Loss: 140.2735\tAvg Loss: 0.0017\n",
      "====> Epoch: 52\tTotal Loss: 146.5747\t Avg Loss: 0.0016\tCorrect: 79236/88956\tPercentage Correct: 89.07\n",
      "====> Val Loss: 23.6776\t Avg Loss: 0.0024\tCorrect: 8421/9885\tPercentage Correct: 85.19\n",
      "====> Test Loss: 57.9149\t Avg Loss: 0.0023\tCorrect: 21177/24711\tPercentage Correct: 85.70\n",
      "Train Epoch: 53\t[5000/88956 (6%)]\tTotal Loss: 8.6831\tAvg Loss: 0.0017\n",
      "Train Epoch: 53\t[10000/88956 (11%)]\tTotal Loss: 16.4270\tAvg Loss: 0.0016\n",
      "Train Epoch: 53\t[15000/88956 (17%)]\tTotal Loss: 24.6950\tAvg Loss: 0.0016\n",
      "Train Epoch: 53\t[20000/88956 (22%)]\tTotal Loss: 33.0809\tAvg Loss: 0.0017\n",
      "Train Epoch: 53\t[25000/88956 (28%)]\tTotal Loss: 41.2221\tAvg Loss: 0.0016\n",
      "Train Epoch: 53\t[30000/88956 (34%)]\tTotal Loss: 49.4531\tAvg Loss: 0.0016\n",
      "Train Epoch: 53\t[35000/88956 (39%)]\tTotal Loss: 58.1374\tAvg Loss: 0.0017\n",
      "Train Epoch: 53\t[40000/88956 (45%)]\tTotal Loss: 66.7181\tAvg Loss: 0.0017\n",
      "Train Epoch: 53\t[45000/88956 (51%)]\tTotal Loss: 74.6703\tAvg Loss: 0.0017\n",
      "Train Epoch: 53\t[50000/88956 (56%)]\tTotal Loss: 82.4568\tAvg Loss: 0.0016\n",
      "Train Epoch: 53\t[55000/88956 (62%)]\tTotal Loss: 90.3248\tAvg Loss: 0.0016\n",
      "Train Epoch: 53\t[60000/88956 (67%)]\tTotal Loss: 98.0171\tAvg Loss: 0.0016\n",
      "Train Epoch: 53\t[65000/88956 (73%)]\tTotal Loss: 106.2906\tAvg Loss: 0.0016\n",
      "Train Epoch: 53\t[70000/88956 (79%)]\tTotal Loss: 114.2198\tAvg Loss: 0.0016\n",
      "Train Epoch: 53\t[75000/88956 (84%)]\tTotal Loss: 122.7551\tAvg Loss: 0.0016\n",
      "Train Epoch: 53\t[80000/88956 (90%)]\tTotal Loss: 131.0881\tAvg Loss: 0.0016\n",
      "Train Epoch: 53\t[85000/88956 (96%)]\tTotal Loss: 139.1289\tAvg Loss: 0.0016\n",
      "====> Epoch: 53\tTotal Loss: 145.2024\t Avg Loss: 0.0016\tCorrect: 79259/88956\tPercentage Correct: 89.10\n",
      "====> Val Loss: 27.9108\t Avg Loss: 0.0028\tCorrect: 8384/9885\tPercentage Correct: 84.82\n",
      "====> Test Loss: 69.8318\t Avg Loss: 0.0028\tCorrect: 21069/24711\tPercentage Correct: 85.26\n",
      "Train Epoch: 54\t[5000/88956 (6%)]\tTotal Loss: 8.3626\tAvg Loss: 0.0017\n",
      "Train Epoch: 54\t[10000/88956 (11%)]\tTotal Loss: 16.0739\tAvg Loss: 0.0016\n",
      "Train Epoch: 54\t[15000/88956 (17%)]\tTotal Loss: 24.0154\tAvg Loss: 0.0016\n",
      "Train Epoch: 54\t[20000/88956 (22%)]\tTotal Loss: 32.0083\tAvg Loss: 0.0016\n",
      "Train Epoch: 54\t[25000/88956 (28%)]\tTotal Loss: 40.0815\tAvg Loss: 0.0016\n",
      "Train Epoch: 54\t[30000/88956 (34%)]\tTotal Loss: 48.3311\tAvg Loss: 0.0016\n",
      "Train Epoch: 54\t[35000/88956 (39%)]\tTotal Loss: 56.1207\tAvg Loss: 0.0016\n",
      "Train Epoch: 54\t[40000/88956 (45%)]\tTotal Loss: 64.2246\tAvg Loss: 0.0016\n",
      "Train Epoch: 54\t[45000/88956 (51%)]\tTotal Loss: 72.4490\tAvg Loss: 0.0016\n",
      "Train Epoch: 54\t[50000/88956 (56%)]\tTotal Loss: 80.6981\tAvg Loss: 0.0016\n",
      "Train Epoch: 54\t[55000/88956 (62%)]\tTotal Loss: 88.9717\tAvg Loss: 0.0016\n",
      "Train Epoch: 54\t[60000/88956 (67%)]\tTotal Loss: 97.0013\tAvg Loss: 0.0016\n",
      "Train Epoch: 54\t[65000/88956 (73%)]\tTotal Loss: 105.2043\tAvg Loss: 0.0016\n",
      "Train Epoch: 54\t[70000/88956 (79%)]\tTotal Loss: 113.0962\tAvg Loss: 0.0016\n",
      "Train Epoch: 54\t[75000/88956 (84%)]\tTotal Loss: 121.4723\tAvg Loss: 0.0016\n",
      "Train Epoch: 54\t[80000/88956 (90%)]\tTotal Loss: 129.9571\tAvg Loss: 0.0016\n",
      "Train Epoch: 54\t[85000/88956 (96%)]\tTotal Loss: 138.2451\tAvg Loss: 0.0016\n",
      "====> Epoch: 54\tTotal Loss: 144.3192\t Avg Loss: 0.0016\tCorrect: 79396/88956\tPercentage Correct: 89.25\n",
      "====> Val Loss: 25.6433\t Avg Loss: 0.0026\tCorrect: 8417/9885\tPercentage Correct: 85.15\n",
      "====> Test Loss: 67.9410\t Avg Loss: 0.0027\tCorrect: 21118/24711\tPercentage Correct: 85.46\n",
      "Train Epoch: 55\t[5000/88956 (6%)]\tTotal Loss: 8.1517\tAvg Loss: 0.0016\n",
      "Train Epoch: 55\t[10000/88956 (11%)]\tTotal Loss: 16.1797\tAvg Loss: 0.0016\n",
      "Train Epoch: 55\t[15000/88956 (17%)]\tTotal Loss: 24.2405\tAvg Loss: 0.0016\n",
      "Train Epoch: 55\t[20000/88956 (22%)]\tTotal Loss: 32.1790\tAvg Loss: 0.0016\n",
      "Train Epoch: 55\t[25000/88956 (28%)]\tTotal Loss: 40.3486\tAvg Loss: 0.0016\n",
      "Train Epoch: 55\t[30000/88956 (34%)]\tTotal Loss: 48.6782\tAvg Loss: 0.0016\n",
      "Train Epoch: 55\t[35000/88956 (39%)]\tTotal Loss: 56.7684\tAvg Loss: 0.0016\n",
      "Train Epoch: 55\t[40000/88956 (45%)]\tTotal Loss: 64.5224\tAvg Loss: 0.0016\n",
      "Train Epoch: 55\t[45000/88956 (51%)]\tTotal Loss: 73.0644\tAvg Loss: 0.0016\n",
      "Train Epoch: 55\t[50000/88956 (56%)]\tTotal Loss: 81.5391\tAvg Loss: 0.0016\n",
      "Train Epoch: 55\t[55000/88956 (62%)]\tTotal Loss: 90.0052\tAvg Loss: 0.0016\n",
      "Train Epoch: 55\t[60000/88956 (67%)]\tTotal Loss: 98.6803\tAvg Loss: 0.0016\n",
      "Train Epoch: 55\t[65000/88956 (73%)]\tTotal Loss: 106.8693\tAvg Loss: 0.0016\n",
      "Train Epoch: 55\t[70000/88956 (79%)]\tTotal Loss: 115.5387\tAvg Loss: 0.0017\n",
      "Train Epoch: 55\t[75000/88956 (84%)]\tTotal Loss: 123.8052\tAvg Loss: 0.0017\n",
      "Train Epoch: 55\t[80000/88956 (90%)]\tTotal Loss: 131.8441\tAvg Loss: 0.0016\n",
      "Train Epoch: 55\t[85000/88956 (96%)]\tTotal Loss: 140.0610\tAvg Loss: 0.0016\n",
      "====> Epoch: 55\tTotal Loss: 146.8894\t Avg Loss: 0.0017\tCorrect: 79255/88956\tPercentage Correct: 89.09\n",
      "====> Val Loss: 175.5798\t Avg Loss: 0.0178\tCorrect: 6778/9885\tPercentage Correct: 68.57\n",
      "====> Test Loss: 452.9869\t Avg Loss: 0.0183\tCorrect: 16816/24711\tPercentage Correct: 68.05\n",
      "Train Epoch: 56\t[5000/88956 (6%)]\tTotal Loss: 8.3591\tAvg Loss: 0.0017\n",
      "Train Epoch: 56\t[10000/88956 (11%)]\tTotal Loss: 16.4943\tAvg Loss: 0.0016\n",
      "Train Epoch: 56\t[15000/88956 (17%)]\tTotal Loss: 24.4450\tAvg Loss: 0.0016\n",
      "Train Epoch: 56\t[20000/88956 (22%)]\tTotal Loss: 32.7355\tAvg Loss: 0.0016\n",
      "Train Epoch: 56\t[25000/88956 (28%)]\tTotal Loss: 40.8614\tAvg Loss: 0.0016\n",
      "Train Epoch: 56\t[30000/88956 (34%)]\tTotal Loss: 48.3922\tAvg Loss: 0.0016\n",
      "Train Epoch: 56\t[35000/88956 (39%)]\tTotal Loss: 56.6992\tAvg Loss: 0.0016\n",
      "Train Epoch: 56\t[40000/88956 (45%)]\tTotal Loss: 64.3952\tAvg Loss: 0.0016\n",
      "Train Epoch: 56\t[45000/88956 (51%)]\tTotal Loss: 72.4490\tAvg Loss: 0.0016\n",
      "Train Epoch: 56\t[50000/88956 (56%)]\tTotal Loss: 80.9516\tAvg Loss: 0.0016\n",
      "Train Epoch: 56\t[55000/88956 (62%)]\tTotal Loss: 89.2811\tAvg Loss: 0.0016\n",
      "Train Epoch: 56\t[60000/88956 (67%)]\tTotal Loss: 97.6570\tAvg Loss: 0.0016\n",
      "Train Epoch: 56\t[65000/88956 (73%)]\tTotal Loss: 105.9515\tAvg Loss: 0.0016\n",
      "Train Epoch: 56\t[70000/88956 (79%)]\tTotal Loss: 113.7193\tAvg Loss: 0.0016\n",
      "Train Epoch: 56\t[75000/88956 (84%)]\tTotal Loss: 121.6004\tAvg Loss: 0.0016\n",
      "Train Epoch: 56\t[80000/88956 (90%)]\tTotal Loss: 130.1130\tAvg Loss: 0.0016\n",
      "Train Epoch: 56\t[85000/88956 (96%)]\tTotal Loss: 138.7047\tAvg Loss: 0.0016\n",
      "====> Epoch: 56\tTotal Loss: 145.4096\t Avg Loss: 0.0016\tCorrect: 79194/88956\tPercentage Correct: 89.03\n",
      "====> Val Loss: 28.4722\t Avg Loss: 0.0029\tCorrect: 8398/9885\tPercentage Correct: 84.96\n",
      "====> Test Loss: 71.1520\t Avg Loss: 0.0029\tCorrect: 20929/24711\tPercentage Correct: 84.70\n",
      "Train Epoch: 57\t[5000/88956 (6%)]\tTotal Loss: 8.3875\tAvg Loss: 0.0017\n",
      "Train Epoch: 57\t[10000/88956 (11%)]\tTotal Loss: 16.2529\tAvg Loss: 0.0016\n",
      "Train Epoch: 57\t[15000/88956 (17%)]\tTotal Loss: 23.9086\tAvg Loss: 0.0016\n",
      "Train Epoch: 57\t[20000/88956 (22%)]\tTotal Loss: 31.9749\tAvg Loss: 0.0016\n",
      "Train Epoch: 57\t[25000/88956 (28%)]\tTotal Loss: 39.7736\tAvg Loss: 0.0016\n",
      "Train Epoch: 57\t[30000/88956 (34%)]\tTotal Loss: 48.0189\tAvg Loss: 0.0016\n",
      "Train Epoch: 57\t[35000/88956 (39%)]\tTotal Loss: 56.0571\tAvg Loss: 0.0016\n",
      "Train Epoch: 57\t[40000/88956 (45%)]\tTotal Loss: 64.1390\tAvg Loss: 0.0016\n",
      "Train Epoch: 57\t[45000/88956 (51%)]\tTotal Loss: 72.2728\tAvg Loss: 0.0016\n",
      "Train Epoch: 57\t[50000/88956 (56%)]\tTotal Loss: 80.0105\tAvg Loss: 0.0016\n",
      "Train Epoch: 57\t[55000/88956 (62%)]\tTotal Loss: 88.2025\tAvg Loss: 0.0016\n",
      "Train Epoch: 57\t[60000/88956 (67%)]\tTotal Loss: 96.7158\tAvg Loss: 0.0016\n",
      "Train Epoch: 57\t[65000/88956 (73%)]\tTotal Loss: 104.6412\tAvg Loss: 0.0016\n",
      "Train Epoch: 57\t[70000/88956 (79%)]\tTotal Loss: 112.6262\tAvg Loss: 0.0016\n",
      "Train Epoch: 57\t[75000/88956 (84%)]\tTotal Loss: 120.9252\tAvg Loss: 0.0016\n",
      "Train Epoch: 57\t[80000/88956 (90%)]\tTotal Loss: 129.1116\tAvg Loss: 0.0016\n",
      "Train Epoch: 57\t[85000/88956 (96%)]\tTotal Loss: 137.1499\tAvg Loss: 0.0016\n",
      "====> Epoch: 57\tTotal Loss: 143.6873\t Avg Loss: 0.0016\tCorrect: 79470/88956\tPercentage Correct: 89.34\n",
      "====> Val Loss: 22.2609\t Avg Loss: 0.0023\tCorrect: 8486/9885\tPercentage Correct: 85.85\n",
      "====> Test Loss: 56.0790\t Avg Loss: 0.0023\tCorrect: 21333/24711\tPercentage Correct: 86.33\n",
      "Train Epoch: 58\t[5000/88956 (6%)]\tTotal Loss: 8.4006\tAvg Loss: 0.0017\n",
      "Train Epoch: 58\t[10000/88956 (11%)]\tTotal Loss: 16.6516\tAvg Loss: 0.0017\n",
      "Train Epoch: 58\t[15000/88956 (17%)]\tTotal Loss: 24.7457\tAvg Loss: 0.0016\n",
      "Train Epoch: 58\t[20000/88956 (22%)]\tTotal Loss: 32.5888\tAvg Loss: 0.0016\n",
      "Train Epoch: 58\t[25000/88956 (28%)]\tTotal Loss: 40.4371\tAvg Loss: 0.0016\n",
      "Train Epoch: 58\t[30000/88956 (34%)]\tTotal Loss: 48.7513\tAvg Loss: 0.0016\n",
      "Train Epoch: 58\t[35000/88956 (39%)]\tTotal Loss: 57.5768\tAvg Loss: 0.0016\n",
      "Train Epoch: 58\t[40000/88956 (45%)]\tTotal Loss: 66.1350\tAvg Loss: 0.0017\n",
      "Train Epoch: 58\t[45000/88956 (51%)]\tTotal Loss: 73.8494\tAvg Loss: 0.0016\n",
      "Train Epoch: 58\t[50000/88956 (56%)]\tTotal Loss: 82.1393\tAvg Loss: 0.0016\n",
      "Train Epoch: 58\t[55000/88956 (62%)]\tTotal Loss: 90.2976\tAvg Loss: 0.0016\n",
      "Train Epoch: 58\t[60000/88956 (67%)]\tTotal Loss: 98.7207\tAvg Loss: 0.0016\n",
      "Train Epoch: 58\t[65000/88956 (73%)]\tTotal Loss: 106.8576\tAvg Loss: 0.0016\n",
      "Train Epoch: 58\t[70000/88956 (79%)]\tTotal Loss: 114.9902\tAvg Loss: 0.0016\n",
      "Train Epoch: 58\t[75000/88956 (84%)]\tTotal Loss: 122.8086\tAvg Loss: 0.0016\n",
      "Train Epoch: 58\t[80000/88956 (90%)]\tTotal Loss: 131.0100\tAvg Loss: 0.0016\n",
      "Train Epoch: 58\t[85000/88956 (96%)]\tTotal Loss: 138.7998\tAvg Loss: 0.0016\n",
      "====> Epoch: 58\tTotal Loss: 145.2710\t Avg Loss: 0.0016\tCorrect: 79191/88956\tPercentage Correct: 89.02\n",
      "====> Val Loss: 23.5099\t Avg Loss: 0.0024\tCorrect: 8583/9885\tPercentage Correct: 86.83\n",
      "====> Test Loss: 58.8414\t Avg Loss: 0.0024\tCorrect: 21514/24711\tPercentage Correct: 87.06\n",
      "Train Epoch: 59\t[5000/88956 (6%)]\tTotal Loss: 8.4493\tAvg Loss: 0.0017\n",
      "Train Epoch: 59\t[10000/88956 (11%)]\tTotal Loss: 16.0029\tAvg Loss: 0.0016\n",
      "Train Epoch: 59\t[15000/88956 (17%)]\tTotal Loss: 24.4576\tAvg Loss: 0.0016\n",
      "Train Epoch: 59\t[20000/88956 (22%)]\tTotal Loss: 32.3432\tAvg Loss: 0.0016\n",
      "Train Epoch: 59\t[25000/88956 (28%)]\tTotal Loss: 40.1980\tAvg Loss: 0.0016\n",
      "Train Epoch: 59\t[30000/88956 (34%)]\tTotal Loss: 48.2540\tAvg Loss: 0.0016\n",
      "Train Epoch: 59\t[35000/88956 (39%)]\tTotal Loss: 56.0873\tAvg Loss: 0.0016\n",
      "Train Epoch: 59\t[40000/88956 (45%)]\tTotal Loss: 64.1764\tAvg Loss: 0.0016\n",
      "Train Epoch: 59\t[45000/88956 (51%)]\tTotal Loss: 72.2129\tAvg Loss: 0.0016\n",
      "Train Epoch: 59\t[50000/88956 (56%)]\tTotal Loss: 80.4603\tAvg Loss: 0.0016\n",
      "Train Epoch: 59\t[55000/88956 (62%)]\tTotal Loss: 88.8869\tAvg Loss: 0.0016\n",
      "Train Epoch: 59\t[60000/88956 (67%)]\tTotal Loss: 96.8712\tAvg Loss: 0.0016\n",
      "Train Epoch: 59\t[65000/88956 (73%)]\tTotal Loss: 104.7446\tAvg Loss: 0.0016\n",
      "Train Epoch: 59\t[70000/88956 (79%)]\tTotal Loss: 113.1033\tAvg Loss: 0.0016\n",
      "Train Epoch: 59\t[75000/88956 (84%)]\tTotal Loss: 121.7354\tAvg Loss: 0.0016\n",
      "Train Epoch: 59\t[80000/88956 (90%)]\tTotal Loss: 129.9029\tAvg Loss: 0.0016\n",
      "Train Epoch: 59\t[85000/88956 (96%)]\tTotal Loss: 137.8162\tAvg Loss: 0.0016\n",
      "====> Epoch: 59\tTotal Loss: 143.9487\t Avg Loss: 0.0016\tCorrect: 79415/88956\tPercentage Correct: 89.27\n",
      "====> Val Loss: 36.9697\t Avg Loss: 0.0037\tCorrect: 8208/9885\tPercentage Correct: 83.03\n",
      "====> Test Loss: 90.1237\t Avg Loss: 0.0036\tCorrect: 20621/24711\tPercentage Correct: 83.45\n",
      "Train Epoch: 60\t[5000/88956 (6%)]\tTotal Loss: 7.9357\tAvg Loss: 0.0016\n",
      "Train Epoch: 60\t[10000/88956 (11%)]\tTotal Loss: 15.7196\tAvg Loss: 0.0016\n",
      "Train Epoch: 60\t[15000/88956 (17%)]\tTotal Loss: 23.7270\tAvg Loss: 0.0016\n",
      "Train Epoch: 60\t[20000/88956 (22%)]\tTotal Loss: 31.1955\tAvg Loss: 0.0016\n",
      "Train Epoch: 60\t[25000/88956 (28%)]\tTotal Loss: 39.0556\tAvg Loss: 0.0016\n",
      "Train Epoch: 60\t[30000/88956 (34%)]\tTotal Loss: 46.9926\tAvg Loss: 0.0016\n",
      "Train Epoch: 60\t[35000/88956 (39%)]\tTotal Loss: 55.0717\tAvg Loss: 0.0016\n",
      "Train Epoch: 60\t[40000/88956 (45%)]\tTotal Loss: 63.2214\tAvg Loss: 0.0016\n",
      "Train Epoch: 60\t[45000/88956 (51%)]\tTotal Loss: 71.1219\tAvg Loss: 0.0016\n",
      "Train Epoch: 60\t[50000/88956 (56%)]\tTotal Loss: 79.0636\tAvg Loss: 0.0016\n",
      "Train Epoch: 60\t[55000/88956 (62%)]\tTotal Loss: 86.7568\tAvg Loss: 0.0016\n",
      "Train Epoch: 60\t[60000/88956 (67%)]\tTotal Loss: 95.0836\tAvg Loss: 0.0016\n",
      "Train Epoch: 60\t[65000/88956 (73%)]\tTotal Loss: 103.4617\tAvg Loss: 0.0016\n",
      "Train Epoch: 60\t[70000/88956 (79%)]\tTotal Loss: 111.7102\tAvg Loss: 0.0016\n",
      "Train Epoch: 60\t[75000/88956 (84%)]\tTotal Loss: 119.8855\tAvg Loss: 0.0016\n",
      "Train Epoch: 60\t[80000/88956 (90%)]\tTotal Loss: 128.3264\tAvg Loss: 0.0016\n",
      "Train Epoch: 60\t[85000/88956 (96%)]\tTotal Loss: 136.3984\tAvg Loss: 0.0016\n",
      "====> Epoch: 60\tTotal Loss: 143.0125\t Avg Loss: 0.0016\tCorrect: 79357/88956\tPercentage Correct: 89.21\n",
      "====> Val Loss: 47.6412\t Avg Loss: 0.0048\tCorrect: 7994/9885\tPercentage Correct: 80.87\n",
      "====> Test Loss: 119.3327\t Avg Loss: 0.0048\tCorrect: 20138/24711\tPercentage Correct: 81.49\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fd61924e012d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     train_loss, train_correct, train_results = trainer.train_fx_net(\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfxnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_fxnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Marco/Documents/GOOGLE DRIVE/PHD/REPOS/gfx_classifier_2/gfx_classifier_2/src/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain_fx_net\u001b[0;34m(model, optimizer, train_loader, train_sampler, epoch, loss_function, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# zero gradients otherwise get accumulated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# calculate gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Marco/Documents/GOOGLE DRIVE/PHD/REPOS/gfx_classifier_2/venv/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Marco/Documents/GOOGLE DRIVE/PHD/REPOS/gfx_classifier_2/venv/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TRAIN and TEST FxNet OVER MULTIPLE EPOCHS\n",
    "train_set_size = len(split.train_sampler)\n",
    "val_set_size = len(split.val_sampler)\n",
    "test_set_size = len(split.test_sampler)\n",
    "\n",
    "all_train_losses, all_val_losses, all_test_losses = [],[],[]\n",
    "all_train_correct, all_val_correct, all_test_correct = [],[],[]\n",
    "all_train_results, all_val_results, all_test_results = [],[],[]\n",
    "\n",
    "best_val_correct = 0\n",
    "early_stop_counter = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss, train_correct, train_results = trainer.train_fx_net(\n",
    "        model=fxnet,\n",
    "        optimizer=optimizer_fxnet, \n",
    "        train_loader=train_loader, \n",
    "        train_sampler=split.train_sampler, \n",
    "        epoch=epoch, \n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    val_loss, val_correct, val_results = trainer.val_fx_net(\n",
    "        model=fxnet, \n",
    "        val_loader=val_loader, \n",
    "        val_sampler=split.val_sampler, \n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    test_loss, test_correct, test_results = trainer.test_fx_net(\n",
    "        model=fxnet, \n",
    "        test_loader=test_loader, \n",
    "        test_sampler=split.test_sampler, \n",
    "        device=device\n",
    "    )\n",
    "    # save model\n",
    "    if val_correct > best_val_correct:\n",
    "        best_val_correct = val_correct\n",
    "        torch.save(fxnet, '%s/%s' % (models_folder, model_name))\n",
    "        early_stop_counter = 0\n",
    "        print('\\n=== saved best model ===\\n')\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        \n",
    "    # append results\n",
    "    all_train_losses.append(train_loss)\n",
    "    all_val_losses.append(val_loss)\n",
    "    all_test_losses.append(test_loss)\n",
    "    \n",
    "    all_train_correct.append(train_correct)\n",
    "    all_val_correct.append(val_correct)\n",
    "    all_test_correct.append(test_correct)\n",
    "    \n",
    "    all_train_results.append(train_results)\n",
    "    all_val_results.append(val_results)\n",
    "    all_test_results.append(test_results)\n",
    "\n",
    "    if early_stop_counter == 15:\n",
    "        print('\\n--- early stop ---\\n')\n",
    "        break\n",
    "\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy:  89.33630109267503\nEpoch:  57\n\nAccuracy:  86.89934243803744\nEpoch:  32\n\nAccuracy:  87.0624418275262\nEpoch:  58\n\n"
     ]
    }
   ],
   "source": [
    "# BEST RESULTS\n",
    "print('Accuracy: ', 100 * max(all_train_correct) / train_set_size)\n",
    "print('Epoch: ', np.argmax(all_train_correct))\n",
    "print()\n",
    "print('Accuracy: ', 100 * max(all_val_correct) / val_set_size)\n",
    "print('Epoch: ', np.argmax(all_val_correct))\n",
    "print()\n",
    "print('Accuracy: ', 100 * max(all_test_correct) / test_set_size)\n",
    "print('Epoch: ', np.argmax(all_test_correct))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE RESULTS - all losses, all correct, best results\n",
    "all_train_losses_npy = np.array(all_train_losses)\n",
    "all_train_correct_npy = np.array(all_train_correct)\n",
    "best_train_results_npy = np.array(all_train_results[32])\n",
    "\n",
    "all_val_losses_npy = np.array(all_val_losses)\n",
    "all_val_correct_npy = np.array(all_val_correct)\n",
    "best_val_results_npy = np.array(all_val_results[32])\n",
    "\n",
    "all_test_losses_npy = np.array(all_test_losses)\n",
    "all_test_correct_npy = np.array(all_test_correct)\n",
    "best_test_results_npy = np.array(all_test_results[32])\n",
    "\n",
    "fx_labels_npy = np.array(list(dataset.fx_to_label.keys()))\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_train_losses')), arr=all_train_losses_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_train_correct')), arr=all_train_correct_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'best_train_results')), arr=best_train_results_npy)\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_val_losses')), arr=all_val_losses_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_val_correct')), arr=all_val_correct_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'best_val_results')), arr=best_val_results_npy)\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_test_losses')), arr=all_test_losses_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_test_correct')), arr=all_test_correct_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'best_test_results')), arr=best_test_results_npy)\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'fx_labels')), arr=fx_labels_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('venv')",
   "display_name": "Python 3.8.5 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "da4eaf7a9185e3501df7afd22cc190d755d8240551460f68877bb66ec170b6fc"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}