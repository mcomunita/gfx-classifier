{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import dataset.dataset as dataset\n",
    "import datasplit.datasplit as datasplit\n",
    "import model.models as models\n",
    "import trainer.trainer as trainer\n",
    "import utils.utils as utils\n",
    "\n",
    "torch.cuda.device_count()\n",
    "cuda0 = torch.device('cuda:0')\n",
    "cuda1 = torch.device('cuda:1')\n",
    "cuda2 = torch.device('cuda:2')\n",
    "cuda3 = torch.device('cuda:3')\n",
    "device = torch.device(cuda0 if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "source": [
    "# INIT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dataset size:  111072\ntrain set size:  79971\nval set size:  8886\ntest set size:  22215\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'808': 0,\n",
       " 'BD2': 1,\n",
       " 'BMF': 2,\n",
       " 'DPL': 3,\n",
       " 'DS1': 4,\n",
       " 'FFC': 5,\n",
       " 'MGS': 6,\n",
       " 'OD1': 7,\n",
       " 'RAT': 8,\n",
       " 'RBM': 9,\n",
       " 'SD1': 10,\n",
       " 'VTB': 11}"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# transforms\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "# dataset\n",
    "root = '/Volumes/Macintosh HD/DATASETS/GUITAR-FX/Mono_Discrete'\n",
    "excl_folders = ['TS9','MT2'] # effects to exclude from the dataset\n",
    "spectra_folder= 'mel_22050_1024_512' # folder containing features\n",
    "proc_settings_csv = 'proc_settings.csv'\n",
    "max_num_settings=3 # maximum number of controls across dataset (e.g. [level, gain, tone] = 3)\n",
    "\n",
    "dataset = dataset.FxDataset(root=root,\n",
    "                            excl_folders=excl_folders, \n",
    "                            spectra_folder=spectra_folder, \n",
    "                            processed_settings_csv=proc_settings_csv,\n",
    "                            max_num_settings=max_num_settings,\n",
    "                            transform=transform)\n",
    "# initialise data structures\n",
    "dataset.init_dataset()\n",
    "# generate mel features - necessary only the first time\n",
    "# dataset.generate_mel()\n",
    "\n",
    "# split\n",
    "# set test_train_split=0.0 and val_train_split=0.0 to test pre-trained model\n",
    "split = datasplit.DataSplit(dataset, test_train_split=0.8, val_train_split=0.1, shuffle=True)\n",
    "\n",
    "# loaders\n",
    "train_loader, val_loader, test_loader = split.get_split(batch_size=100)\n",
    "\n",
    "print('dataset size: ', len(dataset))\n",
    "print('train set size: ', len(split.train_sampler))\n",
    "print('val set size: ', len(split.val_sampler))\n",
    "print('test set size: ', len(split.test_sampler))\n",
    "dataset.fx_to_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN FxNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FxNet(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (batchNorm1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n  (batchNorm2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (fc1): Linear(in_features=6264, out_features=120, bias=True)\n  (batchNorm3): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (fc2): Linear(in_features=120, out_features=60, bias=True)\n  (batchNorm4): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (out): Linear(in_features=60, out_features=12, bias=True)\n)\nTrainable Params:  762156\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "fxnet = models.FxNet(n_classes=dataset.num_fx).to(device)\n",
    "# optimizer\n",
    "optimizer_fxnet = optim.Adam(fxnet.parameters(), lr=0.001)\n",
    "# loss function\n",
    "loss_func_fxnet = nn.CrossEntropyLoss()\n",
    "\n",
    "print(fxnet)\n",
    "print('Trainable Params: ', sum(p.numel() for p in fxnet.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE\n",
    "models_folder = '../../models_and_results/models'\n",
    "model_name = '20201210_fxnet_mono_disc_noTS9_best'\n",
    "results_folder = '../../models_and_results/results'\n",
    "results_subfolder = '20201210_fxnet_mono_disc_noTS9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 0\t[5000/79971 (6%)]\tTotal Loss: 96.6142\tAvg Loss: 0.0193\n",
      "Train Epoch: 0\t[10000/79971 (12%)]\tTotal Loss: 163.1267\tAvg Loss: 0.0163\n",
      "Train Epoch: 0\t[15000/79971 (19%)]\tTotal Loss: 215.7511\tAvg Loss: 0.0144\n",
      "Train Epoch: 0\t[20000/79971 (25%)]\tTotal Loss: 258.6821\tAvg Loss: 0.0129\n",
      "Train Epoch: 0\t[25000/79971 (31%)]\tTotal Loss: 294.8609\tAvg Loss: 0.0118\n",
      "Train Epoch: 0\t[30000/79971 (38%)]\tTotal Loss: 325.4680\tAvg Loss: 0.0108\n",
      "Train Epoch: 0\t[35000/79971 (44%)]\tTotal Loss: 352.5878\tAvg Loss: 0.0101\n",
      "Train Epoch: 0\t[40000/79971 (50%)]\tTotal Loss: 377.3034\tAvg Loss: 0.0094\n",
      "Train Epoch: 0\t[45000/79971 (56%)]\tTotal Loss: 398.6025\tAvg Loss: 0.0089\n",
      "Train Epoch: 0\t[50000/79971 (62%)]\tTotal Loss: 418.1186\tAvg Loss: 0.0084\n",
      "Train Epoch: 0\t[55000/79971 (69%)]\tTotal Loss: 436.4407\tAvg Loss: 0.0079\n",
      "Train Epoch: 0\t[60000/79971 (75%)]\tTotal Loss: 454.4711\tAvg Loss: 0.0076\n",
      "Train Epoch: 0\t[65000/79971 (81%)]\tTotal Loss: 470.8507\tAvg Loss: 0.0072\n",
      "Train Epoch: 0\t[70000/79971 (88%)]\tTotal Loss: 486.3488\tAvg Loss: 0.0069\n",
      "Train Epoch: 0\t[75000/79971 (94%)]\tTotal Loss: 501.0130\tAvg Loss: 0.0067\n",
      "====> Epoch: 0\tTotal Loss: 514.4574\t Avg Loss: 0.0064\tCorrect: 63351/79971\tPercentage Correct: 79.22\n",
      "====> Val Loss: 27.8047\t Avg Loss: 0.0031\tCorrect: 7898/8886\tPercentage Correct: 88.88\n",
      "====> Test Loss: 72.9213\t Avg Loss: 0.0033\tCorrect: 19647/22215\tPercentage Correct: 88.44\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 1\t[5000/79971 (6%)]\tTotal Loss: 12.6206\tAvg Loss: 0.0025\n",
      "Train Epoch: 1\t[10000/79971 (12%)]\tTotal Loss: 24.4632\tAvg Loss: 0.0024\n",
      "Train Epoch: 1\t[15000/79971 (19%)]\tTotal Loss: 35.6695\tAvg Loss: 0.0024\n",
      "Train Epoch: 1\t[20000/79971 (25%)]\tTotal Loss: 46.8522\tAvg Loss: 0.0023\n",
      "Train Epoch: 1\t[25000/79971 (31%)]\tTotal Loss: 57.0173\tAvg Loss: 0.0023\n",
      "Train Epoch: 1\t[30000/79971 (38%)]\tTotal Loss: 67.0288\tAvg Loss: 0.0022\n",
      "Train Epoch: 1\t[35000/79971 (44%)]\tTotal Loss: 76.5685\tAvg Loss: 0.0022\n",
      "Train Epoch: 1\t[40000/79971 (50%)]\tTotal Loss: 87.1656\tAvg Loss: 0.0022\n",
      "Train Epoch: 1\t[45000/79971 (56%)]\tTotal Loss: 97.2010\tAvg Loss: 0.0022\n",
      "Train Epoch: 1\t[50000/79971 (62%)]\tTotal Loss: 107.1022\tAvg Loss: 0.0021\n",
      "Train Epoch: 1\t[55000/79971 (69%)]\tTotal Loss: 117.1414\tAvg Loss: 0.0021\n",
      "Train Epoch: 1\t[60000/79971 (75%)]\tTotal Loss: 126.0394\tAvg Loss: 0.0021\n",
      "Train Epoch: 1\t[65000/79971 (81%)]\tTotal Loss: 135.3755\tAvg Loss: 0.0021\n",
      "Train Epoch: 1\t[70000/79971 (88%)]\tTotal Loss: 144.1931\tAvg Loss: 0.0021\n",
      "Train Epoch: 1\t[75000/79971 (94%)]\tTotal Loss: 153.0660\tAvg Loss: 0.0020\n",
      "====> Epoch: 1\tTotal Loss: 161.2737\t Avg Loss: 0.0020\tCorrect: 74346/79971\tPercentage Correct: 92.97\n",
      "====> Val Loss: 149.1368\t Avg Loss: 0.0168\tCorrect: 5276/8886\tPercentage Correct: 59.37\n",
      "====> Test Loss: 372.9706\t Avg Loss: 0.0168\tCorrect: 13255/22215\tPercentage Correct: 59.67\n",
      "Train Epoch: 2\t[5000/79971 (6%)]\tTotal Loss: 6.9508\tAvg Loss: 0.0014\n",
      "Train Epoch: 2\t[10000/79971 (12%)]\tTotal Loss: 14.2392\tAvg Loss: 0.0014\n",
      "Train Epoch: 2\t[15000/79971 (19%)]\tTotal Loss: 21.3028\tAvg Loss: 0.0014\n",
      "Train Epoch: 2\t[20000/79971 (25%)]\tTotal Loss: 28.9091\tAvg Loss: 0.0014\n",
      "Train Epoch: 2\t[25000/79971 (31%)]\tTotal Loss: 36.2430\tAvg Loss: 0.0014\n",
      "Train Epoch: 2\t[30000/79971 (38%)]\tTotal Loss: 43.0406\tAvg Loss: 0.0014\n",
      "Train Epoch: 2\t[35000/79971 (44%)]\tTotal Loss: 49.7060\tAvg Loss: 0.0014\n",
      "Train Epoch: 2\t[40000/79971 (50%)]\tTotal Loss: 58.1784\tAvg Loss: 0.0015\n",
      "Train Epoch: 2\t[45000/79971 (56%)]\tTotal Loss: 65.0929\tAvg Loss: 0.0014\n",
      "Train Epoch: 2\t[50000/79971 (62%)]\tTotal Loss: 72.3784\tAvg Loss: 0.0014\n",
      "Train Epoch: 2\t[55000/79971 (69%)]\tTotal Loss: 79.3066\tAvg Loss: 0.0014\n",
      "Train Epoch: 2\t[60000/79971 (75%)]\tTotal Loss: 85.8430\tAvg Loss: 0.0014\n",
      "Train Epoch: 2\t[65000/79971 (81%)]\tTotal Loss: 92.5628\tAvg Loss: 0.0014\n",
      "Train Epoch: 2\t[70000/79971 (88%)]\tTotal Loss: 99.1307\tAvg Loss: 0.0014\n",
      "Train Epoch: 2\t[75000/79971 (94%)]\tTotal Loss: 105.7574\tAvg Loss: 0.0014\n",
      "====> Epoch: 2\tTotal Loss: 112.4433\t Avg Loss: 0.0014\tCorrect: 75809/79971\tPercentage Correct: 94.80\n",
      "====> Val Loss: 59.3628\t Avg Loss: 0.0067\tCorrect: 7150/8886\tPercentage Correct: 80.46\n",
      "====> Test Loss: 147.1385\t Avg Loss: 0.0066\tCorrect: 17839/22215\tPercentage Correct: 80.30\n",
      "Train Epoch: 3\t[5000/79971 (6%)]\tTotal Loss: 5.5973\tAvg Loss: 0.0011\n",
      "Train Epoch: 3\t[10000/79971 (12%)]\tTotal Loss: 11.5329\tAvg Loss: 0.0012\n",
      "Train Epoch: 3\t[15000/79971 (19%)]\tTotal Loss: 17.6690\tAvg Loss: 0.0012\n",
      "Train Epoch: 3\t[20000/79971 (25%)]\tTotal Loss: 23.0634\tAvg Loss: 0.0012\n",
      "Train Epoch: 3\t[25000/79971 (31%)]\tTotal Loss: 28.8717\tAvg Loss: 0.0012\n",
      "Train Epoch: 3\t[30000/79971 (38%)]\tTotal Loss: 35.0916\tAvg Loss: 0.0012\n",
      "Train Epoch: 3\t[35000/79971 (44%)]\tTotal Loss: 41.5515\tAvg Loss: 0.0012\n",
      "Train Epoch: 3\t[40000/79971 (50%)]\tTotal Loss: 47.4135\tAvg Loss: 0.0012\n",
      "Train Epoch: 3\t[45000/79971 (56%)]\tTotal Loss: 53.3330\tAvg Loss: 0.0012\n",
      "Train Epoch: 3\t[50000/79971 (62%)]\tTotal Loss: 58.9368\tAvg Loss: 0.0012\n",
      "Train Epoch: 3\t[55000/79971 (69%)]\tTotal Loss: 65.7168\tAvg Loss: 0.0012\n",
      "Train Epoch: 3\t[60000/79971 (75%)]\tTotal Loss: 72.0131\tAvg Loss: 0.0012\n",
      "Train Epoch: 3\t[65000/79971 (81%)]\tTotal Loss: 77.5620\tAvg Loss: 0.0012\n",
      "Train Epoch: 3\t[70000/79971 (88%)]\tTotal Loss: 82.9656\tAvg Loss: 0.0012\n",
      "Train Epoch: 3\t[75000/79971 (94%)]\tTotal Loss: 88.2427\tAvg Loss: 0.0012\n",
      "====> Epoch: 3\tTotal Loss: 94.0992\t Avg Loss: 0.0012\tCorrect: 76361/79971\tPercentage Correct: 95.49\n",
      "====> Val Loss: 67.6895\t Avg Loss: 0.0076\tCorrect: 6889/8886\tPercentage Correct: 77.53\n",
      "====> Test Loss: 177.2852\t Avg Loss: 0.0080\tCorrect: 17027/22215\tPercentage Correct: 76.65\n",
      "Train Epoch: 4\t[5000/79971 (6%)]\tTotal Loss: 5.0038\tAvg Loss: 0.0010\n",
      "Train Epoch: 4\t[10000/79971 (12%)]\tTotal Loss: 9.9474\tAvg Loss: 0.0010\n",
      "Train Epoch: 4\t[15000/79971 (19%)]\tTotal Loss: 14.7459\tAvg Loss: 0.0010\n",
      "Train Epoch: 4\t[20000/79971 (25%)]\tTotal Loss: 19.3565\tAvg Loss: 0.0010\n",
      "Train Epoch: 4\t[25000/79971 (31%)]\tTotal Loss: 23.9371\tAvg Loss: 0.0010\n",
      "Train Epoch: 4\t[30000/79971 (38%)]\tTotal Loss: 29.2469\tAvg Loss: 0.0010\n",
      "Train Epoch: 4\t[35000/79971 (44%)]\tTotal Loss: 34.3444\tAvg Loss: 0.0010\n",
      "Train Epoch: 4\t[40000/79971 (50%)]\tTotal Loss: 39.1479\tAvg Loss: 0.0010\n",
      "Train Epoch: 4\t[45000/79971 (56%)]\tTotal Loss: 44.7774\tAvg Loss: 0.0010\n",
      "Train Epoch: 4\t[50000/79971 (62%)]\tTotal Loss: 50.2087\tAvg Loss: 0.0010\n",
      "Train Epoch: 4\t[55000/79971 (69%)]\tTotal Loss: 55.4518\tAvg Loss: 0.0010\n",
      "Train Epoch: 4\t[60000/79971 (75%)]\tTotal Loss: 60.9089\tAvg Loss: 0.0010\n",
      "Train Epoch: 4\t[65000/79971 (81%)]\tTotal Loss: 66.0103\tAvg Loss: 0.0010\n",
      "Train Epoch: 4\t[70000/79971 (88%)]\tTotal Loss: 71.6064\tAvg Loss: 0.0010\n",
      "Train Epoch: 4\t[75000/79971 (94%)]\tTotal Loss: 76.8923\tAvg Loss: 0.0010\n",
      "====> Epoch: 4\tTotal Loss: 82.0486\t Avg Loss: 0.0010\tCorrect: 76735/79971\tPercentage Correct: 95.95\n",
      "====> Val Loss: 18.3785\t Avg Loss: 0.0021\tCorrect: 8249/8886\tPercentage Correct: 92.83\n",
      "====> Test Loss: 49.0377\t Avg Loss: 0.0022\tCorrect: 20443/22215\tPercentage Correct: 92.02\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 5\t[5000/79971 (6%)]\tTotal Loss: 4.6359\tAvg Loss: 0.0009\n",
      "Train Epoch: 5\t[10000/79971 (12%)]\tTotal Loss: 8.3794\tAvg Loss: 0.0008\n",
      "Train Epoch: 5\t[15000/79971 (19%)]\tTotal Loss: 12.7175\tAvg Loss: 0.0008\n",
      "Train Epoch: 5\t[20000/79971 (25%)]\tTotal Loss: 16.7525\tAvg Loss: 0.0008\n",
      "Train Epoch: 5\t[25000/79971 (31%)]\tTotal Loss: 20.9836\tAvg Loss: 0.0008\n",
      "Train Epoch: 5\t[30000/79971 (38%)]\tTotal Loss: 25.6430\tAvg Loss: 0.0009\n",
      "Train Epoch: 5\t[35000/79971 (44%)]\tTotal Loss: 30.3059\tAvg Loss: 0.0009\n",
      "Train Epoch: 5\t[40000/79971 (50%)]\tTotal Loss: 34.9460\tAvg Loss: 0.0009\n",
      "Train Epoch: 5\t[45000/79971 (56%)]\tTotal Loss: 40.0745\tAvg Loss: 0.0009\n",
      "Train Epoch: 5\t[50000/79971 (62%)]\tTotal Loss: 45.2878\tAvg Loss: 0.0009\n",
      "Train Epoch: 5\t[55000/79971 (69%)]\tTotal Loss: 51.0359\tAvg Loss: 0.0009\n",
      "Train Epoch: 5\t[60000/79971 (75%)]\tTotal Loss: 55.5480\tAvg Loss: 0.0009\n",
      "Train Epoch: 5\t[65000/79971 (81%)]\tTotal Loss: 60.7922\tAvg Loss: 0.0009\n",
      "Train Epoch: 5\t[70000/79971 (88%)]\tTotal Loss: 65.4166\tAvg Loss: 0.0009\n",
      "Train Epoch: 5\t[75000/79971 (94%)]\tTotal Loss: 70.0233\tAvg Loss: 0.0009\n",
      "====> Epoch: 5\tTotal Loss: 74.2207\t Avg Loss: 0.0009\tCorrect: 76969/79971\tPercentage Correct: 96.25\n",
      "====> Val Loss: 53.9905\t Avg Loss: 0.0061\tCorrect: 7399/8886\tPercentage Correct: 83.27\n",
      "====> Test Loss: 139.1779\t Avg Loss: 0.0063\tCorrect: 18410/22215\tPercentage Correct: 82.87\n",
      "Train Epoch: 6\t[5000/79971 (6%)]\tTotal Loss: 3.9129\tAvg Loss: 0.0008\n",
      "Train Epoch: 6\t[10000/79971 (12%)]\tTotal Loss: 7.6277\tAvg Loss: 0.0008\n",
      "Train Epoch: 6\t[15000/79971 (19%)]\tTotal Loss: 11.3284\tAvg Loss: 0.0008\n",
      "Train Epoch: 6\t[20000/79971 (25%)]\tTotal Loss: 15.2829\tAvg Loss: 0.0008\n",
      "Train Epoch: 6\t[25000/79971 (31%)]\tTotal Loss: 18.6695\tAvg Loss: 0.0007\n",
      "Train Epoch: 6\t[30000/79971 (38%)]\tTotal Loss: 22.5485\tAvg Loss: 0.0008\n",
      "Train Epoch: 6\t[35000/79971 (44%)]\tTotal Loss: 26.4884\tAvg Loss: 0.0008\n",
      "Train Epoch: 6\t[40000/79971 (50%)]\tTotal Loss: 30.5329\tAvg Loss: 0.0008\n",
      "Train Epoch: 6\t[45000/79971 (56%)]\tTotal Loss: 34.8211\tAvg Loss: 0.0008\n",
      "Train Epoch: 6\t[50000/79971 (62%)]\tTotal Loss: 39.3525\tAvg Loss: 0.0008\n",
      "Train Epoch: 6\t[55000/79971 (69%)]\tTotal Loss: 43.9141\tAvg Loss: 0.0008\n",
      "Train Epoch: 6\t[60000/79971 (75%)]\tTotal Loss: 48.1544\tAvg Loss: 0.0008\n",
      "Train Epoch: 6\t[65000/79971 (81%)]\tTotal Loss: 52.8307\tAvg Loss: 0.0008\n",
      "Train Epoch: 6\t[70000/79971 (88%)]\tTotal Loss: 56.9511\tAvg Loss: 0.0008\n",
      "Train Epoch: 6\t[75000/79971 (94%)]\tTotal Loss: 60.8028\tAvg Loss: 0.0008\n",
      "====> Epoch: 6\tTotal Loss: 65.1766\t Avg Loss: 0.0008\tCorrect: 77305/79971\tPercentage Correct: 96.67\n",
      "====> Val Loss: 9.1817\t Avg Loss: 0.0010\tCorrect: 8516/8886\tPercentage Correct: 95.84\n",
      "====> Test Loss: 24.5916\t Avg Loss: 0.0011\tCorrect: 21179/22215\tPercentage Correct: 95.34\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 7\t[5000/79971 (6%)]\tTotal Loss: 3.6963\tAvg Loss: 0.0007\n",
      "Train Epoch: 7\t[10000/79971 (12%)]\tTotal Loss: 7.1210\tAvg Loss: 0.0007\n",
      "Train Epoch: 7\t[15000/79971 (19%)]\tTotal Loss: 10.7283\tAvg Loss: 0.0007\n",
      "Train Epoch: 7\t[20000/79971 (25%)]\tTotal Loss: 13.7194\tAvg Loss: 0.0007\n",
      "Train Epoch: 7\t[25000/79971 (31%)]\tTotal Loss: 16.9594\tAvg Loss: 0.0007\n",
      "Train Epoch: 7\t[30000/79971 (38%)]\tTotal Loss: 20.7782\tAvg Loss: 0.0007\n",
      "Train Epoch: 7\t[35000/79971 (44%)]\tTotal Loss: 24.8217\tAvg Loss: 0.0007\n",
      "Train Epoch: 7\t[40000/79971 (50%)]\tTotal Loss: 29.2702\tAvg Loss: 0.0007\n",
      "Train Epoch: 7\t[45000/79971 (56%)]\tTotal Loss: 32.8040\tAvg Loss: 0.0007\n",
      "Train Epoch: 7\t[50000/79971 (62%)]\tTotal Loss: 36.4310\tAvg Loss: 0.0007\n",
      "Train Epoch: 7\t[55000/79971 (69%)]\tTotal Loss: 39.8712\tAvg Loss: 0.0007\n",
      "Train Epoch: 7\t[60000/79971 (75%)]\tTotal Loss: 43.5631\tAvg Loss: 0.0007\n",
      "Train Epoch: 7\t[65000/79971 (81%)]\tTotal Loss: 47.4210\tAvg Loss: 0.0007\n",
      "Train Epoch: 7\t[70000/79971 (88%)]\tTotal Loss: 50.9633\tAvg Loss: 0.0007\n",
      "Train Epoch: 7\t[75000/79971 (94%)]\tTotal Loss: 54.4679\tAvg Loss: 0.0007\n",
      "====> Epoch: 7\tTotal Loss: 57.8389\t Avg Loss: 0.0007\tCorrect: 77559/79971\tPercentage Correct: 96.98\n",
      "====> Val Loss: 18.0465\t Avg Loss: 0.0020\tCorrect: 8238/8886\tPercentage Correct: 92.71\n",
      "====> Test Loss: 45.5526\t Avg Loss: 0.0021\tCorrect: 20548/22215\tPercentage Correct: 92.50\n",
      "Train Epoch: 8\t[5000/79971 (6%)]\tTotal Loss: 3.7958\tAvg Loss: 0.0008\n",
      "Train Epoch: 8\t[10000/79971 (12%)]\tTotal Loss: 7.1386\tAvg Loss: 0.0007\n",
      "Train Epoch: 8\t[15000/79971 (19%)]\tTotal Loss: 10.2182\tAvg Loss: 0.0007\n",
      "Train Epoch: 8\t[20000/79971 (25%)]\tTotal Loss: 14.6216\tAvg Loss: 0.0007\n",
      "Train Epoch: 8\t[25000/79971 (31%)]\tTotal Loss: 18.4814\tAvg Loss: 0.0007\n",
      "Train Epoch: 8\t[30000/79971 (38%)]\tTotal Loss: 22.8116\tAvg Loss: 0.0008\n",
      "Train Epoch: 8\t[35000/79971 (44%)]\tTotal Loss: 25.8612\tAvg Loss: 0.0007\n",
      "Train Epoch: 8\t[40000/79971 (50%)]\tTotal Loss: 29.0425\tAvg Loss: 0.0007\n",
      "Train Epoch: 8\t[45000/79971 (56%)]\tTotal Loss: 32.5872\tAvg Loss: 0.0007\n",
      "Train Epoch: 8\t[50000/79971 (62%)]\tTotal Loss: 36.0524\tAvg Loss: 0.0007\n",
      "Train Epoch: 8\t[55000/79971 (69%)]\tTotal Loss: 39.5489\tAvg Loss: 0.0007\n",
      "Train Epoch: 8\t[60000/79971 (75%)]\tTotal Loss: 42.9539\tAvg Loss: 0.0007\n",
      "Train Epoch: 8\t[65000/79971 (81%)]\tTotal Loss: 46.4351\tAvg Loss: 0.0007\n",
      "Train Epoch: 8\t[70000/79971 (88%)]\tTotal Loss: 50.6159\tAvg Loss: 0.0007\n",
      "Train Epoch: 8\t[75000/79971 (94%)]\tTotal Loss: 54.2751\tAvg Loss: 0.0007\n",
      "====> Epoch: 8\tTotal Loss: 57.7781\t Avg Loss: 0.0007\tCorrect: 77525/79971\tPercentage Correct: 96.94\n",
      "====> Val Loss: 21.1927\t Avg Loss: 0.0024\tCorrect: 8178/8886\tPercentage Correct: 92.03\n",
      "====> Test Loss: 54.9663\t Avg Loss: 0.0025\tCorrect: 20317/22215\tPercentage Correct: 91.46\n",
      "Train Epoch: 9\t[5000/79971 (6%)]\tTotal Loss: 3.5271\tAvg Loss: 0.0007\n",
      "Train Epoch: 9\t[10000/79971 (12%)]\tTotal Loss: 6.8013\tAvg Loss: 0.0007\n",
      "Train Epoch: 9\t[15000/79971 (19%)]\tTotal Loss: 10.0467\tAvg Loss: 0.0007\n",
      "Train Epoch: 9\t[20000/79971 (25%)]\tTotal Loss: 13.5604\tAvg Loss: 0.0007\n",
      "Train Epoch: 9\t[25000/79971 (31%)]\tTotal Loss: 17.4225\tAvg Loss: 0.0007\n",
      "Train Epoch: 9\t[30000/79971 (38%)]\tTotal Loss: 20.3072\tAvg Loss: 0.0007\n",
      "Train Epoch: 9\t[35000/79971 (44%)]\tTotal Loss: 23.5145\tAvg Loss: 0.0007\n",
      "Train Epoch: 9\t[40000/79971 (50%)]\tTotal Loss: 26.9983\tAvg Loss: 0.0007\n",
      "Train Epoch: 9\t[45000/79971 (56%)]\tTotal Loss: 30.4710\tAvg Loss: 0.0007\n",
      "Train Epoch: 9\t[50000/79971 (62%)]\tTotal Loss: 33.6085\tAvg Loss: 0.0007\n",
      "Train Epoch: 9\t[55000/79971 (69%)]\tTotal Loss: 37.1703\tAvg Loss: 0.0007\n",
      "Train Epoch: 9\t[60000/79971 (75%)]\tTotal Loss: 40.6575\tAvg Loss: 0.0007\n",
      "Train Epoch: 9\t[65000/79971 (81%)]\tTotal Loss: 43.9196\tAvg Loss: 0.0007\n",
      "Train Epoch: 9\t[70000/79971 (88%)]\tTotal Loss: 47.3673\tAvg Loss: 0.0007\n",
      "Train Epoch: 9\t[75000/79971 (94%)]\tTotal Loss: 51.0583\tAvg Loss: 0.0007\n",
      "====> Epoch: 9\tTotal Loss: 54.4788\t Avg Loss: 0.0007\tCorrect: 77706/79971\tPercentage Correct: 97.17\n",
      "====> Val Loss: 20.0575\t Avg Loss: 0.0023\tCorrect: 8157/8886\tPercentage Correct: 91.80\n",
      "====> Test Loss: 50.7609\t Avg Loss: 0.0023\tCorrect: 20339/22215\tPercentage Correct: 91.56\n",
      "Train Epoch: 10\t[5000/79971 (6%)]\tTotal Loss: 2.8976\tAvg Loss: 0.0006\n",
      "Train Epoch: 10\t[10000/79971 (12%)]\tTotal Loss: 5.6675\tAvg Loss: 0.0006\n",
      "Train Epoch: 10\t[15000/79971 (19%)]\tTotal Loss: 8.7419\tAvg Loss: 0.0006\n",
      "Train Epoch: 10\t[20000/79971 (25%)]\tTotal Loss: 11.4494\tAvg Loss: 0.0006\n",
      "Train Epoch: 10\t[25000/79971 (31%)]\tTotal Loss: 14.4354\tAvg Loss: 0.0006\n",
      "Train Epoch: 10\t[30000/79971 (38%)]\tTotal Loss: 17.1823\tAvg Loss: 0.0006\n",
      "Train Epoch: 10\t[35000/79971 (44%)]\tTotal Loss: 20.2292\tAvg Loss: 0.0006\n",
      "Train Epoch: 10\t[40000/79971 (50%)]\tTotal Loss: 23.1962\tAvg Loss: 0.0006\n",
      "Train Epoch: 10\t[45000/79971 (56%)]\tTotal Loss: 26.1128\tAvg Loss: 0.0006\n",
      "Train Epoch: 10\t[50000/79971 (62%)]\tTotal Loss: 29.9731\tAvg Loss: 0.0006\n",
      "Train Epoch: 10\t[55000/79971 (69%)]\tTotal Loss: 33.4611\tAvg Loss: 0.0006\n",
      "Train Epoch: 10\t[60000/79971 (75%)]\tTotal Loss: 37.2948\tAvg Loss: 0.0006\n",
      "Train Epoch: 10\t[65000/79971 (81%)]\tTotal Loss: 40.8898\tAvg Loss: 0.0006\n",
      "Train Epoch: 10\t[70000/79971 (88%)]\tTotal Loss: 44.3140\tAvg Loss: 0.0006\n",
      "Train Epoch: 10\t[75000/79971 (94%)]\tTotal Loss: 47.6106\tAvg Loss: 0.0006\n",
      "====> Epoch: 10\tTotal Loss: 51.3040\t Avg Loss: 0.0006\tCorrect: 77833/79971\tPercentage Correct: 97.33\n",
      "====> Val Loss: 8.1215\t Avg Loss: 0.0009\tCorrect: 8536/8886\tPercentage Correct: 96.06\n",
      "====> Test Loss: 22.9978\t Avg Loss: 0.0010\tCorrect: 21258/22215\tPercentage Correct: 95.69\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 11\t[5000/79971 (6%)]\tTotal Loss: 2.8485\tAvg Loss: 0.0006\n",
      "Train Epoch: 11\t[10000/79971 (12%)]\tTotal Loss: 5.9268\tAvg Loss: 0.0006\n",
      "Train Epoch: 11\t[15000/79971 (19%)]\tTotal Loss: 9.2203\tAvg Loss: 0.0006\n",
      "Train Epoch: 11\t[20000/79971 (25%)]\tTotal Loss: 12.0961\tAvg Loss: 0.0006\n",
      "Train Epoch: 11\t[25000/79971 (31%)]\tTotal Loss: 14.6137\tAvg Loss: 0.0006\n",
      "Train Epoch: 11\t[30000/79971 (38%)]\tTotal Loss: 17.4411\tAvg Loss: 0.0006\n",
      "Train Epoch: 11\t[35000/79971 (44%)]\tTotal Loss: 20.5131\tAvg Loss: 0.0006\n",
      "Train Epoch: 11\t[40000/79971 (50%)]\tTotal Loss: 23.5004\tAvg Loss: 0.0006\n",
      "Train Epoch: 11\t[45000/79971 (56%)]\tTotal Loss: 26.5593\tAvg Loss: 0.0006\n",
      "Train Epoch: 11\t[50000/79971 (62%)]\tTotal Loss: 29.9706\tAvg Loss: 0.0006\n",
      "Train Epoch: 11\t[55000/79971 (69%)]\tTotal Loss: 34.0197\tAvg Loss: 0.0006\n",
      "Train Epoch: 11\t[60000/79971 (75%)]\tTotal Loss: 37.4616\tAvg Loss: 0.0006\n",
      "Train Epoch: 11\t[65000/79971 (81%)]\tTotal Loss: 40.2348\tAvg Loss: 0.0006\n",
      "Train Epoch: 11\t[70000/79971 (88%)]\tTotal Loss: 43.2501\tAvg Loss: 0.0006\n",
      "Train Epoch: 11\t[75000/79971 (94%)]\tTotal Loss: 46.4026\tAvg Loss: 0.0006\n",
      "====> Epoch: 11\tTotal Loss: 49.9182\t Avg Loss: 0.0006\tCorrect: 77888/79971\tPercentage Correct: 97.40\n",
      "====> Val Loss: 10.0288\t Avg Loss: 0.0011\tCorrect: 8518/8886\tPercentage Correct: 95.86\n",
      "====> Test Loss: 23.7771\t Avg Loss: 0.0011\tCorrect: 21323/22215\tPercentage Correct: 95.98\n",
      "Train Epoch: 12\t[5000/79971 (6%)]\tTotal Loss: 3.4732\tAvg Loss: 0.0007\n",
      "Train Epoch: 12\t[10000/79971 (12%)]\tTotal Loss: 6.1500\tAvg Loss: 0.0006\n",
      "Train Epoch: 12\t[15000/79971 (19%)]\tTotal Loss: 8.5893\tAvg Loss: 0.0006\n",
      "Train Epoch: 12\t[20000/79971 (25%)]\tTotal Loss: 11.3919\tAvg Loss: 0.0006\n",
      "Train Epoch: 12\t[25000/79971 (31%)]\tTotal Loss: 13.9249\tAvg Loss: 0.0006\n",
      "Train Epoch: 12\t[30000/79971 (38%)]\tTotal Loss: 17.0647\tAvg Loss: 0.0006\n",
      "Train Epoch: 12\t[35000/79971 (44%)]\tTotal Loss: 19.6153\tAvg Loss: 0.0006\n",
      "Train Epoch: 12\t[40000/79971 (50%)]\tTotal Loss: 21.9642\tAvg Loss: 0.0005\n",
      "Train Epoch: 12\t[45000/79971 (56%)]\tTotal Loss: 25.1418\tAvg Loss: 0.0006\n",
      "Train Epoch: 12\t[50000/79971 (62%)]\tTotal Loss: 28.5363\tAvg Loss: 0.0006\n",
      "Train Epoch: 12\t[55000/79971 (69%)]\tTotal Loss: 32.0883\tAvg Loss: 0.0006\n",
      "Train Epoch: 12\t[60000/79971 (75%)]\tTotal Loss: 35.4130\tAvg Loss: 0.0006\n",
      "Train Epoch: 12\t[65000/79971 (81%)]\tTotal Loss: 38.3662\tAvg Loss: 0.0006\n",
      "Train Epoch: 12\t[70000/79971 (88%)]\tTotal Loss: 41.5007\tAvg Loss: 0.0006\n",
      "Train Epoch: 12\t[75000/79971 (94%)]\tTotal Loss: 44.4101\tAvg Loss: 0.0006\n",
      "====> Epoch: 12\tTotal Loss: 47.0184\t Avg Loss: 0.0006\tCorrect: 78009/79971\tPercentage Correct: 97.55\n",
      "====> Val Loss: 7.5838\t Avg Loss: 0.0009\tCorrect: 8578/8886\tPercentage Correct: 96.53\n",
      "====> Test Loss: 19.7974\t Avg Loss: 0.0009\tCorrect: 21392/22215\tPercentage Correct: 96.30\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 13\t[5000/79971 (6%)]\tTotal Loss: 2.2089\tAvg Loss: 0.0004\n",
      "Train Epoch: 13\t[10000/79971 (12%)]\tTotal Loss: 4.9908\tAvg Loss: 0.0005\n",
      "Train Epoch: 13\t[15000/79971 (19%)]\tTotal Loss: 7.5311\tAvg Loss: 0.0005\n",
      "Train Epoch: 13\t[20000/79971 (25%)]\tTotal Loss: 10.2000\tAvg Loss: 0.0005\n",
      "Train Epoch: 13\t[25000/79971 (31%)]\tTotal Loss: 12.7843\tAvg Loss: 0.0005\n",
      "Train Epoch: 13\t[30000/79971 (38%)]\tTotal Loss: 15.3180\tAvg Loss: 0.0005\n",
      "Train Epoch: 13\t[35000/79971 (44%)]\tTotal Loss: 17.8533\tAvg Loss: 0.0005\n",
      "Train Epoch: 13\t[40000/79971 (50%)]\tTotal Loss: 20.6667\tAvg Loss: 0.0005\n",
      "Train Epoch: 13\t[45000/79971 (56%)]\tTotal Loss: 23.3996\tAvg Loss: 0.0005\n",
      "Train Epoch: 13\t[50000/79971 (62%)]\tTotal Loss: 26.5365\tAvg Loss: 0.0005\n",
      "Train Epoch: 13\t[55000/79971 (69%)]\tTotal Loss: 29.5213\tAvg Loss: 0.0005\n",
      "Train Epoch: 13\t[60000/79971 (75%)]\tTotal Loss: 32.6534\tAvg Loss: 0.0005\n",
      "Train Epoch: 13\t[65000/79971 (81%)]\tTotal Loss: 35.8509\tAvg Loss: 0.0006\n",
      "Train Epoch: 13\t[70000/79971 (88%)]\tTotal Loss: 38.6268\tAvg Loss: 0.0006\n",
      "Train Epoch: 13\t[75000/79971 (94%)]\tTotal Loss: 41.5393\tAvg Loss: 0.0006\n",
      "====> Epoch: 13\tTotal Loss: 44.3528\t Avg Loss: 0.0006\tCorrect: 78080/79971\tPercentage Correct: 97.64\n",
      "====> Val Loss: 11.9147\t Avg Loss: 0.0013\tCorrect: 8395/8886\tPercentage Correct: 94.47\n",
      "====> Test Loss: 32.0762\t Avg Loss: 0.0014\tCorrect: 20921/22215\tPercentage Correct: 94.18\n",
      "Train Epoch: 14\t[5000/79971 (6%)]\tTotal Loss: 2.6108\tAvg Loss: 0.0005\n",
      "Train Epoch: 14\t[10000/79971 (12%)]\tTotal Loss: 5.0084\tAvg Loss: 0.0005\n",
      "Train Epoch: 14\t[15000/79971 (19%)]\tTotal Loss: 7.7179\tAvg Loss: 0.0005\n",
      "Train Epoch: 14\t[20000/79971 (25%)]\tTotal Loss: 10.3217\tAvg Loss: 0.0005\n",
      "Train Epoch: 14\t[25000/79971 (31%)]\tTotal Loss: 12.8280\tAvg Loss: 0.0005\n",
      "Train Epoch: 14\t[30000/79971 (38%)]\tTotal Loss: 15.5061\tAvg Loss: 0.0005\n",
      "Train Epoch: 14\t[35000/79971 (44%)]\tTotal Loss: 18.3926\tAvg Loss: 0.0005\n",
      "Train Epoch: 14\t[40000/79971 (50%)]\tTotal Loss: 21.0848\tAvg Loss: 0.0005\n",
      "Train Epoch: 14\t[45000/79971 (56%)]\tTotal Loss: 24.1280\tAvg Loss: 0.0005\n",
      "Train Epoch: 14\t[50000/79971 (62%)]\tTotal Loss: 27.2667\tAvg Loss: 0.0005\n",
      "Train Epoch: 14\t[55000/79971 (69%)]\tTotal Loss: 29.7593\tAvg Loss: 0.0005\n",
      "Train Epoch: 14\t[60000/79971 (75%)]\tTotal Loss: 32.2939\tAvg Loss: 0.0005\n",
      "Train Epoch: 14\t[65000/79971 (81%)]\tTotal Loss: 34.9323\tAvg Loss: 0.0005\n",
      "Train Epoch: 14\t[70000/79971 (88%)]\tTotal Loss: 37.8862\tAvg Loss: 0.0005\n",
      "Train Epoch: 14\t[75000/79971 (94%)]\tTotal Loss: 40.7163\tAvg Loss: 0.0005\n",
      "====> Epoch: 14\tTotal Loss: 43.6225\t Avg Loss: 0.0005\tCorrect: 78128/79971\tPercentage Correct: 97.70\n",
      "====> Val Loss: 8.0310\t Avg Loss: 0.0009\tCorrect: 8540/8886\tPercentage Correct: 96.11\n",
      "====> Test Loss: 21.7177\t Avg Loss: 0.0010\tCorrect: 21328/22215\tPercentage Correct: 96.01\n",
      "Train Epoch: 15\t[5000/79971 (6%)]\tTotal Loss: 2.9047\tAvg Loss: 0.0006\n",
      "Train Epoch: 15\t[10000/79971 (12%)]\tTotal Loss: 5.6417\tAvg Loss: 0.0006\n",
      "Train Epoch: 15\t[15000/79971 (19%)]\tTotal Loss: 8.1426\tAvg Loss: 0.0005\n",
      "Train Epoch: 15\t[20000/79971 (25%)]\tTotal Loss: 10.5484\tAvg Loss: 0.0005\n",
      "Train Epoch: 15\t[25000/79971 (31%)]\tTotal Loss: 13.0324\tAvg Loss: 0.0005\n",
      "Train Epoch: 15\t[30000/79971 (38%)]\tTotal Loss: 15.3500\tAvg Loss: 0.0005\n",
      "Train Epoch: 15\t[35000/79971 (44%)]\tTotal Loss: 17.8590\tAvg Loss: 0.0005\n",
      "Train Epoch: 15\t[40000/79971 (50%)]\tTotal Loss: 20.4758\tAvg Loss: 0.0005\n",
      "Train Epoch: 15\t[45000/79971 (56%)]\tTotal Loss: 22.8604\tAvg Loss: 0.0005\n",
      "Train Epoch: 15\t[50000/79971 (62%)]\tTotal Loss: 25.2493\tAvg Loss: 0.0005\n",
      "Train Epoch: 15\t[55000/79971 (69%)]\tTotal Loss: 28.0319\tAvg Loss: 0.0005\n",
      "Train Epoch: 15\t[60000/79971 (75%)]\tTotal Loss: 30.8383\tAvg Loss: 0.0005\n",
      "Train Epoch: 15\t[65000/79971 (81%)]\tTotal Loss: 33.5940\tAvg Loss: 0.0005\n",
      "Train Epoch: 15\t[70000/79971 (88%)]\tTotal Loss: 36.4622\tAvg Loss: 0.0005\n",
      "Train Epoch: 15\t[75000/79971 (94%)]\tTotal Loss: 38.9742\tAvg Loss: 0.0005\n",
      "====> Epoch: 15\tTotal Loss: 41.5992\t Avg Loss: 0.0005\tCorrect: 78207/79971\tPercentage Correct: 97.79\n",
      "====> Val Loss: 12.9789\t Avg Loss: 0.0015\tCorrect: 8410/8886\tPercentage Correct: 94.64\n",
      "====> Test Loss: 32.8897\t Avg Loss: 0.0015\tCorrect: 20959/22215\tPercentage Correct: 94.35\n",
      "Train Epoch: 16\t[5000/79971 (6%)]\tTotal Loss: 2.6875\tAvg Loss: 0.0005\n",
      "Train Epoch: 16\t[10000/79971 (12%)]\tTotal Loss: 5.4505\tAvg Loss: 0.0005\n",
      "Train Epoch: 16\t[15000/79971 (19%)]\tTotal Loss: 7.6495\tAvg Loss: 0.0005\n",
      "Train Epoch: 16\t[20000/79971 (25%)]\tTotal Loss: 9.8489\tAvg Loss: 0.0005\n",
      "Train Epoch: 16\t[25000/79971 (31%)]\tTotal Loss: 11.8744\tAvg Loss: 0.0005\n",
      "Train Epoch: 16\t[30000/79971 (38%)]\tTotal Loss: 13.9708\tAvg Loss: 0.0005\n",
      "Train Epoch: 16\t[35000/79971 (44%)]\tTotal Loss: 16.6442\tAvg Loss: 0.0005\n",
      "Train Epoch: 16\t[40000/79971 (50%)]\tTotal Loss: 18.9911\tAvg Loss: 0.0005\n",
      "Train Epoch: 16\t[45000/79971 (56%)]\tTotal Loss: 21.3322\tAvg Loss: 0.0005\n",
      "Train Epoch: 16\t[50000/79971 (62%)]\tTotal Loss: 24.0224\tAvg Loss: 0.0005\n",
      "Train Epoch: 16\t[55000/79971 (69%)]\tTotal Loss: 26.3648\tAvg Loss: 0.0005\n",
      "Train Epoch: 16\t[60000/79971 (75%)]\tTotal Loss: 28.7670\tAvg Loss: 0.0005\n",
      "Train Epoch: 16\t[65000/79971 (81%)]\tTotal Loss: 31.2413\tAvg Loss: 0.0005\n",
      "Train Epoch: 16\t[70000/79971 (88%)]\tTotal Loss: 33.8242\tAvg Loss: 0.0005\n",
      "Train Epoch: 16\t[75000/79971 (94%)]\tTotal Loss: 35.8592\tAvg Loss: 0.0005\n",
      "====> Epoch: 16\tTotal Loss: 38.8099\t Avg Loss: 0.0005\tCorrect: 78313/79971\tPercentage Correct: 97.93\n",
      "====> Val Loss: 8.2664\t Avg Loss: 0.0009\tCorrect: 8553/8886\tPercentage Correct: 96.25\n",
      "====> Test Loss: 21.3317\t Avg Loss: 0.0010\tCorrect: 21342/22215\tPercentage Correct: 96.07\n",
      "Train Epoch: 17\t[5000/79971 (6%)]\tTotal Loss: 2.4999\tAvg Loss: 0.0005\n",
      "Train Epoch: 17\t[10000/79971 (12%)]\tTotal Loss: 5.0885\tAvg Loss: 0.0005\n",
      "Train Epoch: 17\t[15000/79971 (19%)]\tTotal Loss: 7.6636\tAvg Loss: 0.0005\n",
      "Train Epoch: 17\t[20000/79971 (25%)]\tTotal Loss: 10.5383\tAvg Loss: 0.0005\n",
      "Train Epoch: 17\t[25000/79971 (31%)]\tTotal Loss: 13.2088\tAvg Loss: 0.0005\n",
      "Train Epoch: 17\t[30000/79971 (38%)]\tTotal Loss: 15.6457\tAvg Loss: 0.0005\n",
      "Train Epoch: 17\t[35000/79971 (44%)]\tTotal Loss: 18.3908\tAvg Loss: 0.0005\n",
      "Train Epoch: 17\t[40000/79971 (50%)]\tTotal Loss: 20.4749\tAvg Loss: 0.0005\n",
      "Train Epoch: 17\t[45000/79971 (56%)]\tTotal Loss: 22.5354\tAvg Loss: 0.0005\n",
      "Train Epoch: 17\t[50000/79971 (62%)]\tTotal Loss: 24.9075\tAvg Loss: 0.0005\n",
      "Train Epoch: 17\t[55000/79971 (69%)]\tTotal Loss: 27.7277\tAvg Loss: 0.0005\n",
      "Train Epoch: 17\t[60000/79971 (75%)]\tTotal Loss: 30.4699\tAvg Loss: 0.0005\n",
      "Train Epoch: 17\t[65000/79971 (81%)]\tTotal Loss: 32.8990\tAvg Loss: 0.0005\n",
      "Train Epoch: 17\t[70000/79971 (88%)]\tTotal Loss: 35.0555\tAvg Loss: 0.0005\n",
      "Train Epoch: 17\t[75000/79971 (94%)]\tTotal Loss: 37.5150\tAvg Loss: 0.0005\n",
      "====> Epoch: 17\tTotal Loss: 39.8594\t Avg Loss: 0.0005\tCorrect: 78292/79971\tPercentage Correct: 97.90\n",
      "====> Val Loss: 7.2160\t Avg Loss: 0.0008\tCorrect: 8585/8886\tPercentage Correct: 96.61\n",
      "====> Test Loss: 18.1449\t Avg Loss: 0.0008\tCorrect: 21462/22215\tPercentage Correct: 96.61\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 18\t[5000/79971 (6%)]\tTotal Loss: 2.2751\tAvg Loss: 0.0005\n",
      "Train Epoch: 18\t[10000/79971 (12%)]\tTotal Loss: 4.6639\tAvg Loss: 0.0005\n",
      "Train Epoch: 18\t[15000/79971 (19%)]\tTotal Loss: 7.3459\tAvg Loss: 0.0005\n",
      "Train Epoch: 18\t[20000/79971 (25%)]\tTotal Loss: 10.2547\tAvg Loss: 0.0005\n",
      "Train Epoch: 18\t[25000/79971 (31%)]\tTotal Loss: 12.4892\tAvg Loss: 0.0005\n",
      "Train Epoch: 18\t[30000/79971 (38%)]\tTotal Loss: 15.0248\tAvg Loss: 0.0005\n",
      "Train Epoch: 18\t[35000/79971 (44%)]\tTotal Loss: 17.5416\tAvg Loss: 0.0005\n",
      "Train Epoch: 18\t[40000/79971 (50%)]\tTotal Loss: 19.7806\tAvg Loss: 0.0005\n",
      "Train Epoch: 18\t[45000/79971 (56%)]\tTotal Loss: 22.0000\tAvg Loss: 0.0005\n",
      "Train Epoch: 18\t[50000/79971 (62%)]\tTotal Loss: 24.2784\tAvg Loss: 0.0005\n",
      "Train Epoch: 18\t[55000/79971 (69%)]\tTotal Loss: 26.3379\tAvg Loss: 0.0005\n",
      "Train Epoch: 18\t[60000/79971 (75%)]\tTotal Loss: 28.5780\tAvg Loss: 0.0005\n",
      "Train Epoch: 18\t[65000/79971 (81%)]\tTotal Loss: 30.9917\tAvg Loss: 0.0005\n",
      "Train Epoch: 18\t[70000/79971 (88%)]\tTotal Loss: 33.1254\tAvg Loss: 0.0005\n",
      "Train Epoch: 18\t[75000/79971 (94%)]\tTotal Loss: 35.4713\tAvg Loss: 0.0005\n",
      "====> Epoch: 18\tTotal Loss: 37.9113\t Avg Loss: 0.0005\tCorrect: 78349/79971\tPercentage Correct: 97.97\n",
      "====> Val Loss: 6.5229\t Avg Loss: 0.0007\tCorrect: 8626/8886\tPercentage Correct: 97.07\n",
      "====> Test Loss: 17.4663\t Avg Loss: 0.0008\tCorrect: 21535/22215\tPercentage Correct: 96.94\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 19\t[5000/79971 (6%)]\tTotal Loss: 1.9670\tAvg Loss: 0.0004\n",
      "Train Epoch: 19\t[10000/79971 (12%)]\tTotal Loss: 4.1519\tAvg Loss: 0.0004\n",
      "Train Epoch: 19\t[15000/79971 (19%)]\tTotal Loss: 7.2680\tAvg Loss: 0.0005\n",
      "Train Epoch: 19\t[20000/79971 (25%)]\tTotal Loss: 9.8641\tAvg Loss: 0.0005\n",
      "Train Epoch: 19\t[25000/79971 (31%)]\tTotal Loss: 12.0337\tAvg Loss: 0.0005\n",
      "Train Epoch: 19\t[30000/79971 (38%)]\tTotal Loss: 14.1345\tAvg Loss: 0.0005\n",
      "Train Epoch: 19\t[35000/79971 (44%)]\tTotal Loss: 16.1944\tAvg Loss: 0.0005\n",
      "Train Epoch: 19\t[40000/79971 (50%)]\tTotal Loss: 19.0148\tAvg Loss: 0.0005\n",
      "Train Epoch: 19\t[45000/79971 (56%)]\tTotal Loss: 21.4338\tAvg Loss: 0.0005\n",
      "Train Epoch: 19\t[50000/79971 (62%)]\tTotal Loss: 24.0686\tAvg Loss: 0.0005\n",
      "Train Epoch: 19\t[55000/79971 (69%)]\tTotal Loss: 26.8414\tAvg Loss: 0.0005\n",
      "Train Epoch: 19\t[60000/79971 (75%)]\tTotal Loss: 29.3982\tAvg Loss: 0.0005\n",
      "Train Epoch: 19\t[65000/79971 (81%)]\tTotal Loss: 31.4690\tAvg Loss: 0.0005\n",
      "Train Epoch: 19\t[70000/79971 (88%)]\tTotal Loss: 33.9357\tAvg Loss: 0.0005\n",
      "Train Epoch: 19\t[75000/79971 (94%)]\tTotal Loss: 36.7440\tAvg Loss: 0.0005\n",
      "====> Epoch: 19\tTotal Loss: 39.1800\t Avg Loss: 0.0005\tCorrect: 78296/79971\tPercentage Correct: 97.91\n",
      "====> Val Loss: 12.4055\t Avg Loss: 0.0014\tCorrect: 8422/8886\tPercentage Correct: 94.78\n",
      "====> Test Loss: 33.7257\t Avg Loss: 0.0015\tCorrect: 21005/22215\tPercentage Correct: 94.55\n",
      "Train Epoch: 20\t[5000/79971 (6%)]\tTotal Loss: 2.0132\tAvg Loss: 0.0004\n",
      "Train Epoch: 20\t[10000/79971 (12%)]\tTotal Loss: 4.4379\tAvg Loss: 0.0004\n",
      "Train Epoch: 20\t[15000/79971 (19%)]\tTotal Loss: 6.7914\tAvg Loss: 0.0005\n",
      "Train Epoch: 20\t[20000/79971 (25%)]\tTotal Loss: 8.6843\tAvg Loss: 0.0004\n",
      "Train Epoch: 20\t[25000/79971 (31%)]\tTotal Loss: 10.7010\tAvg Loss: 0.0004\n",
      "Train Epoch: 20\t[30000/79971 (38%)]\tTotal Loss: 12.8859\tAvg Loss: 0.0004\n",
      "Train Epoch: 20\t[35000/79971 (44%)]\tTotal Loss: 15.2864\tAvg Loss: 0.0004\n",
      "Train Epoch: 20\t[40000/79971 (50%)]\tTotal Loss: 17.8478\tAvg Loss: 0.0004\n",
      "Train Epoch: 20\t[45000/79971 (56%)]\tTotal Loss: 20.2300\tAvg Loss: 0.0004\n",
      "Train Epoch: 20\t[50000/79971 (62%)]\tTotal Loss: 22.7053\tAvg Loss: 0.0005\n",
      "Train Epoch: 20\t[55000/79971 (69%)]\tTotal Loss: 24.7814\tAvg Loss: 0.0005\n",
      "Train Epoch: 20\t[60000/79971 (75%)]\tTotal Loss: 27.0165\tAvg Loss: 0.0005\n",
      "Train Epoch: 20\t[65000/79971 (81%)]\tTotal Loss: 28.9471\tAvg Loss: 0.0004\n",
      "Train Epoch: 20\t[70000/79971 (88%)]\tTotal Loss: 30.9646\tAvg Loss: 0.0004\n",
      "Train Epoch: 20\t[75000/79971 (94%)]\tTotal Loss: 33.1568\tAvg Loss: 0.0004\n",
      "====> Epoch: 20\tTotal Loss: 35.2849\t Avg Loss: 0.0004\tCorrect: 78467/79971\tPercentage Correct: 98.12\n",
      "====> Val Loss: 6.6490\t Avg Loss: 0.0007\tCorrect: 8649/8886\tPercentage Correct: 97.33\n",
      "====> Test Loss: 18.4903\t Avg Loss: 0.0008\tCorrect: 21531/22215\tPercentage Correct: 96.92\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 21\t[5000/79971 (6%)]\tTotal Loss: 2.0850\tAvg Loss: 0.0004\n",
      "Train Epoch: 21\t[10000/79971 (12%)]\tTotal Loss: 4.2926\tAvg Loss: 0.0004\n",
      "Train Epoch: 21\t[15000/79971 (19%)]\tTotal Loss: 6.2797\tAvg Loss: 0.0004\n",
      "Train Epoch: 21\t[20000/79971 (25%)]\tTotal Loss: 8.3533\tAvg Loss: 0.0004\n",
      "Train Epoch: 21\t[25000/79971 (31%)]\tTotal Loss: 10.2725\tAvg Loss: 0.0004\n",
      "Train Epoch: 21\t[30000/79971 (38%)]\tTotal Loss: 12.6925\tAvg Loss: 0.0004\n",
      "Train Epoch: 21\t[35000/79971 (44%)]\tTotal Loss: 15.2415\tAvg Loss: 0.0004\n",
      "Train Epoch: 21\t[40000/79971 (50%)]\tTotal Loss: 17.5935\tAvg Loss: 0.0004\n",
      "Train Epoch: 21\t[45000/79971 (56%)]\tTotal Loss: 19.4866\tAvg Loss: 0.0004\n",
      "Train Epoch: 21\t[50000/79971 (62%)]\tTotal Loss: 21.2197\tAvg Loss: 0.0004\n",
      "Train Epoch: 21\t[55000/79971 (69%)]\tTotal Loss: 23.4096\tAvg Loss: 0.0004\n",
      "Train Epoch: 21\t[60000/79971 (75%)]\tTotal Loss: 25.4298\tAvg Loss: 0.0004\n",
      "Train Epoch: 21\t[65000/79971 (81%)]\tTotal Loss: 27.7144\tAvg Loss: 0.0004\n",
      "Train Epoch: 21\t[70000/79971 (88%)]\tTotal Loss: 29.7179\tAvg Loss: 0.0004\n",
      "Train Epoch: 21\t[75000/79971 (94%)]\tTotal Loss: 31.8136\tAvg Loss: 0.0004\n",
      "====> Epoch: 21\tTotal Loss: 33.8789\t Avg Loss: 0.0004\tCorrect: 78522/79971\tPercentage Correct: 98.19\n",
      "====> Val Loss: 9.5764\t Avg Loss: 0.0011\tCorrect: 8530/8886\tPercentage Correct: 95.99\n",
      "====> Test Loss: 24.5390\t Avg Loss: 0.0011\tCorrect: 21279/22215\tPercentage Correct: 95.79\n",
      "Train Epoch: 22\t[5000/79971 (6%)]\tTotal Loss: 2.2202\tAvg Loss: 0.0004\n",
      "Train Epoch: 22\t[10000/79971 (12%)]\tTotal Loss: 4.1884\tAvg Loss: 0.0004\n",
      "Train Epoch: 22\t[15000/79971 (19%)]\tTotal Loss: 6.5164\tAvg Loss: 0.0004\n",
      "Train Epoch: 22\t[20000/79971 (25%)]\tTotal Loss: 8.7399\tAvg Loss: 0.0004\n",
      "Train Epoch: 22\t[25000/79971 (31%)]\tTotal Loss: 11.3474\tAvg Loss: 0.0005\n",
      "Train Epoch: 22\t[30000/79971 (38%)]\tTotal Loss: 13.8209\tAvg Loss: 0.0005\n",
      "Train Epoch: 22\t[35000/79971 (44%)]\tTotal Loss: 16.0581\tAvg Loss: 0.0005\n",
      "Train Epoch: 22\t[40000/79971 (50%)]\tTotal Loss: 17.8885\tAvg Loss: 0.0004\n",
      "Train Epoch: 22\t[45000/79971 (56%)]\tTotal Loss: 19.9466\tAvg Loss: 0.0004\n",
      "Train Epoch: 22\t[50000/79971 (62%)]\tTotal Loss: 22.5836\tAvg Loss: 0.0005\n",
      "Train Epoch: 22\t[55000/79971 (69%)]\tTotal Loss: 24.7840\tAvg Loss: 0.0005\n",
      "Train Epoch: 22\t[60000/79971 (75%)]\tTotal Loss: 27.1409\tAvg Loss: 0.0005\n",
      "Train Epoch: 22\t[65000/79971 (81%)]\tTotal Loss: 29.5666\tAvg Loss: 0.0005\n",
      "Train Epoch: 22\t[70000/79971 (88%)]\tTotal Loss: 31.8327\tAvg Loss: 0.0005\n",
      "Train Epoch: 22\t[75000/79971 (94%)]\tTotal Loss: 34.0114\tAvg Loss: 0.0005\n",
      "====> Epoch: 22\tTotal Loss: 36.1000\t Avg Loss: 0.0005\tCorrect: 78471/79971\tPercentage Correct: 98.12\n",
      "====> Val Loss: 8.8850\t Avg Loss: 0.0010\tCorrect: 8547/8886\tPercentage Correct: 96.19\n",
      "====> Test Loss: 23.9575\t Avg Loss: 0.0011\tCorrect: 21277/22215\tPercentage Correct: 95.78\n",
      "Train Epoch: 23\t[5000/79971 (6%)]\tTotal Loss: 1.9933\tAvg Loss: 0.0004\n",
      "Train Epoch: 23\t[10000/79971 (12%)]\tTotal Loss: 4.1431\tAvg Loss: 0.0004\n",
      "Train Epoch: 23\t[15000/79971 (19%)]\tTotal Loss: 5.8703\tAvg Loss: 0.0004\n",
      "Train Epoch: 23\t[20000/79971 (25%)]\tTotal Loss: 7.8046\tAvg Loss: 0.0004\n",
      "Train Epoch: 23\t[25000/79971 (31%)]\tTotal Loss: 9.7242\tAvg Loss: 0.0004\n",
      "Train Epoch: 23\t[30000/79971 (38%)]\tTotal Loss: 11.6800\tAvg Loss: 0.0004\n",
      "Train Epoch: 23\t[35000/79971 (44%)]\tTotal Loss: 13.7340\tAvg Loss: 0.0004\n",
      "Train Epoch: 23\t[40000/79971 (50%)]\tTotal Loss: 15.7701\tAvg Loss: 0.0004\n",
      "Train Epoch: 23\t[45000/79971 (56%)]\tTotal Loss: 17.8066\tAvg Loss: 0.0004\n",
      "Train Epoch: 23\t[50000/79971 (62%)]\tTotal Loss: 20.1303\tAvg Loss: 0.0004\n",
      "Train Epoch: 23\t[55000/79971 (69%)]\tTotal Loss: 22.1463\tAvg Loss: 0.0004\n",
      "Train Epoch: 23\t[60000/79971 (75%)]\tTotal Loss: 24.2096\tAvg Loss: 0.0004\n",
      "Train Epoch: 23\t[65000/79971 (81%)]\tTotal Loss: 26.3854\tAvg Loss: 0.0004\n",
      "Train Epoch: 23\t[70000/79971 (88%)]\tTotal Loss: 28.8260\tAvg Loss: 0.0004\n",
      "Train Epoch: 23\t[75000/79971 (94%)]\tTotal Loss: 31.4895\tAvg Loss: 0.0004\n",
      "====> Epoch: 23\tTotal Loss: 33.8625\t Avg Loss: 0.0004\tCorrect: 78471/79971\tPercentage Correct: 98.12\n",
      "====> Val Loss: 10.6963\t Avg Loss: 0.0012\tCorrect: 8489/8886\tPercentage Correct: 95.53\n",
      "====> Test Loss: 29.4302\t Avg Loss: 0.0013\tCorrect: 21146/22215\tPercentage Correct: 95.19\n",
      "Train Epoch: 24\t[5000/79971 (6%)]\tTotal Loss: 2.0463\tAvg Loss: 0.0004\n",
      "Train Epoch: 24\t[10000/79971 (12%)]\tTotal Loss: 4.1422\tAvg Loss: 0.0004\n",
      "Train Epoch: 24\t[15000/79971 (19%)]\tTotal Loss: 5.8165\tAvg Loss: 0.0004\n",
      "Train Epoch: 24\t[20000/79971 (25%)]\tTotal Loss: 7.7889\tAvg Loss: 0.0004\n",
      "Train Epoch: 24\t[25000/79971 (31%)]\tTotal Loss: 9.6432\tAvg Loss: 0.0004\n",
      "Train Epoch: 24\t[30000/79971 (38%)]\tTotal Loss: 11.9827\tAvg Loss: 0.0004\n",
      "Train Epoch: 24\t[35000/79971 (44%)]\tTotal Loss: 13.9833\tAvg Loss: 0.0004\n",
      "Train Epoch: 24\t[40000/79971 (50%)]\tTotal Loss: 15.7377\tAvg Loss: 0.0004\n",
      "Train Epoch: 24\t[45000/79971 (56%)]\tTotal Loss: 17.7653\tAvg Loss: 0.0004\n",
      "Train Epoch: 24\t[50000/79971 (62%)]\tTotal Loss: 19.8376\tAvg Loss: 0.0004\n",
      "Train Epoch: 24\t[55000/79971 (69%)]\tTotal Loss: 21.8879\tAvg Loss: 0.0004\n",
      "Train Epoch: 24\t[60000/79971 (75%)]\tTotal Loss: 23.9826\tAvg Loss: 0.0004\n",
      "Train Epoch: 24\t[65000/79971 (81%)]\tTotal Loss: 26.2356\tAvg Loss: 0.0004\n",
      "Train Epoch: 24\t[70000/79971 (88%)]\tTotal Loss: 28.6518\tAvg Loss: 0.0004\n",
      "Train Epoch: 24\t[75000/79971 (94%)]\tTotal Loss: 30.9757\tAvg Loss: 0.0004\n",
      "====> Epoch: 24\tTotal Loss: 32.9006\t Avg Loss: 0.0004\tCorrect: 78567/79971\tPercentage Correct: 98.24\n",
      "====> Val Loss: 34.0020\t Avg Loss: 0.0038\tCorrect: 7907/8886\tPercentage Correct: 88.98\n",
      "====> Test Loss: 87.5731\t Avg Loss: 0.0039\tCorrect: 19800/22215\tPercentage Correct: 89.13\n",
      "Train Epoch: 25\t[5000/79971 (6%)]\tTotal Loss: 1.8597\tAvg Loss: 0.0004\n",
      "Train Epoch: 25\t[10000/79971 (12%)]\tTotal Loss: 3.9236\tAvg Loss: 0.0004\n",
      "Train Epoch: 25\t[15000/79971 (19%)]\tTotal Loss: 5.6894\tAvg Loss: 0.0004\n",
      "Train Epoch: 25\t[20000/79971 (25%)]\tTotal Loss: 7.6389\tAvg Loss: 0.0004\n",
      "Train Epoch: 25\t[25000/79971 (31%)]\tTotal Loss: 9.3830\tAvg Loss: 0.0004\n",
      "Train Epoch: 25\t[30000/79971 (38%)]\tTotal Loss: 11.2512\tAvg Loss: 0.0004\n",
      "Train Epoch: 25\t[35000/79971 (44%)]\tTotal Loss: 13.3075\tAvg Loss: 0.0004\n",
      "Train Epoch: 25\t[40000/79971 (50%)]\tTotal Loss: 15.6905\tAvg Loss: 0.0004\n",
      "Train Epoch: 25\t[45000/79971 (56%)]\tTotal Loss: 17.9280\tAvg Loss: 0.0004\n",
      "Train Epoch: 25\t[50000/79971 (62%)]\tTotal Loss: 19.9684\tAvg Loss: 0.0004\n",
      "Train Epoch: 25\t[55000/79971 (69%)]\tTotal Loss: 21.8597\tAvg Loss: 0.0004\n",
      "Train Epoch: 25\t[60000/79971 (75%)]\tTotal Loss: 23.5898\tAvg Loss: 0.0004\n",
      "Train Epoch: 25\t[65000/79971 (81%)]\tTotal Loss: 25.6589\tAvg Loss: 0.0004\n",
      "Train Epoch: 25\t[70000/79971 (88%)]\tTotal Loss: 27.5562\tAvg Loss: 0.0004\n",
      "Train Epoch: 25\t[75000/79971 (94%)]\tTotal Loss: 29.1933\tAvg Loss: 0.0004\n",
      "====> Epoch: 25\tTotal Loss: 31.0196\t Avg Loss: 0.0004\tCorrect: 78617/79971\tPercentage Correct: 98.31\n",
      "====> Val Loss: 25.9143\t Avg Loss: 0.0029\tCorrect: 8128/8886\tPercentage Correct: 91.47\n",
      "====> Test Loss: 67.6686\t Avg Loss: 0.0030\tCorrect: 20278/22215\tPercentage Correct: 91.28\n",
      "Train Epoch: 26\t[5000/79971 (6%)]\tTotal Loss: 1.8272\tAvg Loss: 0.0004\n",
      "Train Epoch: 26\t[10000/79971 (12%)]\tTotal Loss: 3.8371\tAvg Loss: 0.0004\n",
      "Train Epoch: 26\t[15000/79971 (19%)]\tTotal Loss: 6.2721\tAvg Loss: 0.0004\n",
      "Train Epoch: 26\t[20000/79971 (25%)]\tTotal Loss: 7.7553\tAvg Loss: 0.0004\n",
      "Train Epoch: 26\t[25000/79971 (31%)]\tTotal Loss: 9.7751\tAvg Loss: 0.0004\n",
      "Train Epoch: 26\t[30000/79971 (38%)]\tTotal Loss: 11.7307\tAvg Loss: 0.0004\n",
      "Train Epoch: 26\t[35000/79971 (44%)]\tTotal Loss: 13.6639\tAvg Loss: 0.0004\n",
      "Train Epoch: 26\t[40000/79971 (50%)]\tTotal Loss: 15.6516\tAvg Loss: 0.0004\n",
      "Train Epoch: 26\t[45000/79971 (56%)]\tTotal Loss: 17.5416\tAvg Loss: 0.0004\n",
      "Train Epoch: 26\t[50000/79971 (62%)]\tTotal Loss: 19.7803\tAvg Loss: 0.0004\n",
      "Train Epoch: 26\t[55000/79971 (69%)]\tTotal Loss: 21.8691\tAvg Loss: 0.0004\n",
      "Train Epoch: 26\t[60000/79971 (75%)]\tTotal Loss: 24.3104\tAvg Loss: 0.0004\n",
      "Train Epoch: 26\t[65000/79971 (81%)]\tTotal Loss: 26.3816\tAvg Loss: 0.0004\n",
      "Train Epoch: 26\t[70000/79971 (88%)]\tTotal Loss: 28.5766\tAvg Loss: 0.0004\n",
      "Train Epoch: 26\t[75000/79971 (94%)]\tTotal Loss: 30.3334\tAvg Loss: 0.0004\n",
      "====> Epoch: 26\tTotal Loss: 32.4459\t Avg Loss: 0.0004\tCorrect: 78590/79971\tPercentage Correct: 98.27\n",
      "====> Val Loss: 6.3603\t Avg Loss: 0.0007\tCorrect: 8622/8886\tPercentage Correct: 97.03\n",
      "====> Test Loss: 16.4248\t Avg Loss: 0.0007\tCorrect: 21566/22215\tPercentage Correct: 97.08\n",
      "Train Epoch: 27\t[5000/79971 (6%)]\tTotal Loss: 1.6071\tAvg Loss: 0.0003\n",
      "Train Epoch: 27\t[10000/79971 (12%)]\tTotal Loss: 3.2483\tAvg Loss: 0.0003\n",
      "Train Epoch: 27\t[15000/79971 (19%)]\tTotal Loss: 4.8145\tAvg Loss: 0.0003\n",
      "Train Epoch: 27\t[20000/79971 (25%)]\tTotal Loss: 6.5955\tAvg Loss: 0.0003\n",
      "Train Epoch: 27\t[25000/79971 (31%)]\tTotal Loss: 8.0772\tAvg Loss: 0.0003\n",
      "Train Epoch: 27\t[30000/79971 (38%)]\tTotal Loss: 9.4140\tAvg Loss: 0.0003\n",
      "Train Epoch: 27\t[35000/79971 (44%)]\tTotal Loss: 11.2041\tAvg Loss: 0.0003\n",
      "Train Epoch: 27\t[40000/79971 (50%)]\tTotal Loss: 12.7011\tAvg Loss: 0.0003\n",
      "Train Epoch: 27\t[45000/79971 (56%)]\tTotal Loss: 14.5907\tAvg Loss: 0.0003\n",
      "Train Epoch: 27\t[50000/79971 (62%)]\tTotal Loss: 16.6922\tAvg Loss: 0.0003\n",
      "Train Epoch: 27\t[55000/79971 (69%)]\tTotal Loss: 18.6083\tAvg Loss: 0.0003\n",
      "Train Epoch: 27\t[60000/79971 (75%)]\tTotal Loss: 20.8034\tAvg Loss: 0.0003\n",
      "Train Epoch: 27\t[65000/79971 (81%)]\tTotal Loss: 22.8132\tAvg Loss: 0.0004\n",
      "Train Epoch: 27\t[70000/79971 (88%)]\tTotal Loss: 24.8636\tAvg Loss: 0.0004\n",
      "Train Epoch: 27\t[75000/79971 (94%)]\tTotal Loss: 26.6043\tAvg Loss: 0.0004\n",
      "====> Epoch: 27\tTotal Loss: 28.5427\t Avg Loss: 0.0004\tCorrect: 78719/79971\tPercentage Correct: 98.43\n",
      "====> Val Loss: 11.3265\t Avg Loss: 0.0013\tCorrect: 8444/8886\tPercentage Correct: 95.03\n",
      "====> Test Loss: 31.5470\t Avg Loss: 0.0014\tCorrect: 21046/22215\tPercentage Correct: 94.74\n",
      "Train Epoch: 28\t[5000/79971 (6%)]\tTotal Loss: 1.7215\tAvg Loss: 0.0003\n",
      "Train Epoch: 28\t[10000/79971 (12%)]\tTotal Loss: 3.7403\tAvg Loss: 0.0004\n",
      "Train Epoch: 28\t[15000/79971 (19%)]\tTotal Loss: 5.8567\tAvg Loss: 0.0004\n",
      "Train Epoch: 28\t[20000/79971 (25%)]\tTotal Loss: 7.7529\tAvg Loss: 0.0004\n",
      "Train Epoch: 28\t[25000/79971 (31%)]\tTotal Loss: 10.0867\tAvg Loss: 0.0004\n",
      "Train Epoch: 28\t[30000/79971 (38%)]\tTotal Loss: 12.1844\tAvg Loss: 0.0004\n",
      "Train Epoch: 28\t[35000/79971 (44%)]\tTotal Loss: 13.9736\tAvg Loss: 0.0004\n",
      "Train Epoch: 28\t[40000/79971 (50%)]\tTotal Loss: 15.7661\tAvg Loss: 0.0004\n",
      "Train Epoch: 28\t[45000/79971 (56%)]\tTotal Loss: 17.4469\tAvg Loss: 0.0004\n",
      "Train Epoch: 28\t[50000/79971 (62%)]\tTotal Loss: 19.1206\tAvg Loss: 0.0004\n",
      "Train Epoch: 28\t[55000/79971 (69%)]\tTotal Loss: 21.0029\tAvg Loss: 0.0004\n",
      "Train Epoch: 28\t[60000/79971 (75%)]\tTotal Loss: 23.1387\tAvg Loss: 0.0004\n",
      "Train Epoch: 28\t[65000/79971 (81%)]\tTotal Loss: 25.0077\tAvg Loss: 0.0004\n",
      "Train Epoch: 28\t[70000/79971 (88%)]\tTotal Loss: 26.8088\tAvg Loss: 0.0004\n",
      "Train Epoch: 28\t[75000/79971 (94%)]\tTotal Loss: 28.4927\tAvg Loss: 0.0004\n",
      "====> Epoch: 28\tTotal Loss: 30.1662\t Avg Loss: 0.0004\tCorrect: 78649/79971\tPercentage Correct: 98.35\n",
      "====> Val Loss: 7.0794\t Avg Loss: 0.0008\tCorrect: 8621/8886\tPercentage Correct: 97.02\n",
      "====> Test Loss: 18.3664\t Avg Loss: 0.0008\tCorrect: 21509/22215\tPercentage Correct: 96.82\n",
      "Train Epoch: 29\t[5000/79971 (6%)]\tTotal Loss: 1.7416\tAvg Loss: 0.0003\n",
      "Train Epoch: 29\t[10000/79971 (12%)]\tTotal Loss: 3.8955\tAvg Loss: 0.0004\n",
      "Train Epoch: 29\t[15000/79971 (19%)]\tTotal Loss: 5.9761\tAvg Loss: 0.0004\n",
      "Train Epoch: 29\t[20000/79971 (25%)]\tTotal Loss: 7.7705\tAvg Loss: 0.0004\n",
      "Train Epoch: 29\t[25000/79971 (31%)]\tTotal Loss: 9.3735\tAvg Loss: 0.0004\n",
      "Train Epoch: 29\t[30000/79971 (38%)]\tTotal Loss: 11.2441\tAvg Loss: 0.0004\n",
      "Train Epoch: 29\t[35000/79971 (44%)]\tTotal Loss: 13.1883\tAvg Loss: 0.0004\n",
      "Train Epoch: 29\t[40000/79971 (50%)]\tTotal Loss: 15.2239\tAvg Loss: 0.0004\n",
      "Train Epoch: 29\t[45000/79971 (56%)]\tTotal Loss: 17.2860\tAvg Loss: 0.0004\n",
      "Train Epoch: 29\t[50000/79971 (62%)]\tTotal Loss: 18.9426\tAvg Loss: 0.0004\n",
      "Train Epoch: 29\t[55000/79971 (69%)]\tTotal Loss: 20.6484\tAvg Loss: 0.0004\n",
      "Train Epoch: 29\t[60000/79971 (75%)]\tTotal Loss: 22.4709\tAvg Loss: 0.0004\n",
      "Train Epoch: 29\t[65000/79971 (81%)]\tTotal Loss: 24.6584\tAvg Loss: 0.0004\n",
      "Train Epoch: 29\t[70000/79971 (88%)]\tTotal Loss: 26.6902\tAvg Loss: 0.0004\n",
      "Train Epoch: 29\t[75000/79971 (94%)]\tTotal Loss: 29.0235\tAvg Loss: 0.0004\n",
      "====> Epoch: 29\tTotal Loss: 31.0293\t Avg Loss: 0.0004\tCorrect: 78639/79971\tPercentage Correct: 98.33\n",
      "====> Val Loss: 6.9384\t Avg Loss: 0.0008\tCorrect: 8641/8886\tPercentage Correct: 97.24\n",
      "====> Test Loss: 16.4534\t Avg Loss: 0.0007\tCorrect: 21582/22215\tPercentage Correct: 97.15\n",
      "Train Epoch: 30\t[5000/79971 (6%)]\tTotal Loss: 2.0348\tAvg Loss: 0.0004\n",
      "Train Epoch: 30\t[10000/79971 (12%)]\tTotal Loss: 3.4959\tAvg Loss: 0.0003\n",
      "Train Epoch: 30\t[15000/79971 (19%)]\tTotal Loss: 5.0669\tAvg Loss: 0.0003\n",
      "Train Epoch: 30\t[20000/79971 (25%)]\tTotal Loss: 6.7958\tAvg Loss: 0.0003\n",
      "Train Epoch: 30\t[25000/79971 (31%)]\tTotal Loss: 8.4490\tAvg Loss: 0.0003\n",
      "Train Epoch: 30\t[30000/79971 (38%)]\tTotal Loss: 10.0391\tAvg Loss: 0.0003\n",
      "Train Epoch: 30\t[35000/79971 (44%)]\tTotal Loss: 11.8642\tAvg Loss: 0.0003\n",
      "Train Epoch: 30\t[40000/79971 (50%)]\tTotal Loss: 14.1131\tAvg Loss: 0.0004\n",
      "Train Epoch: 30\t[45000/79971 (56%)]\tTotal Loss: 16.2544\tAvg Loss: 0.0004\n",
      "Train Epoch: 30\t[50000/79971 (62%)]\tTotal Loss: 17.9379\tAvg Loss: 0.0004\n",
      "Train Epoch: 30\t[55000/79971 (69%)]\tTotal Loss: 19.7637\tAvg Loss: 0.0004\n",
      "Train Epoch: 30\t[60000/79971 (75%)]\tTotal Loss: 21.5066\tAvg Loss: 0.0004\n",
      "Train Epoch: 30\t[65000/79971 (81%)]\tTotal Loss: 23.0723\tAvg Loss: 0.0004\n",
      "Train Epoch: 30\t[70000/79971 (88%)]\tTotal Loss: 25.2225\tAvg Loss: 0.0004\n",
      "Train Epoch: 30\t[75000/79971 (94%)]\tTotal Loss: 27.2985\tAvg Loss: 0.0004\n",
      "====> Epoch: 30\tTotal Loss: 28.9146\t Avg Loss: 0.0004\tCorrect: 78696/79971\tPercentage Correct: 98.41\n",
      "====> Val Loss: 8.5892\t Avg Loss: 0.0010\tCorrect: 8558/8886\tPercentage Correct: 96.31\n",
      "====> Test Loss: 23.2089\t Avg Loss: 0.0010\tCorrect: 21360/22215\tPercentage Correct: 96.15\n",
      "Train Epoch: 31\t[5000/79971 (6%)]\tTotal Loss: 1.4926\tAvg Loss: 0.0003\n",
      "Train Epoch: 31\t[10000/79971 (12%)]\tTotal Loss: 3.1712\tAvg Loss: 0.0003\n",
      "Train Epoch: 31\t[15000/79971 (19%)]\tTotal Loss: 4.8715\tAvg Loss: 0.0003\n",
      "Train Epoch: 31\t[20000/79971 (25%)]\tTotal Loss: 6.4758\tAvg Loss: 0.0003\n",
      "Train Epoch: 31\t[25000/79971 (31%)]\tTotal Loss: 8.3153\tAvg Loss: 0.0003\n",
      "Train Epoch: 31\t[30000/79971 (38%)]\tTotal Loss: 10.2059\tAvg Loss: 0.0003\n",
      "Train Epoch: 31\t[35000/79971 (44%)]\tTotal Loss: 11.9652\tAvg Loss: 0.0003\n",
      "Train Epoch: 31\t[40000/79971 (50%)]\tTotal Loss: 13.7618\tAvg Loss: 0.0003\n",
      "Train Epoch: 31\t[45000/79971 (56%)]\tTotal Loss: 15.5244\tAvg Loss: 0.0003\n",
      "Train Epoch: 31\t[50000/79971 (62%)]\tTotal Loss: 17.7645\tAvg Loss: 0.0004\n",
      "Train Epoch: 31\t[55000/79971 (69%)]\tTotal Loss: 19.3779\tAvg Loss: 0.0004\n",
      "Train Epoch: 31\t[60000/79971 (75%)]\tTotal Loss: 21.2350\tAvg Loss: 0.0004\n",
      "Train Epoch: 31\t[65000/79971 (81%)]\tTotal Loss: 22.9029\tAvg Loss: 0.0004\n",
      "Train Epoch: 31\t[70000/79971 (88%)]\tTotal Loss: 24.6376\tAvg Loss: 0.0004\n",
      "Train Epoch: 31\t[75000/79971 (94%)]\tTotal Loss: 26.4519\tAvg Loss: 0.0004\n",
      "====> Epoch: 31\tTotal Loss: 28.3680\t Avg Loss: 0.0004\tCorrect: 78746/79971\tPercentage Correct: 98.47\n",
      "====> Val Loss: 6.1835\t Avg Loss: 0.0007\tCorrect: 8625/8886\tPercentage Correct: 97.06\n",
      "====> Test Loss: 15.9749\t Avg Loss: 0.0007\tCorrect: 21527/22215\tPercentage Correct: 96.90\n",
      "Train Epoch: 32\t[5000/79971 (6%)]\tTotal Loss: 1.7005\tAvg Loss: 0.0003\n",
      "Train Epoch: 32\t[10000/79971 (12%)]\tTotal Loss: 3.3277\tAvg Loss: 0.0003\n",
      "Train Epoch: 32\t[15000/79971 (19%)]\tTotal Loss: 5.3412\tAvg Loss: 0.0004\n",
      "Train Epoch: 32\t[20000/79971 (25%)]\tTotal Loss: 6.9475\tAvg Loss: 0.0003\n",
      "Train Epoch: 32\t[25000/79971 (31%)]\tTotal Loss: 8.6870\tAvg Loss: 0.0003\n",
      "Train Epoch: 32\t[30000/79971 (38%)]\tTotal Loss: 10.2187\tAvg Loss: 0.0003\n",
      "Train Epoch: 32\t[35000/79971 (44%)]\tTotal Loss: 11.6126\tAvg Loss: 0.0003\n",
      "Train Epoch: 32\t[40000/79971 (50%)]\tTotal Loss: 13.2383\tAvg Loss: 0.0003\n",
      "Train Epoch: 32\t[45000/79971 (56%)]\tTotal Loss: 14.9497\tAvg Loss: 0.0003\n",
      "Train Epoch: 32\t[50000/79971 (62%)]\tTotal Loss: 16.6835\tAvg Loss: 0.0003\n",
      "Train Epoch: 32\t[55000/79971 (69%)]\tTotal Loss: 18.7381\tAvg Loss: 0.0003\n",
      "Train Epoch: 32\t[60000/79971 (75%)]\tTotal Loss: 20.4968\tAvg Loss: 0.0003\n",
      "Train Epoch: 32\t[65000/79971 (81%)]\tTotal Loss: 22.8194\tAvg Loss: 0.0004\n",
      "Train Epoch: 32\t[70000/79971 (88%)]\tTotal Loss: 24.8503\tAvg Loss: 0.0004\n",
      "Train Epoch: 32\t[75000/79971 (94%)]\tTotal Loss: 26.7791\tAvg Loss: 0.0004\n",
      "====> Epoch: 32\tTotal Loss: 28.6117\t Avg Loss: 0.0004\tCorrect: 78775/79971\tPercentage Correct: 98.50\n",
      "====> Val Loss: 20.3110\t Avg Loss: 0.0023\tCorrect: 8243/8886\tPercentage Correct: 92.76\n",
      "====> Test Loss: 53.4317\t Avg Loss: 0.0024\tCorrect: 20571/22215\tPercentage Correct: 92.60\n",
      "Train Epoch: 33\t[5000/79971 (6%)]\tTotal Loss: 2.0552\tAvg Loss: 0.0004\n",
      "Train Epoch: 33\t[10000/79971 (12%)]\tTotal Loss: 3.5360\tAvg Loss: 0.0004\n",
      "Train Epoch: 33\t[15000/79971 (19%)]\tTotal Loss: 5.2057\tAvg Loss: 0.0003\n",
      "Train Epoch: 33\t[20000/79971 (25%)]\tTotal Loss: 6.3635\tAvg Loss: 0.0003\n",
      "Train Epoch: 33\t[25000/79971 (31%)]\tTotal Loss: 8.0568\tAvg Loss: 0.0003\n",
      "Train Epoch: 33\t[30000/79971 (38%)]\tTotal Loss: 9.5659\tAvg Loss: 0.0003\n",
      "Train Epoch: 33\t[35000/79971 (44%)]\tTotal Loss: 11.1550\tAvg Loss: 0.0003\n",
      "Train Epoch: 33\t[40000/79971 (50%)]\tTotal Loss: 12.8093\tAvg Loss: 0.0003\n",
      "Train Epoch: 33\t[45000/79971 (56%)]\tTotal Loss: 14.4276\tAvg Loss: 0.0003\n",
      "Train Epoch: 33\t[50000/79971 (62%)]\tTotal Loss: 15.9528\tAvg Loss: 0.0003\n",
      "Train Epoch: 33\t[55000/79971 (69%)]\tTotal Loss: 17.8317\tAvg Loss: 0.0003\n",
      "Train Epoch: 33\t[60000/79971 (75%)]\tTotal Loss: 19.6168\tAvg Loss: 0.0003\n",
      "Train Epoch: 33\t[65000/79971 (81%)]\tTotal Loss: 21.9980\tAvg Loss: 0.0003\n",
      "Train Epoch: 33\t[70000/79971 (88%)]\tTotal Loss: 23.9300\tAvg Loss: 0.0003\n",
      "Train Epoch: 33\t[75000/79971 (94%)]\tTotal Loss: 25.7858\tAvg Loss: 0.0003\n",
      "====> Epoch: 33\tTotal Loss: 27.5410\t Avg Loss: 0.0003\tCorrect: 78808/79971\tPercentage Correct: 98.55\n",
      "====> Val Loss: 22.5076\t Avg Loss: 0.0025\tCorrect: 8256/8886\tPercentage Correct: 92.91\n",
      "====> Test Loss: 56.3740\t Avg Loss: 0.0025\tCorrect: 20584/22215\tPercentage Correct: 92.66\n",
      "Train Epoch: 34\t[5000/79971 (6%)]\tTotal Loss: 1.5747\tAvg Loss: 0.0003\n",
      "Train Epoch: 34\t[10000/79971 (12%)]\tTotal Loss: 3.2339\tAvg Loss: 0.0003\n",
      "Train Epoch: 34\t[15000/79971 (19%)]\tTotal Loss: 4.6001\tAvg Loss: 0.0003\n",
      "Train Epoch: 34\t[20000/79971 (25%)]\tTotal Loss: 6.1572\tAvg Loss: 0.0003\n",
      "Train Epoch: 34\t[25000/79971 (31%)]\tTotal Loss: 7.7861\tAvg Loss: 0.0003\n",
      "Train Epoch: 34\t[30000/79971 (38%)]\tTotal Loss: 9.3294\tAvg Loss: 0.0003\n",
      "Train Epoch: 34\t[35000/79971 (44%)]\tTotal Loss: 11.0125\tAvg Loss: 0.0003\n",
      "Train Epoch: 34\t[40000/79971 (50%)]\tTotal Loss: 12.6845\tAvg Loss: 0.0003\n",
      "Train Epoch: 34\t[45000/79971 (56%)]\tTotal Loss: 14.5280\tAvg Loss: 0.0003\n",
      "Train Epoch: 34\t[50000/79971 (62%)]\tTotal Loss: 15.9606\tAvg Loss: 0.0003\n",
      "Train Epoch: 34\t[55000/79971 (69%)]\tTotal Loss: 17.5450\tAvg Loss: 0.0003\n",
      "Train Epoch: 34\t[60000/79971 (75%)]\tTotal Loss: 19.1409\tAvg Loss: 0.0003\n",
      "Train Epoch: 34\t[65000/79971 (81%)]\tTotal Loss: 20.5572\tAvg Loss: 0.0003\n",
      "Train Epoch: 34\t[70000/79971 (88%)]\tTotal Loss: 22.1274\tAvg Loss: 0.0003\n",
      "Train Epoch: 34\t[75000/79971 (94%)]\tTotal Loss: 23.9995\tAvg Loss: 0.0003\n",
      "====> Epoch: 34\tTotal Loss: 26.0552\t Avg Loss: 0.0003\tCorrect: 78856/79971\tPercentage Correct: 98.61\n",
      "====> Val Loss: 27.7109\t Avg Loss: 0.0031\tCorrect: 8116/8886\tPercentage Correct: 91.33\n",
      "====> Test Loss: 73.4911\t Avg Loss: 0.0033\tCorrect: 20230/22215\tPercentage Correct: 91.06\n",
      "Train Epoch: 35\t[5000/79971 (6%)]\tTotal Loss: 1.7261\tAvg Loss: 0.0003\n",
      "Train Epoch: 35\t[10000/79971 (12%)]\tTotal Loss: 3.4233\tAvg Loss: 0.0003\n",
      "Train Epoch: 35\t[15000/79971 (19%)]\tTotal Loss: 5.1153\tAvg Loss: 0.0003\n",
      "Train Epoch: 35\t[20000/79971 (25%)]\tTotal Loss: 6.6932\tAvg Loss: 0.0003\n",
      "Train Epoch: 35\t[25000/79971 (31%)]\tTotal Loss: 8.2054\tAvg Loss: 0.0003\n",
      "Train Epoch: 35\t[30000/79971 (38%)]\tTotal Loss: 9.9046\tAvg Loss: 0.0003\n",
      "Train Epoch: 35\t[35000/79971 (44%)]\tTotal Loss: 11.5443\tAvg Loss: 0.0003\n",
      "Train Epoch: 35\t[40000/79971 (50%)]\tTotal Loss: 13.3032\tAvg Loss: 0.0003\n",
      "Train Epoch: 35\t[45000/79971 (56%)]\tTotal Loss: 14.9392\tAvg Loss: 0.0003\n",
      "Train Epoch: 35\t[50000/79971 (62%)]\tTotal Loss: 16.6439\tAvg Loss: 0.0003\n",
      "Train Epoch: 35\t[55000/79971 (69%)]\tTotal Loss: 18.9264\tAvg Loss: 0.0003\n",
      "Train Epoch: 35\t[60000/79971 (75%)]\tTotal Loss: 21.0115\tAvg Loss: 0.0004\n",
      "Train Epoch: 35\t[65000/79971 (81%)]\tTotal Loss: 22.8310\tAvg Loss: 0.0004\n",
      "Train Epoch: 35\t[70000/79971 (88%)]\tTotal Loss: 24.6803\tAvg Loss: 0.0004\n",
      "Train Epoch: 35\t[75000/79971 (94%)]\tTotal Loss: 26.4357\tAvg Loss: 0.0004\n",
      "====> Epoch: 35\tTotal Loss: 28.0413\t Avg Loss: 0.0004\tCorrect: 78793/79971\tPercentage Correct: 98.53\n",
      "====> Val Loss: 10.2648\t Avg Loss: 0.0012\tCorrect: 8521/8886\tPercentage Correct: 95.89\n",
      "====> Test Loss: 26.0853\t Avg Loss: 0.0012\tCorrect: 21282/22215\tPercentage Correct: 95.80\n",
      "\n",
      "--- early stop ---\n",
      "\n",
      "Training time: 20269.557193994522s\n"
     ]
    }
   ],
   "source": [
    "# TRAIN and TEST FxNet OVER MULTIPLE EPOCHS\n",
    "train_set_size = len(split.train_sampler)\n",
    "val_set_size = len(split.val_sampler)\n",
    "test_set_size = len(split.test_sampler)\n",
    "\n",
    "all_train_losses, all_val_losses, all_test_losses = [],[],[]\n",
    "all_train_correct, all_val_correct, all_test_correct = [],[],[]\n",
    "all_train_results, all_val_results, all_test_results = [],[],[]\n",
    "\n",
    "best_val_correct = 0\n",
    "early_stop_counter = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss, train_correct, train_results = trainer.train_fx_net(\n",
    "        model=fxnet,\n",
    "        optimizer=optimizer_fxnet, \n",
    "        train_loader=train_loader, \n",
    "        train_sampler=split.train_sampler, \n",
    "        epoch=epoch, \n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    val_loss, val_correct, val_results = trainer.val_fx_net(\n",
    "        model=fxnet, \n",
    "        val_loader=val_loader, \n",
    "        val_sampler=split.val_sampler, \n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    test_loss, test_correct, test_results = trainer.test_fx_net(\n",
    "        model=fxnet, \n",
    "        test_loader=test_loader, \n",
    "        test_sampler=split.test_sampler, \n",
    "        device=device\n",
    "    )\n",
    "    # save model\n",
    "    if val_correct > best_val_correct:\n",
    "        best_val_correct = val_correct\n",
    "        torch.save(fxnet, '%s/%s' % (models_folder, model_name))\n",
    "        early_stop_counter = 0\n",
    "        print('\\n=== saved best model ===\\n')\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        \n",
    "    # append results\n",
    "    all_train_losses.append(train_loss)\n",
    "    all_val_losses.append(val_loss)\n",
    "    all_test_losses.append(test_loss)\n",
    "    \n",
    "    all_train_correct.append(train_correct)\n",
    "    all_val_correct.append(val_correct)\n",
    "    all_test_correct.append(test_correct)\n",
    "    \n",
    "    all_train_results.append(train_results)\n",
    "    all_val_results.append(val_results)\n",
    "    all_test_results.append(test_results)\n",
    "\n",
    "    if early_stop_counter == 15:\n",
    "        print('\\n--- early stop ---\\n')\n",
    "        break\n",
    "\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Accuracy:  98.60574458241112\nEpoch:  34\n\nVal Accuracy:  97.33288318703579\nEpoch:  20\n\nTest Accuracy:  97.15057393652937\nEpoch:  29\n\n"
     ]
    }
   ],
   "source": [
    "# BEST RESULTS\n",
    "print('Train Accuracy: ', 100 * max(all_train_correct) / train_set_size)\n",
    "print('Epoch: ', np.argmax(all_train_correct))\n",
    "print()\n",
    "print('Val Accuracy: ', 100 * max(all_val_correct) / val_set_size)\n",
    "print('Epoch: ', np.argmax(all_val_correct))\n",
    "print()\n",
    "print('Test Accuracy: ', 100 * max(all_test_correct) / test_set_size)\n",
    "print('Epoch: ', np.argmax(all_test_correct))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE RESULTS - all losses, all correct, best results\n",
    "all_train_losses_npy = np.array(all_train_losses)\n",
    "all_train_correct_npy = np.array(all_train_correct)\n",
    "best_train_results_npy = np.array(all_train_results[20])\n",
    "\n",
    "all_val_losses_npy = np.array(all_val_losses)\n",
    "all_val_correct_npy = np.array(all_val_correct)\n",
    "best_val_results_npy = np.array(all_val_results[20])\n",
    "\n",
    "all_test_losses_npy = np.array(all_test_losses)\n",
    "all_test_correct_npy = np.array(all_test_correct)\n",
    "best_test_results_npy = np.array(all_test_results[20])\n",
    "\n",
    "fx_labels_npy = np.array(list(dataset.fx_to_label.keys()))\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_train_losses')), arr=all_train_losses_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_train_correct')), arr=all_train_correct_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'best_train_results')), arr=best_train_results_npy)\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_val_losses')), arr=all_val_losses_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_val_correct')), arr=all_val_correct_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'best_val_results')), arr=best_val_results_npy)\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_test_losses')), arr=all_test_losses_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_test_correct')), arr=all_test_correct_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'best_test_results')), arr=best_test_results_npy)\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'fx_labels')), arr=fx_labels_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "d8d8ede0c763ce977430036d480dcd796d93873b3cf6a7515802d811734aa2cd"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}