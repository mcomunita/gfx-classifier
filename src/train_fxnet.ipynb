{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dataset.dataset as dataset\n",
    "import datasplit.datasplit as datasplit\n",
    "import model.models as models\n",
    "import trainer.trainer as trainer\n",
    "import utils.utils as utils\n",
    "\n",
    "torch.cuda.device_count()\n",
    "cuda0 = torch.device('cuda:0')\n",
    "cuda1 = torch.device('cuda:1')\n",
    "cuda2 = torch.device('cuda:2')\n",
    "cuda3 = torch.device('cuda:3')\n",
    "device = torch.device(cuda0 if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "source": [
    "### INIT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "# dataset\n",
    "root = '/Volumes/Macintosh HD/DATASETS/GUITAR-FX/Mono'\n",
    "excl_folders = ['NoFX_mono', 'NoFX_mono_preprocessed']\n",
    "spectra_folder= 'mel_22050_1024_512'\n",
    "proc_settings_csv = 'proc_settings.csv'\n",
    "max_num_settings=6\n",
    "\n",
    "dataset = dataset.FxDataset(root=root,\n",
    "                            excl_folders=excl_folders, \n",
    "                            spectra_folder=spectra_folder, \n",
    "                            processed_settings_csv=proc_settings_csv,\n",
    "                            max_num_settings=max_num_settings,\n",
    "                            transform=transform)\n",
    "dataset.init_dataset()\n",
    "# dataset.generate_mel()\n",
    "\n",
    "# split\n",
    "# set test_train_split=0.0 and val_train_split=0.0 to test pre-trained model\n",
    "split = datasplit.DataSplit(dataset, test_train_split=0.8, val_train_split=0.1, shuffle=True)\n",
    "# loaders\n",
    "train_loader, val_loader, test_loader = split.get_split(batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dataset size:  163488\ntrain set size:  117711\nval set size:  13079\ntest set size:  32698\n"
     ]
    }
   ],
   "source": [
    "print('dataset size: ', len(dataset))\n",
    "print('train set size: ', len(split.train_sampler))\n",
    "print('val set size: ', len(split.val_sampler))\n",
    "print('test set size: ', len(split.test_sampler))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN FxNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "fxnet = models.FxNet(n_classes=dataset.num_fx).to(device)\n",
    "# optimizer\n",
    "optimizer_fxnet = optim.Adam(fxnet.parameters(), lr=0.001)\n",
    "# loss function\n",
    "loss_func_fxnet = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FxNet(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (batchNorm1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n  (batchNorm2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (fc1): Linear(in_features=6264, out_features=120, bias=True)\n  (batchNorm3): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (fc2): Linear(in_features=120, out_features=60, bias=True)\n  (batchNorm4): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (out): Linear(in_features=60, out_features=14, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "print(fxnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE\n",
    "models_folder = 'saved_models'\n",
    "model_name = '20201008_fxnet_best'\n",
    "results_folder = 'saved_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 0\t[2000/117711 (2%)]\tTotal Loss: 49.9333\tAvg Loss: 0.0250\n",
      "Train Epoch: 0\t[4000/117711 (3%)]\tTotal Loss: 88.9361\tAvg Loss: 0.0222\n",
      "Train Epoch: 0\t[6000/117711 (5%)]\tTotal Loss: 122.3618\tAvg Loss: 0.0204\n",
      "Train Epoch: 0\t[8000/117711 (7%)]\tTotal Loss: 152.3350\tAvg Loss: 0.0190\n",
      "Train Epoch: 0\t[10000/117711 (8%)]\tTotal Loss: 180.2528\tAvg Loss: 0.0180\n",
      "Train Epoch: 0\t[12000/117711 (10%)]\tTotal Loss: 204.9772\tAvg Loss: 0.0171\n",
      "Train Epoch: 0\t[14000/117711 (12%)]\tTotal Loss: 228.4171\tAvg Loss: 0.0163\n",
      "Train Epoch: 0\t[16000/117711 (14%)]\tTotal Loss: 249.1776\tAvg Loss: 0.0156\n",
      "Train Epoch: 0\t[18000/117711 (15%)]\tTotal Loss: 269.8136\tAvg Loss: 0.0150\n",
      "Train Epoch: 0\t[20000/117711 (17%)]\tTotal Loss: 289.2927\tAvg Loss: 0.0145\n",
      "Train Epoch: 0\t[22000/117711 (19%)]\tTotal Loss: 307.5866\tAvg Loss: 0.0140\n",
      "Train Epoch: 0\t[24000/117711 (20%)]\tTotal Loss: 325.8063\tAvg Loss: 0.0136\n",
      "Train Epoch: 0\t[26000/117711 (22%)]\tTotal Loss: 343.0937\tAvg Loss: 0.0132\n",
      "Train Epoch: 0\t[28000/117711 (24%)]\tTotal Loss: 359.1340\tAvg Loss: 0.0128\n",
      "Train Epoch: 0\t[30000/117711 (25%)]\tTotal Loss: 374.5579\tAvg Loss: 0.0125\n",
      "Train Epoch: 0\t[32000/117711 (27%)]\tTotal Loss: 389.4871\tAvg Loss: 0.0122\n",
      "Train Epoch: 0\t[34000/117711 (29%)]\tTotal Loss: 403.9200\tAvg Loss: 0.0119\n",
      "Train Epoch: 0\t[36000/117711 (31%)]\tTotal Loss: 418.0170\tAvg Loss: 0.0116\n",
      "Train Epoch: 0\t[38000/117711 (32%)]\tTotal Loss: 431.8900\tAvg Loss: 0.0114\n",
      "Train Epoch: 0\t[40000/117711 (34%)]\tTotal Loss: 445.7322\tAvg Loss: 0.0111\n",
      "Train Epoch: 0\t[42000/117711 (36%)]\tTotal Loss: 458.7316\tAvg Loss: 0.0109\n",
      "Train Epoch: 0\t[44000/117711 (37%)]\tTotal Loss: 471.6543\tAvg Loss: 0.0107\n",
      "Train Epoch: 0\t[46000/117711 (39%)]\tTotal Loss: 483.9982\tAvg Loss: 0.0105\n",
      "Train Epoch: 0\t[48000/117711 (41%)]\tTotal Loss: 495.8511\tAvg Loss: 0.0103\n",
      "Train Epoch: 0\t[50000/117711 (42%)]\tTotal Loss: 507.5608\tAvg Loss: 0.0102\n",
      "Train Epoch: 0\t[52000/117711 (44%)]\tTotal Loss: 519.0263\tAvg Loss: 0.0100\n",
      "Train Epoch: 0\t[54000/117711 (46%)]\tTotal Loss: 530.5410\tAvg Loss: 0.0098\n",
      "Train Epoch: 0\t[56000/117711 (48%)]\tTotal Loss: 541.4494\tAvg Loss: 0.0097\n",
      "Train Epoch: 0\t[58000/117711 (49%)]\tTotal Loss: 552.4975\tAvg Loss: 0.0095\n",
      "Train Epoch: 0\t[60000/117711 (51%)]\tTotal Loss: 563.0809\tAvg Loss: 0.0094\n",
      "Train Epoch: 0\t[62000/117711 (53%)]\tTotal Loss: 572.7976\tAvg Loss: 0.0092\n",
      "Train Epoch: 0\t[64000/117711 (54%)]\tTotal Loss: 583.1550\tAvg Loss: 0.0091\n",
      "Train Epoch: 0\t[66000/117711 (56%)]\tTotal Loss: 593.5284\tAvg Loss: 0.0090\n",
      "Train Epoch: 0\t[68000/117711 (58%)]\tTotal Loss: 603.2519\tAvg Loss: 0.0089\n",
      "Train Epoch: 0\t[70000/117711 (59%)]\tTotal Loss: 613.0062\tAvg Loss: 0.0088\n",
      "Train Epoch: 0\t[72000/117711 (61%)]\tTotal Loss: 622.5591\tAvg Loss: 0.0086\n",
      "Train Epoch: 0\t[74000/117711 (63%)]\tTotal Loss: 631.3733\tAvg Loss: 0.0085\n",
      "Train Epoch: 0\t[76000/117711 (65%)]\tTotal Loss: 639.8030\tAvg Loss: 0.0084\n",
      "Train Epoch: 0\t[78000/117711 (66%)]\tTotal Loss: 649.0392\tAvg Loss: 0.0083\n",
      "Train Epoch: 0\t[80000/117711 (68%)]\tTotal Loss: 658.2570\tAvg Loss: 0.0082\n",
      "Train Epoch: 0\t[82000/117711 (70%)]\tTotal Loss: 666.7648\tAvg Loss: 0.0081\n",
      "Train Epoch: 0\t[84000/117711 (71%)]\tTotal Loss: 676.0225\tAvg Loss: 0.0080\n",
      "Train Epoch: 0\t[86000/117711 (73%)]\tTotal Loss: 685.1072\tAvg Loss: 0.0080\n",
      "Train Epoch: 0\t[88000/117711 (75%)]\tTotal Loss: 694.0038\tAvg Loss: 0.0079\n",
      "Train Epoch: 0\t[90000/117711 (76%)]\tTotal Loss: 702.3024\tAvg Loss: 0.0078\n",
      "Train Epoch: 0\t[92000/117711 (78%)]\tTotal Loss: 710.1050\tAvg Loss: 0.0077\n",
      "Train Epoch: 0\t[94000/117711 (80%)]\tTotal Loss: 718.8648\tAvg Loss: 0.0076\n",
      "Train Epoch: 0\t[96000/117711 (81%)]\tTotal Loss: 728.0119\tAvg Loss: 0.0076\n",
      "Train Epoch: 0\t[98000/117711 (83%)]\tTotal Loss: 736.0341\tAvg Loss: 0.0075\n",
      "Train Epoch: 0\t[100000/117711 (85%)]\tTotal Loss: 744.6553\tAvg Loss: 0.0074\n",
      "Train Epoch: 0\t[102000/117711 (87%)]\tTotal Loss: 752.7118\tAvg Loss: 0.0074\n",
      "Train Epoch: 0\t[104000/117711 (88%)]\tTotal Loss: 760.8966\tAvg Loss: 0.0073\n",
      "Train Epoch: 0\t[106000/117711 (90%)]\tTotal Loss: 769.2605\tAvg Loss: 0.0073\n",
      "Train Epoch: 0\t[108000/117711 (92%)]\tTotal Loss: 777.4848\tAvg Loss: 0.0072\n",
      "Train Epoch: 0\t[110000/117711 (93%)]\tTotal Loss: 785.3537\tAvg Loss: 0.0071\n",
      "Train Epoch: 0\t[112000/117711 (95%)]\tTotal Loss: 793.0484\tAvg Loss: 0.0071\n",
      "Train Epoch: 0\t[114000/117711 (97%)]\tTotal Loss: 800.6222\tAvg Loss: 0.0070\n",
      "Train Epoch: 0\t[116000/117711 (98%)]\tTotal Loss: 808.1373\tAvg Loss: 0.0070\n",
      "====> Epoch: 0\tTotal Loss: 814.1994\t Avg Loss: 0.0069\tCorrect: 87218/117711\tPercentage Correct: 74.10\n",
      "====> Val Loss: 110.7427\t Avg Loss: 0.0085\tCorrect: 8886/13079\tPercentage Correct: 67.94\n",
      "====> Test Loss: 276.9467\t Avg Loss: 0.0085\tCorrect: 22296/32698\tPercentage Correct: 68.19\n",
      "--- saved best model ---\n",
      "Train Epoch: 1\t[2000/117711 (2%)]\tTotal Loss: 8.2156\tAvg Loss: 0.0041\n",
      "Train Epoch: 1\t[4000/117711 (3%)]\tTotal Loss: 15.5230\tAvg Loss: 0.0039\n",
      "Train Epoch: 1\t[6000/117711 (5%)]\tTotal Loss: 22.4307\tAvg Loss: 0.0037\n",
      "Train Epoch: 1\t[8000/117711 (7%)]\tTotal Loss: 29.2104\tAvg Loss: 0.0037\n",
      "Train Epoch: 1\t[10000/117711 (8%)]\tTotal Loss: 35.7493\tAvg Loss: 0.0036\n",
      "Train Epoch: 1\t[12000/117711 (10%)]\tTotal Loss: 42.4210\tAvg Loss: 0.0035\n",
      "Train Epoch: 1\t[14000/117711 (12%)]\tTotal Loss: 49.4333\tAvg Loss: 0.0035\n",
      "Train Epoch: 1\t[16000/117711 (14%)]\tTotal Loss: 56.6205\tAvg Loss: 0.0035\n",
      "Train Epoch: 1\t[18000/117711 (15%)]\tTotal Loss: 62.9613\tAvg Loss: 0.0035\n",
      "Train Epoch: 1\t[20000/117711 (17%)]\tTotal Loss: 69.4834\tAvg Loss: 0.0035\n",
      "Train Epoch: 1\t[22000/117711 (19%)]\tTotal Loss: 75.6072\tAvg Loss: 0.0034\n",
      "Train Epoch: 1\t[24000/117711 (20%)]\tTotal Loss: 82.2096\tAvg Loss: 0.0034\n",
      "Train Epoch: 1\t[26000/117711 (22%)]\tTotal Loss: 88.2184\tAvg Loss: 0.0034\n",
      "Train Epoch: 1\t[28000/117711 (24%)]\tTotal Loss: 94.5616\tAvg Loss: 0.0034\n",
      "Train Epoch: 1\t[30000/117711 (25%)]\tTotal Loss: 101.4153\tAvg Loss: 0.0034\n",
      "Train Epoch: 1\t[32000/117711 (27%)]\tTotal Loss: 107.9465\tAvg Loss: 0.0034\n",
      "Train Epoch: 1\t[34000/117711 (29%)]\tTotal Loss: 114.5310\tAvg Loss: 0.0034\n",
      "Train Epoch: 1\t[36000/117711 (31%)]\tTotal Loss: 120.8194\tAvg Loss: 0.0034\n",
      "Train Epoch: 1\t[38000/117711 (32%)]\tTotal Loss: 126.7521\tAvg Loss: 0.0033\n",
      "Train Epoch: 1\t[40000/117711 (34%)]\tTotal Loss: 133.0831\tAvg Loss: 0.0033\n",
      "Train Epoch: 1\t[42000/117711 (36%)]\tTotal Loss: 139.2586\tAvg Loss: 0.0033\n",
      "Train Epoch: 1\t[44000/117711 (37%)]\tTotal Loss: 145.7460\tAvg Loss: 0.0033\n",
      "Train Epoch: 1\t[46000/117711 (39%)]\tTotal Loss: 151.9170\tAvg Loss: 0.0033\n",
      "Train Epoch: 1\t[48000/117711 (41%)]\tTotal Loss: 158.4076\tAvg Loss: 0.0033\n",
      "Train Epoch: 1\t[50000/117711 (42%)]\tTotal Loss: 164.3966\tAvg Loss: 0.0033\n",
      "Train Epoch: 1\t[52000/117711 (44%)]\tTotal Loss: 170.6454\tAvg Loss: 0.0033\n",
      "Train Epoch: 1\t[54000/117711 (46%)]\tTotal Loss: 177.0140\tAvg Loss: 0.0033\n",
      "Train Epoch: 1\t[56000/117711 (48%)]\tTotal Loss: 183.0418\tAvg Loss: 0.0033\n",
      "Train Epoch: 1\t[58000/117711 (49%)]\tTotal Loss: 188.8635\tAvg Loss: 0.0033\n",
      "Train Epoch: 1\t[60000/117711 (51%)]\tTotal Loss: 195.0749\tAvg Loss: 0.0033\n",
      "Train Epoch: 1\t[62000/117711 (53%)]\tTotal Loss: 200.9501\tAvg Loss: 0.0032\n",
      "Train Epoch: 1\t[64000/117711 (54%)]\tTotal Loss: 207.1224\tAvg Loss: 0.0032\n",
      "Train Epoch: 1\t[66000/117711 (56%)]\tTotal Loss: 213.0002\tAvg Loss: 0.0032\n",
      "Train Epoch: 1\t[68000/117711 (58%)]\tTotal Loss: 219.1385\tAvg Loss: 0.0032\n",
      "Train Epoch: 1\t[70000/117711 (59%)]\tTotal Loss: 225.0533\tAvg Loss: 0.0032\n",
      "Train Epoch: 1\t[72000/117711 (61%)]\tTotal Loss: 230.8116\tAvg Loss: 0.0032\n",
      "Train Epoch: 1\t[74000/117711 (63%)]\tTotal Loss: 236.2227\tAvg Loss: 0.0032\n",
      "Train Epoch: 1\t[76000/117711 (65%)]\tTotal Loss: 242.1381\tAvg Loss: 0.0032\n",
      "Train Epoch: 1\t[78000/117711 (66%)]\tTotal Loss: 248.1872\tAvg Loss: 0.0032\n",
      "Train Epoch: 1\t[80000/117711 (68%)]\tTotal Loss: 254.4338\tAvg Loss: 0.0032\n",
      "Train Epoch: 1\t[82000/117711 (70%)]\tTotal Loss: 260.4400\tAvg Loss: 0.0032\n",
      "Train Epoch: 1\t[84000/117711 (71%)]\tTotal Loss: 266.1428\tAvg Loss: 0.0032\n",
      "Train Epoch: 1\t[86000/117711 (73%)]\tTotal Loss: 272.2731\tAvg Loss: 0.0032\n",
      "Train Epoch: 1\t[88000/117711 (75%)]\tTotal Loss: 277.9253\tAvg Loss: 0.0032\n",
      "Train Epoch: 1\t[90000/117711 (76%)]\tTotal Loss: 283.9339\tAvg Loss: 0.0032\n",
      "Train Epoch: 1\t[92000/117711 (78%)]\tTotal Loss: 289.6828\tAvg Loss: 0.0031\n",
      "Train Epoch: 1\t[94000/117711 (80%)]\tTotal Loss: 295.4446\tAvg Loss: 0.0031\n",
      "Train Epoch: 1\t[96000/117711 (81%)]\tTotal Loss: 301.9205\tAvg Loss: 0.0031\n",
      "Train Epoch: 1\t[98000/117711 (83%)]\tTotal Loss: 307.9004\tAvg Loss: 0.0031\n",
      "Train Epoch: 1\t[100000/117711 (85%)]\tTotal Loss: 313.4347\tAvg Loss: 0.0031\n",
      "Train Epoch: 1\t[102000/117711 (87%)]\tTotal Loss: 318.8041\tAvg Loss: 0.0031\n",
      "Train Epoch: 1\t[104000/117711 (88%)]\tTotal Loss: 324.5712\tAvg Loss: 0.0031\n",
      "Train Epoch: 1\t[106000/117711 (90%)]\tTotal Loss: 330.3157\tAvg Loss: 0.0031\n",
      "Train Epoch: 1\t[108000/117711 (92%)]\tTotal Loss: 335.9441\tAvg Loss: 0.0031\n",
      "Train Epoch: 1\t[110000/117711 (93%)]\tTotal Loss: 341.8508\tAvg Loss: 0.0031\n",
      "Train Epoch: 1\t[112000/117711 (95%)]\tTotal Loss: 347.1149\tAvg Loss: 0.0031\n",
      "Train Epoch: 1\t[114000/117711 (97%)]\tTotal Loss: 353.2269\tAvg Loss: 0.0031\n",
      "Train Epoch: 1\t[116000/117711 (98%)]\tTotal Loss: 358.7307\tAvg Loss: 0.0031\n",
      "====> Epoch: 1\tTotal Loss: 363.2974\t Avg Loss: 0.0031\tCorrect: 100504/117711\tPercentage Correct: 85.38\n",
      "====> Val Loss: 115.0170\t Avg Loss: 0.0088\tCorrect: 9142/13079\tPercentage Correct: 69.90\n",
      "====> Test Loss: 291.4830\t Avg Loss: 0.0089\tCorrect: 22628/32698\tPercentage Correct: 69.20\n",
      "--- saved best model ---\n",
      "Train Epoch: 2\t[2000/117711 (2%)]\tTotal Loss: 5.4878\tAvg Loss: 0.0027\n",
      "Train Epoch: 2\t[4000/117711 (3%)]\tTotal Loss: 10.5567\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[6000/117711 (5%)]\tTotal Loss: 15.4189\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[8000/117711 (7%)]\tTotal Loss: 20.5919\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[10000/117711 (8%)]\tTotal Loss: 25.6568\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[12000/117711 (10%)]\tTotal Loss: 30.7326\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[14000/117711 (12%)]\tTotal Loss: 35.8685\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[16000/117711 (14%)]\tTotal Loss: 41.0801\tAvg Loss: 0.0026\n",
      "Train Epoch: 2\t[18000/117711 (15%)]\tTotal Loss: 45.8369\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[20000/117711 (17%)]\tTotal Loss: 50.5319\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[22000/117711 (19%)]\tTotal Loss: 55.4776\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[24000/117711 (20%)]\tTotal Loss: 60.1583\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[26000/117711 (22%)]\tTotal Loss: 65.5380\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[28000/117711 (24%)]\tTotal Loss: 71.0929\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[30000/117711 (25%)]\tTotal Loss: 76.2218\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[32000/117711 (27%)]\tTotal Loss: 81.2016\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[34000/117711 (29%)]\tTotal Loss: 86.0344\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[36000/117711 (31%)]\tTotal Loss: 90.9594\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[38000/117711 (32%)]\tTotal Loss: 95.6637\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[40000/117711 (34%)]\tTotal Loss: 100.2214\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[42000/117711 (36%)]\tTotal Loss: 105.3771\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[44000/117711 (37%)]\tTotal Loss: 110.5512\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[46000/117711 (39%)]\tTotal Loss: 115.7059\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[48000/117711 (41%)]\tTotal Loss: 120.2534\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[50000/117711 (42%)]\tTotal Loss: 124.8111\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[52000/117711 (44%)]\tTotal Loss: 129.7578\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[54000/117711 (46%)]\tTotal Loss: 134.5773\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[56000/117711 (48%)]\tTotal Loss: 139.7050\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[58000/117711 (49%)]\tTotal Loss: 144.7957\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[60000/117711 (51%)]\tTotal Loss: 150.1657\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[62000/117711 (53%)]\tTotal Loss: 155.3322\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[64000/117711 (54%)]\tTotal Loss: 160.2232\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[66000/117711 (56%)]\tTotal Loss: 165.1481\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[68000/117711 (58%)]\tTotal Loss: 170.0499\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[70000/117711 (59%)]\tTotal Loss: 174.8419\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[72000/117711 (61%)]\tTotal Loss: 179.6096\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[74000/117711 (63%)]\tTotal Loss: 184.3283\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[76000/117711 (65%)]\tTotal Loss: 189.4282\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[78000/117711 (66%)]\tTotal Loss: 194.5605\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[80000/117711 (68%)]\tTotal Loss: 199.6497\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[82000/117711 (70%)]\tTotal Loss: 204.4453\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[84000/117711 (71%)]\tTotal Loss: 208.7071\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[86000/117711 (73%)]\tTotal Loss: 213.6696\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[88000/117711 (75%)]\tTotal Loss: 218.3386\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[90000/117711 (76%)]\tTotal Loss: 223.0922\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[92000/117711 (78%)]\tTotal Loss: 228.0326\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[94000/117711 (80%)]\tTotal Loss: 232.8048\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[96000/117711 (81%)]\tTotal Loss: 237.1445\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[98000/117711 (83%)]\tTotal Loss: 241.6117\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[100000/117711 (85%)]\tTotal Loss: 246.1493\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[102000/117711 (87%)]\tTotal Loss: 250.9754\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[104000/117711 (88%)]\tTotal Loss: 255.7217\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[106000/117711 (90%)]\tTotal Loss: 260.9231\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[108000/117711 (92%)]\tTotal Loss: 265.7454\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[110000/117711 (93%)]\tTotal Loss: 270.5021\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[112000/117711 (95%)]\tTotal Loss: 275.2355\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[114000/117711 (97%)]\tTotal Loss: 280.3436\tAvg Loss: 0.0025\n",
      "Train Epoch: 2\t[116000/117711 (98%)]\tTotal Loss: 285.1312\tAvg Loss: 0.0025\n",
      "====> Epoch: 2\tTotal Loss: 289.4143\t Avg Loss: 0.0025\tCorrect: 102911/117711\tPercentage Correct: 87.43\n",
      "====> Val Loss: 158.7512\t Avg Loss: 0.0121\tCorrect: 8473/13079\tPercentage Correct: 64.78\n",
      "====> Test Loss: 406.5467\t Avg Loss: 0.0124\tCorrect: 21011/32698\tPercentage Correct: 64.26\n",
      "Train Epoch: 3\t[2000/117711 (2%)]\tTotal Loss: 6.0203\tAvg Loss: 0.0030\n",
      "Train Epoch: 3\t[4000/117711 (3%)]\tTotal Loss: 11.1233\tAvg Loss: 0.0028\n",
      "Train Epoch: 3\t[6000/117711 (5%)]\tTotal Loss: 15.7403\tAvg Loss: 0.0026\n",
      "Train Epoch: 3\t[8000/117711 (7%)]\tTotal Loss: 20.2016\tAvg Loss: 0.0025\n",
      "Train Epoch: 3\t[10000/117711 (8%)]\tTotal Loss: 24.6509\tAvg Loss: 0.0025\n",
      "Train Epoch: 3\t[12000/117711 (10%)]\tTotal Loss: 28.9821\tAvg Loss: 0.0024\n",
      "Train Epoch: 3\t[14000/117711 (12%)]\tTotal Loss: 33.4275\tAvg Loss: 0.0024\n",
      "Train Epoch: 3\t[16000/117711 (14%)]\tTotal Loss: 37.5260\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[18000/117711 (15%)]\tTotal Loss: 41.8441\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[20000/117711 (17%)]\tTotal Loss: 46.5401\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[22000/117711 (19%)]\tTotal Loss: 51.3977\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[24000/117711 (20%)]\tTotal Loss: 55.9619\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[26000/117711 (22%)]\tTotal Loss: 60.5192\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[28000/117711 (24%)]\tTotal Loss: 65.2033\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[30000/117711 (25%)]\tTotal Loss: 69.6753\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[32000/117711 (27%)]\tTotal Loss: 73.6309\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[34000/117711 (29%)]\tTotal Loss: 78.0643\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[36000/117711 (31%)]\tTotal Loss: 82.5902\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[38000/117711 (32%)]\tTotal Loss: 86.7000\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[40000/117711 (34%)]\tTotal Loss: 91.1924\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[42000/117711 (36%)]\tTotal Loss: 95.1130\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[44000/117711 (37%)]\tTotal Loss: 99.6155\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[46000/117711 (39%)]\tTotal Loss: 103.9784\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[48000/117711 (41%)]\tTotal Loss: 108.1561\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[50000/117711 (42%)]\tTotal Loss: 112.6976\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[52000/117711 (44%)]\tTotal Loss: 117.3611\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[54000/117711 (46%)]\tTotal Loss: 121.7398\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[56000/117711 (48%)]\tTotal Loss: 126.1525\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[58000/117711 (49%)]\tTotal Loss: 130.5007\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[60000/117711 (51%)]\tTotal Loss: 135.1598\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[62000/117711 (53%)]\tTotal Loss: 139.5732\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[64000/117711 (54%)]\tTotal Loss: 144.1532\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[66000/117711 (56%)]\tTotal Loss: 148.5365\tAvg Loss: 0.0023\n",
      "Train Epoch: 3\t[68000/117711 (58%)]\tTotal Loss: 152.8160\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[70000/117711 (59%)]\tTotal Loss: 157.4668\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[72000/117711 (61%)]\tTotal Loss: 161.6293\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[74000/117711 (63%)]\tTotal Loss: 165.9071\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[76000/117711 (65%)]\tTotal Loss: 169.8081\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[78000/117711 (66%)]\tTotal Loss: 174.1760\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[80000/117711 (68%)]\tTotal Loss: 178.3115\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[82000/117711 (70%)]\tTotal Loss: 182.4307\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[84000/117711 (71%)]\tTotal Loss: 186.4098\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[86000/117711 (73%)]\tTotal Loss: 190.8202\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[88000/117711 (75%)]\tTotal Loss: 194.9031\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[90000/117711 (76%)]\tTotal Loss: 199.3012\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[92000/117711 (78%)]\tTotal Loss: 203.2882\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[94000/117711 (80%)]\tTotal Loss: 207.5358\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[96000/117711 (81%)]\tTotal Loss: 211.7857\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[98000/117711 (83%)]\tTotal Loss: 216.1725\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[100000/117711 (85%)]\tTotal Loss: 220.9254\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[102000/117711 (87%)]\tTotal Loss: 225.3392\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[104000/117711 (88%)]\tTotal Loss: 229.6515\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[106000/117711 (90%)]\tTotal Loss: 233.6463\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[108000/117711 (92%)]\tTotal Loss: 237.9594\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[110000/117711 (93%)]\tTotal Loss: 241.9782\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[112000/117711 (95%)]\tTotal Loss: 246.0404\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[114000/117711 (97%)]\tTotal Loss: 250.2771\tAvg Loss: 0.0022\n",
      "Train Epoch: 3\t[116000/117711 (98%)]\tTotal Loss: 254.4934\tAvg Loss: 0.0022\n",
      "====> Epoch: 3\tTotal Loss: 258.0700\t Avg Loss: 0.0022\tCorrect: 103959/117711\tPercentage Correct: 88.32\n",
      "====> Val Loss: 31.4014\t Avg Loss: 0.0024\tCorrect: 11382/13079\tPercentage Correct: 87.03\n",
      "====> Test Loss: 75.8926\t Avg Loss: 0.0023\tCorrect: 28709/32698\tPercentage Correct: 87.80\n",
      "--- saved best model ---\n",
      "Train Epoch: 4\t[2000/117711 (2%)]\tTotal Loss: 4.3441\tAvg Loss: 0.0022\n",
      "Train Epoch: 4\t[4000/117711 (3%)]\tTotal Loss: 8.5293\tAvg Loss: 0.0021\n",
      "Train Epoch: 4\t[6000/117711 (5%)]\tTotal Loss: 12.5580\tAvg Loss: 0.0021\n",
      "Train Epoch: 4\t[8000/117711 (7%)]\tTotal Loss: 16.7093\tAvg Loss: 0.0021\n",
      "Train Epoch: 4\t[10000/117711 (8%)]\tTotal Loss: 20.7681\tAvg Loss: 0.0021\n",
      "Train Epoch: 4\t[12000/117711 (10%)]\tTotal Loss: 24.9288\tAvg Loss: 0.0021\n",
      "Train Epoch: 4\t[14000/117711 (12%)]\tTotal Loss: 29.2736\tAvg Loss: 0.0021\n",
      "Train Epoch: 4\t[16000/117711 (14%)]\tTotal Loss: 33.1684\tAvg Loss: 0.0021\n",
      "Train Epoch: 4\t[18000/117711 (15%)]\tTotal Loss: 37.3497\tAvg Loss: 0.0021\n",
      "Train Epoch: 4\t[20000/117711 (17%)]\tTotal Loss: 41.2933\tAvg Loss: 0.0021\n",
      "Train Epoch: 4\t[22000/117711 (19%)]\tTotal Loss: 45.1369\tAvg Loss: 0.0021\n",
      "Train Epoch: 4\t[24000/117711 (20%)]\tTotal Loss: 48.8809\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[26000/117711 (22%)]\tTotal Loss: 52.9012\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[28000/117711 (24%)]\tTotal Loss: 56.7288\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[30000/117711 (25%)]\tTotal Loss: 60.6567\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[32000/117711 (27%)]\tTotal Loss: 64.8375\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[34000/117711 (29%)]\tTotal Loss: 68.8184\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[36000/117711 (31%)]\tTotal Loss: 72.5636\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[38000/117711 (32%)]\tTotal Loss: 76.6630\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[40000/117711 (34%)]\tTotal Loss: 81.0831\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[42000/117711 (36%)]\tTotal Loss: 85.1049\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[44000/117711 (37%)]\tTotal Loss: 89.8269\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[46000/117711 (39%)]\tTotal Loss: 94.0417\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[48000/117711 (41%)]\tTotal Loss: 98.2431\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[50000/117711 (42%)]\tTotal Loss: 102.0299\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[52000/117711 (44%)]\tTotal Loss: 106.2949\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[54000/117711 (46%)]\tTotal Loss: 110.5757\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[56000/117711 (48%)]\tTotal Loss: 114.1143\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[58000/117711 (49%)]\tTotal Loss: 118.2545\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[60000/117711 (51%)]\tTotal Loss: 122.0364\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[62000/117711 (53%)]\tTotal Loss: 125.9117\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[64000/117711 (54%)]\tTotal Loss: 129.7568\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[66000/117711 (56%)]\tTotal Loss: 134.0313\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[68000/117711 (58%)]\tTotal Loss: 137.9792\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[70000/117711 (59%)]\tTotal Loss: 142.3207\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[72000/117711 (61%)]\tTotal Loss: 146.3448\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[74000/117711 (63%)]\tTotal Loss: 150.5875\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[76000/117711 (65%)]\tTotal Loss: 154.9264\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[78000/117711 (66%)]\tTotal Loss: 158.6282\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[80000/117711 (68%)]\tTotal Loss: 162.4120\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[82000/117711 (70%)]\tTotal Loss: 166.5541\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[84000/117711 (71%)]\tTotal Loss: 170.6253\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[86000/117711 (73%)]\tTotal Loss: 174.4727\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[88000/117711 (75%)]\tTotal Loss: 178.2258\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[90000/117711 (76%)]\tTotal Loss: 181.9913\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[92000/117711 (78%)]\tTotal Loss: 185.9623\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[94000/117711 (80%)]\tTotal Loss: 190.0685\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[96000/117711 (81%)]\tTotal Loss: 194.1273\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[98000/117711 (83%)]\tTotal Loss: 198.0767\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[100000/117711 (85%)]\tTotal Loss: 202.1440\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[102000/117711 (87%)]\tTotal Loss: 206.0892\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[104000/117711 (88%)]\tTotal Loss: 210.0766\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[106000/117711 (90%)]\tTotal Loss: 213.9064\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[108000/117711 (92%)]\tTotal Loss: 217.7971\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[110000/117711 (93%)]\tTotal Loss: 221.6502\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[112000/117711 (95%)]\tTotal Loss: 225.9319\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[114000/117711 (97%)]\tTotal Loss: 230.0989\tAvg Loss: 0.0020\n",
      "Train Epoch: 4\t[116000/117711 (98%)]\tTotal Loss: 234.5171\tAvg Loss: 0.0020\n",
      "====> Epoch: 4\tTotal Loss: 238.6707\t Avg Loss: 0.0020\tCorrect: 104495/117711\tPercentage Correct: 88.77\n",
      "====> Val Loss: 199.6944\t Avg Loss: 0.0153\tCorrect: 8270/13079\tPercentage Correct: 63.23\n",
      "====> Test Loss: 501.6356\t Avg Loss: 0.0153\tCorrect: 20688/32698\tPercentage Correct: 63.27\n",
      "Train Epoch: 5\t[2000/117711 (2%)]\tTotal Loss: 5.2139\tAvg Loss: 0.0026\n",
      "Train Epoch: 5\t[4000/117711 (3%)]\tTotal Loss: 9.8754\tAvg Loss: 0.0025\n",
      "Train Epoch: 5\t[6000/117711 (5%)]\tTotal Loss: 14.2252\tAvg Loss: 0.0024\n",
      "Train Epoch: 5\t[8000/117711 (7%)]\tTotal Loss: 18.4217\tAvg Loss: 0.0023\n",
      "Train Epoch: 5\t[10000/117711 (8%)]\tTotal Loss: 22.4237\tAvg Loss: 0.0022\n",
      "Train Epoch: 5\t[12000/117711 (10%)]\tTotal Loss: 26.2736\tAvg Loss: 0.0022\n",
      "Train Epoch: 5\t[14000/117711 (12%)]\tTotal Loss: 30.1854\tAvg Loss: 0.0022\n",
      "Train Epoch: 5\t[16000/117711 (14%)]\tTotal Loss: 34.1393\tAvg Loss: 0.0021\n",
      "Train Epoch: 5\t[18000/117711 (15%)]\tTotal Loss: 38.1132\tAvg Loss: 0.0021\n",
      "Train Epoch: 5\t[20000/117711 (17%)]\tTotal Loss: 41.7151\tAvg Loss: 0.0021\n",
      "Train Epoch: 5\t[22000/117711 (19%)]\tTotal Loss: 45.4172\tAvg Loss: 0.0021\n",
      "Train Epoch: 5\t[24000/117711 (20%)]\tTotal Loss: 49.0589\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[26000/117711 (22%)]\tTotal Loss: 52.7390\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[28000/117711 (24%)]\tTotal Loss: 56.9017\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[30000/117711 (25%)]\tTotal Loss: 61.0578\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[32000/117711 (27%)]\tTotal Loss: 64.7142\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[34000/117711 (29%)]\tTotal Loss: 68.4622\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[36000/117711 (31%)]\tTotal Loss: 72.4977\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[38000/117711 (32%)]\tTotal Loss: 76.1459\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[40000/117711 (34%)]\tTotal Loss: 80.0900\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[42000/117711 (36%)]\tTotal Loss: 83.8890\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[44000/117711 (37%)]\tTotal Loss: 87.9118\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[46000/117711 (39%)]\tTotal Loss: 91.7096\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[48000/117711 (41%)]\tTotal Loss: 95.5968\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[50000/117711 (42%)]\tTotal Loss: 99.6844\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[52000/117711 (44%)]\tTotal Loss: 103.3071\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[54000/117711 (46%)]\tTotal Loss: 107.0618\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[56000/117711 (48%)]\tTotal Loss: 110.7670\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[58000/117711 (49%)]\tTotal Loss: 114.8179\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[60000/117711 (51%)]\tTotal Loss: 118.6544\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[62000/117711 (53%)]\tTotal Loss: 122.5809\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[64000/117711 (54%)]\tTotal Loss: 126.5610\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[66000/117711 (56%)]\tTotal Loss: 130.2324\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[68000/117711 (58%)]\tTotal Loss: 134.2941\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[70000/117711 (59%)]\tTotal Loss: 137.8492\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[72000/117711 (61%)]\tTotal Loss: 141.8999\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[74000/117711 (63%)]\tTotal Loss: 145.7066\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[76000/117711 (65%)]\tTotal Loss: 149.5801\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[78000/117711 (66%)]\tTotal Loss: 153.2865\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[80000/117711 (68%)]\tTotal Loss: 156.8395\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[82000/117711 (70%)]\tTotal Loss: 160.5424\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[84000/117711 (71%)]\tTotal Loss: 164.2193\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[86000/117711 (73%)]\tTotal Loss: 168.0997\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[88000/117711 (75%)]\tTotal Loss: 171.5069\tAvg Loss: 0.0019\n",
      "Train Epoch: 5\t[90000/117711 (76%)]\tTotal Loss: 175.2981\tAvg Loss: 0.0019\n",
      "Train Epoch: 5\t[92000/117711 (78%)]\tTotal Loss: 178.6545\tAvg Loss: 0.0019\n",
      "Train Epoch: 5\t[94000/117711 (80%)]\tTotal Loss: 182.8166\tAvg Loss: 0.0019\n",
      "Train Epoch: 5\t[96000/117711 (81%)]\tTotal Loss: 186.7171\tAvg Loss: 0.0019\n",
      "Train Epoch: 5\t[98000/117711 (83%)]\tTotal Loss: 190.6278\tAvg Loss: 0.0019\n",
      "Train Epoch: 5\t[100000/117711 (85%)]\tTotal Loss: 195.0800\tAvg Loss: 0.0020\n",
      "Train Epoch: 5\t[102000/117711 (87%)]\tTotal Loss: 198.8254\tAvg Loss: 0.0019\n",
      "Train Epoch: 5\t[104000/117711 (88%)]\tTotal Loss: 202.6948\tAvg Loss: 0.0019\n",
      "Train Epoch: 5\t[106000/117711 (90%)]\tTotal Loss: 206.4795\tAvg Loss: 0.0019\n",
      "Train Epoch: 5\t[108000/117711 (92%)]\tTotal Loss: 210.2544\tAvg Loss: 0.0019\n",
      "Train Epoch: 5\t[110000/117711 (93%)]\tTotal Loss: 214.2576\tAvg Loss: 0.0019\n",
      "Train Epoch: 5\t[112000/117711 (95%)]\tTotal Loss: 217.9841\tAvg Loss: 0.0019\n",
      "Train Epoch: 5\t[114000/117711 (97%)]\tTotal Loss: 221.8992\tAvg Loss: 0.0019\n",
      "Train Epoch: 5\t[116000/117711 (98%)]\tTotal Loss: 225.9573\tAvg Loss: 0.0019\n",
      "====> Epoch: 5\tTotal Loss: 230.2502\t Avg Loss: 0.0020\tCorrect: 104719/117711\tPercentage Correct: 88.96\n",
      "====> Val Loss: 213.8388\t Avg Loss: 0.0163\tCorrect: 7969/13079\tPercentage Correct: 60.93\n",
      "====> Test Loss: 545.6035\t Avg Loss: 0.0167\tCorrect: 19493/32698\tPercentage Correct: 59.62\n",
      "Train Epoch: 6\t[2000/117711 (2%)]\tTotal Loss: 5.4324\tAvg Loss: 0.0027\n",
      "Train Epoch: 6\t[4000/117711 (3%)]\tTotal Loss: 9.4873\tAvg Loss: 0.0024\n",
      "Train Epoch: 6\t[6000/117711 (5%)]\tTotal Loss: 13.3910\tAvg Loss: 0.0022\n",
      "Train Epoch: 6\t[8000/117711 (7%)]\tTotal Loss: 17.5764\tAvg Loss: 0.0022\n",
      "Train Epoch: 6\t[10000/117711 (8%)]\tTotal Loss: 21.6213\tAvg Loss: 0.0022\n",
      "Train Epoch: 6\t[12000/117711 (10%)]\tTotal Loss: 25.3090\tAvg Loss: 0.0021\n",
      "Train Epoch: 6\t[14000/117711 (12%)]\tTotal Loss: 28.9916\tAvg Loss: 0.0021\n",
      "Train Epoch: 6\t[16000/117711 (14%)]\tTotal Loss: 32.5124\tAvg Loss: 0.0020\n",
      "Train Epoch: 6\t[18000/117711 (15%)]\tTotal Loss: 36.0980\tAvg Loss: 0.0020\n",
      "Train Epoch: 6\t[20000/117711 (17%)]\tTotal Loss: 39.9455\tAvg Loss: 0.0020\n",
      "Train Epoch: 6\t[22000/117711 (19%)]\tTotal Loss: 43.3729\tAvg Loss: 0.0020\n",
      "Train Epoch: 6\t[24000/117711 (20%)]\tTotal Loss: 46.9441\tAvg Loss: 0.0020\n",
      "Train Epoch: 6\t[26000/117711 (22%)]\tTotal Loss: 50.3824\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[28000/117711 (24%)]\tTotal Loss: 53.9502\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[30000/117711 (25%)]\tTotal Loss: 57.4976\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[32000/117711 (27%)]\tTotal Loss: 60.9364\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[34000/117711 (29%)]\tTotal Loss: 64.6798\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[36000/117711 (31%)]\tTotal Loss: 68.0758\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[38000/117711 (32%)]\tTotal Loss: 71.5550\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[40000/117711 (34%)]\tTotal Loss: 75.1942\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[42000/117711 (36%)]\tTotal Loss: 78.8243\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[44000/117711 (37%)]\tTotal Loss: 82.4691\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[46000/117711 (39%)]\tTotal Loss: 86.2321\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[48000/117711 (41%)]\tTotal Loss: 89.8188\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[50000/117711 (42%)]\tTotal Loss: 93.6936\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[52000/117711 (44%)]\tTotal Loss: 97.4499\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[54000/117711 (46%)]\tTotal Loss: 101.0588\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[56000/117711 (48%)]\tTotal Loss: 104.9091\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[58000/117711 (49%)]\tTotal Loss: 108.7297\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[60000/117711 (51%)]\tTotal Loss: 112.1774\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[62000/117711 (53%)]\tTotal Loss: 115.8150\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[64000/117711 (54%)]\tTotal Loss: 119.5736\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[66000/117711 (56%)]\tTotal Loss: 123.3864\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[68000/117711 (58%)]\tTotal Loss: 127.0526\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[70000/117711 (59%)]\tTotal Loss: 130.5665\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[72000/117711 (61%)]\tTotal Loss: 134.3260\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[74000/117711 (63%)]\tTotal Loss: 138.1937\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[76000/117711 (65%)]\tTotal Loss: 141.6909\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[78000/117711 (66%)]\tTotal Loss: 145.1853\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[80000/117711 (68%)]\tTotal Loss: 148.8914\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[82000/117711 (70%)]\tTotal Loss: 152.5049\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[84000/117711 (71%)]\tTotal Loss: 156.1746\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[86000/117711 (73%)]\tTotal Loss: 159.5309\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[88000/117711 (75%)]\tTotal Loss: 163.4254\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[90000/117711 (76%)]\tTotal Loss: 166.9756\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[92000/117711 (78%)]\tTotal Loss: 170.6970\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[94000/117711 (80%)]\tTotal Loss: 175.0283\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[96000/117711 (81%)]\tTotal Loss: 178.7748\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[98000/117711 (83%)]\tTotal Loss: 182.3595\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[100000/117711 (85%)]\tTotal Loss: 185.9002\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[102000/117711 (87%)]\tTotal Loss: 189.6389\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[104000/117711 (88%)]\tTotal Loss: 193.5702\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[106000/117711 (90%)]\tTotal Loss: 197.4492\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[108000/117711 (92%)]\tTotal Loss: 201.0969\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[110000/117711 (93%)]\tTotal Loss: 204.6187\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[112000/117711 (95%)]\tTotal Loss: 208.3314\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[114000/117711 (97%)]\tTotal Loss: 212.0844\tAvg Loss: 0.0019\n",
      "Train Epoch: 6\t[116000/117711 (98%)]\tTotal Loss: 215.3517\tAvg Loss: 0.0019\n",
      "====> Epoch: 6\tTotal Loss: 218.2493\t Avg Loss: 0.0019\tCorrect: 105180/117711\tPercentage Correct: 89.35\n",
      "====> Val Loss: 38.9763\t Avg Loss: 0.0030\tCorrect: 11228/13079\tPercentage Correct: 85.85\n",
      "====> Test Loss: 99.0379\t Avg Loss: 0.0030\tCorrect: 27868/32698\tPercentage Correct: 85.23\n",
      "Train Epoch: 7\t[2000/117711 (2%)]\tTotal Loss: 3.6759\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[4000/117711 (3%)]\tTotal Loss: 7.4439\tAvg Loss: 0.0019\n",
      "Train Epoch: 7\t[6000/117711 (5%)]\tTotal Loss: 11.0903\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[8000/117711 (7%)]\tTotal Loss: 14.2079\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[10000/117711 (8%)]\tTotal Loss: 17.6208\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[12000/117711 (10%)]\tTotal Loss: 20.8815\tAvg Loss: 0.0017\n",
      "Train Epoch: 7\t[14000/117711 (12%)]\tTotal Loss: 24.4673\tAvg Loss: 0.0017\n",
      "Train Epoch: 7\t[16000/117711 (14%)]\tTotal Loss: 28.1360\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[18000/117711 (15%)]\tTotal Loss: 31.8315\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[20000/117711 (17%)]\tTotal Loss: 35.2465\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[22000/117711 (19%)]\tTotal Loss: 38.7728\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[24000/117711 (20%)]\tTotal Loss: 42.3874\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[26000/117711 (22%)]\tTotal Loss: 45.8956\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[28000/117711 (24%)]\tTotal Loss: 49.2912\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[30000/117711 (25%)]\tTotal Loss: 52.6923\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[32000/117711 (27%)]\tTotal Loss: 56.2163\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[34000/117711 (29%)]\tTotal Loss: 59.5481\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[36000/117711 (31%)]\tTotal Loss: 62.7619\tAvg Loss: 0.0017\n",
      "Train Epoch: 7\t[38000/117711 (32%)]\tTotal Loss: 65.9273\tAvg Loss: 0.0017\n",
      "Train Epoch: 7\t[40000/117711 (34%)]\tTotal Loss: 69.6902\tAvg Loss: 0.0017\n",
      "Train Epoch: 7\t[42000/117711 (36%)]\tTotal Loss: 73.4550\tAvg Loss: 0.0017\n",
      "Train Epoch: 7\t[44000/117711 (37%)]\tTotal Loss: 77.2305\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[46000/117711 (39%)]\tTotal Loss: 80.6034\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[48000/117711 (41%)]\tTotal Loss: 84.2861\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[50000/117711 (42%)]\tTotal Loss: 87.7859\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[52000/117711 (44%)]\tTotal Loss: 91.5000\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[54000/117711 (46%)]\tTotal Loss: 95.1763\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[56000/117711 (48%)]\tTotal Loss: 99.0871\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[58000/117711 (49%)]\tTotal Loss: 102.8672\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[60000/117711 (51%)]\tTotal Loss: 106.4206\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[62000/117711 (53%)]\tTotal Loss: 109.9402\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[64000/117711 (54%)]\tTotal Loss: 113.4177\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[66000/117711 (56%)]\tTotal Loss: 117.1929\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[68000/117711 (58%)]\tTotal Loss: 120.7244\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[70000/117711 (59%)]\tTotal Loss: 124.0328\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[72000/117711 (61%)]\tTotal Loss: 127.6482\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[74000/117711 (63%)]\tTotal Loss: 131.1302\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[76000/117711 (65%)]\tTotal Loss: 134.8401\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[78000/117711 (66%)]\tTotal Loss: 138.7759\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[80000/117711 (68%)]\tTotal Loss: 142.2606\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[82000/117711 (70%)]\tTotal Loss: 145.7594\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[84000/117711 (71%)]\tTotal Loss: 149.0370\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[86000/117711 (73%)]\tTotal Loss: 152.8136\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[88000/117711 (75%)]\tTotal Loss: 156.7654\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[90000/117711 (76%)]\tTotal Loss: 160.2501\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[92000/117711 (78%)]\tTotal Loss: 163.6447\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[94000/117711 (80%)]\tTotal Loss: 167.2535\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[96000/117711 (81%)]\tTotal Loss: 170.6156\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[98000/117711 (83%)]\tTotal Loss: 174.3225\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[100000/117711 (85%)]\tTotal Loss: 177.8046\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[102000/117711 (87%)]\tTotal Loss: 181.8272\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[104000/117711 (88%)]\tTotal Loss: 185.4420\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[106000/117711 (90%)]\tTotal Loss: 188.9192\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[108000/117711 (92%)]\tTotal Loss: 192.6019\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[110000/117711 (93%)]\tTotal Loss: 196.3843\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[112000/117711 (95%)]\tTotal Loss: 199.9561\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[114000/117711 (97%)]\tTotal Loss: 203.4765\tAvg Loss: 0.0018\n",
      "Train Epoch: 7\t[116000/117711 (98%)]\tTotal Loss: 206.9915\tAvg Loss: 0.0018\n",
      "====> Epoch: 7\tTotal Loss: 210.0359\t Avg Loss: 0.0018\tCorrect: 105435/117711\tPercentage Correct: 89.57\n",
      "====> Val Loss: 60.1678\t Avg Loss: 0.0046\tCorrect: 10554/13079\tPercentage Correct: 80.69\n",
      "====> Test Loss: 147.7348\t Avg Loss: 0.0045\tCorrect: 26266/32698\tPercentage Correct: 80.33\n",
      "Train Epoch: 8\t[2000/117711 (2%)]\tTotal Loss: 4.0966\tAvg Loss: 0.0020\n",
      "Train Epoch: 8\t[4000/117711 (3%)]\tTotal Loss: 7.4882\tAvg Loss: 0.0019\n",
      "Train Epoch: 8\t[6000/117711 (5%)]\tTotal Loss: 11.0448\tAvg Loss: 0.0018\n",
      "Train Epoch: 8\t[8000/117711 (7%)]\tTotal Loss: 14.5775\tAvg Loss: 0.0018\n",
      "Train Epoch: 8\t[10000/117711 (8%)]\tTotal Loss: 18.1808\tAvg Loss: 0.0018\n",
      "Train Epoch: 8\t[12000/117711 (10%)]\tTotal Loss: 21.7281\tAvg Loss: 0.0018\n",
      "Train Epoch: 8\t[14000/117711 (12%)]\tTotal Loss: 25.3328\tAvg Loss: 0.0018\n",
      "Train Epoch: 8\t[16000/117711 (14%)]\tTotal Loss: 28.8003\tAvg Loss: 0.0018\n",
      "Train Epoch: 8\t[18000/117711 (15%)]\tTotal Loss: 32.6203\tAvg Loss: 0.0018\n",
      "Train Epoch: 8\t[20000/117711 (17%)]\tTotal Loss: 35.9300\tAvg Loss: 0.0018\n",
      "Train Epoch: 8\t[22000/117711 (19%)]\tTotal Loss: 39.2547\tAvg Loss: 0.0018\n",
      "Train Epoch: 8\t[24000/117711 (20%)]\tTotal Loss: 42.4575\tAvg Loss: 0.0018\n",
      "Train Epoch: 8\t[26000/117711 (22%)]\tTotal Loss: 45.9017\tAvg Loss: 0.0018\n",
      "Train Epoch: 8\t[28000/117711 (24%)]\tTotal Loss: 49.3376\tAvg Loss: 0.0018\n",
      "Train Epoch: 8\t[30000/117711 (25%)]\tTotal Loss: 52.3668\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[32000/117711 (27%)]\tTotal Loss: 55.8815\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[34000/117711 (29%)]\tTotal Loss: 58.6448\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[36000/117711 (31%)]\tTotal Loss: 62.0493\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[38000/117711 (32%)]\tTotal Loss: 65.4073\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[40000/117711 (34%)]\tTotal Loss: 68.8384\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[42000/117711 (36%)]\tTotal Loss: 72.2665\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[44000/117711 (37%)]\tTotal Loss: 75.6149\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[46000/117711 (39%)]\tTotal Loss: 79.1290\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[48000/117711 (41%)]\tTotal Loss: 82.6012\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[50000/117711 (42%)]\tTotal Loss: 86.1230\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[52000/117711 (44%)]\tTotal Loss: 89.7851\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[54000/117711 (46%)]\tTotal Loss: 93.7008\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[56000/117711 (48%)]\tTotal Loss: 97.3890\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[58000/117711 (49%)]\tTotal Loss: 100.8068\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[60000/117711 (51%)]\tTotal Loss: 104.4616\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[62000/117711 (53%)]\tTotal Loss: 108.0068\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[64000/117711 (54%)]\tTotal Loss: 111.5368\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[66000/117711 (56%)]\tTotal Loss: 115.0780\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[68000/117711 (58%)]\tTotal Loss: 118.5493\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[70000/117711 (59%)]\tTotal Loss: 122.0584\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[72000/117711 (61%)]\tTotal Loss: 125.2655\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[74000/117711 (63%)]\tTotal Loss: 128.6468\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[76000/117711 (65%)]\tTotal Loss: 131.9266\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[78000/117711 (66%)]\tTotal Loss: 135.2745\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[80000/117711 (68%)]\tTotal Loss: 138.9678\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[82000/117711 (70%)]\tTotal Loss: 142.3486\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[84000/117711 (71%)]\tTotal Loss: 145.4704\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[86000/117711 (73%)]\tTotal Loss: 149.0940\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[88000/117711 (75%)]\tTotal Loss: 152.5295\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[90000/117711 (76%)]\tTotal Loss: 155.8101\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[92000/117711 (78%)]\tTotal Loss: 159.2599\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[94000/117711 (80%)]\tTotal Loss: 162.6297\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[96000/117711 (81%)]\tTotal Loss: 166.2327\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[98000/117711 (83%)]\tTotal Loss: 169.3427\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[100000/117711 (85%)]\tTotal Loss: 172.9531\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[102000/117711 (87%)]\tTotal Loss: 176.4923\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[104000/117711 (88%)]\tTotal Loss: 179.9538\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[106000/117711 (90%)]\tTotal Loss: 183.3689\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[108000/117711 (92%)]\tTotal Loss: 186.8680\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[110000/117711 (93%)]\tTotal Loss: 190.2015\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[112000/117711 (95%)]\tTotal Loss: 193.7238\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[114000/117711 (97%)]\tTotal Loss: 197.0657\tAvg Loss: 0.0017\n",
      "Train Epoch: 8\t[116000/117711 (98%)]\tTotal Loss: 200.5911\tAvg Loss: 0.0017\n",
      "====> Epoch: 8\tTotal Loss: 203.9255\t Avg Loss: 0.0017\tCorrect: 105624/117711\tPercentage Correct: 89.73\n",
      "====> Val Loss: 54.3128\t Avg Loss: 0.0042\tCorrect: 10781/13079\tPercentage Correct: 82.43\n",
      "====> Test Loss: 138.7470\t Avg Loss: 0.0042\tCorrect: 26948/32698\tPercentage Correct: 82.41\n",
      "Train Epoch: 9\t[2000/117711 (2%)]\tTotal Loss: 5.4708\tAvg Loss: 0.0027\n",
      "Train Epoch: 9\t[4000/117711 (3%)]\tTotal Loss: 9.7651\tAvg Loss: 0.0024\n",
      "Train Epoch: 9\t[6000/117711 (5%)]\tTotal Loss: 13.8875\tAvg Loss: 0.0023\n",
      "Train Epoch: 9\t[8000/117711 (7%)]\tTotal Loss: 17.5869\tAvg Loss: 0.0022\n",
      "Train Epoch: 9\t[10000/117711 (8%)]\tTotal Loss: 20.7966\tAvg Loss: 0.0021\n",
      "Train Epoch: 9\t[12000/117711 (10%)]\tTotal Loss: 24.2379\tAvg Loss: 0.0020\n",
      "Train Epoch: 9\t[14000/117711 (12%)]\tTotal Loss: 28.0617\tAvg Loss: 0.0020\n",
      "Train Epoch: 9\t[16000/117711 (14%)]\tTotal Loss: 31.4241\tAvg Loss: 0.0020\n",
      "Train Epoch: 9\t[18000/117711 (15%)]\tTotal Loss: 34.7407\tAvg Loss: 0.0019\n",
      "Train Epoch: 9\t[20000/117711 (17%)]\tTotal Loss: 38.1809\tAvg Loss: 0.0019\n",
      "Train Epoch: 9\t[22000/117711 (19%)]\tTotal Loss: 41.7844\tAvg Loss: 0.0019\n",
      "Train Epoch: 9\t[24000/117711 (20%)]\tTotal Loss: 45.2929\tAvg Loss: 0.0019\n",
      "Train Epoch: 9\t[26000/117711 (22%)]\tTotal Loss: 48.3666\tAvg Loss: 0.0019\n",
      "Train Epoch: 9\t[28000/117711 (24%)]\tTotal Loss: 51.7689\tAvg Loss: 0.0018\n",
      "Train Epoch: 9\t[30000/117711 (25%)]\tTotal Loss: 54.9957\tAvg Loss: 0.0018\n",
      "Train Epoch: 9\t[32000/117711 (27%)]\tTotal Loss: 58.5594\tAvg Loss: 0.0018\n",
      "Train Epoch: 9\t[34000/117711 (29%)]\tTotal Loss: 62.2001\tAvg Loss: 0.0018\n",
      "Train Epoch: 9\t[36000/117711 (31%)]\tTotal Loss: 65.5281\tAvg Loss: 0.0018\n",
      "Train Epoch: 9\t[38000/117711 (32%)]\tTotal Loss: 68.6140\tAvg Loss: 0.0018\n",
      "Train Epoch: 9\t[40000/117711 (34%)]\tTotal Loss: 72.0260\tAvg Loss: 0.0018\n",
      "Train Epoch: 9\t[42000/117711 (36%)]\tTotal Loss: 75.2799\tAvg Loss: 0.0018\n",
      "Train Epoch: 9\t[44000/117711 (37%)]\tTotal Loss: 78.6729\tAvg Loss: 0.0018\n",
      "Train Epoch: 9\t[46000/117711 (39%)]\tTotal Loss: 82.0399\tAvg Loss: 0.0018\n",
      "Train Epoch: 9\t[48000/117711 (41%)]\tTotal Loss: 85.3537\tAvg Loss: 0.0018\n",
      "Train Epoch: 9\t[50000/117711 (42%)]\tTotal Loss: 88.6379\tAvg Loss: 0.0018\n",
      "Train Epoch: 9\t[52000/117711 (44%)]\tTotal Loss: 91.7274\tAvg Loss: 0.0018\n",
      "Train Epoch: 9\t[54000/117711 (46%)]\tTotal Loss: 94.9832\tAvg Loss: 0.0018\n",
      "Train Epoch: 9\t[56000/117711 (48%)]\tTotal Loss: 98.0401\tAvg Loss: 0.0018\n",
      "Train Epoch: 9\t[58000/117711 (49%)]\tTotal Loss: 101.3817\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[60000/117711 (51%)]\tTotal Loss: 104.7228\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[62000/117711 (53%)]\tTotal Loss: 108.2551\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[64000/117711 (54%)]\tTotal Loss: 111.8543\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[66000/117711 (56%)]\tTotal Loss: 115.1347\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[68000/117711 (58%)]\tTotal Loss: 118.3018\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[70000/117711 (59%)]\tTotal Loss: 121.5510\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[72000/117711 (61%)]\tTotal Loss: 124.8855\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[74000/117711 (63%)]\tTotal Loss: 128.1612\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[76000/117711 (65%)]\tTotal Loss: 131.5712\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[78000/117711 (66%)]\tTotal Loss: 134.6349\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[80000/117711 (68%)]\tTotal Loss: 137.8897\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[82000/117711 (70%)]\tTotal Loss: 141.0611\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[84000/117711 (71%)]\tTotal Loss: 144.0745\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[86000/117711 (73%)]\tTotal Loss: 147.2633\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[88000/117711 (75%)]\tTotal Loss: 150.8278\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[90000/117711 (76%)]\tTotal Loss: 154.2976\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[92000/117711 (78%)]\tTotal Loss: 157.6313\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[94000/117711 (80%)]\tTotal Loss: 160.9742\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[96000/117711 (81%)]\tTotal Loss: 164.3250\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[98000/117711 (83%)]\tTotal Loss: 167.8011\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[100000/117711 (85%)]\tTotal Loss: 170.8691\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[102000/117711 (87%)]\tTotal Loss: 174.0189\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[104000/117711 (88%)]\tTotal Loss: 177.3345\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[106000/117711 (90%)]\tTotal Loss: 180.6298\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[108000/117711 (92%)]\tTotal Loss: 183.6784\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[110000/117711 (93%)]\tTotal Loss: 187.3081\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[112000/117711 (95%)]\tTotal Loss: 190.4552\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[114000/117711 (97%)]\tTotal Loss: 193.5865\tAvg Loss: 0.0017\n",
      "Train Epoch: 9\t[116000/117711 (98%)]\tTotal Loss: 196.7134\tAvg Loss: 0.0017\n",
      "====> Epoch: 9\tTotal Loss: 200.4660\t Avg Loss: 0.0017\tCorrect: 105757/117711\tPercentage Correct: 89.84\n",
      "====> Val Loss: 45.5729\t Avg Loss: 0.0035\tCorrect: 11088/13079\tPercentage Correct: 84.78\n",
      "====> Test Loss: 119.2396\t Avg Loss: 0.0036\tCorrect: 27463/32698\tPercentage Correct: 83.99\n",
      "Train Epoch: 10\t[2000/117711 (2%)]\tTotal Loss: 4.8986\tAvg Loss: 0.0024\n",
      "Train Epoch: 10\t[4000/117711 (3%)]\tTotal Loss: 8.7121\tAvg Loss: 0.0022\n",
      "Train Epoch: 10\t[6000/117711 (5%)]\tTotal Loss: 12.1120\tAvg Loss: 0.0020\n",
      "Train Epoch: 10\t[8000/117711 (7%)]\tTotal Loss: 15.3135\tAvg Loss: 0.0019\n",
      "Train Epoch: 10\t[10000/117711 (8%)]\tTotal Loss: 18.4263\tAvg Loss: 0.0018\n",
      "Train Epoch: 10\t[12000/117711 (10%)]\tTotal Loss: 22.2103\tAvg Loss: 0.0019\n",
      "Train Epoch: 10\t[14000/117711 (12%)]\tTotal Loss: 25.3944\tAvg Loss: 0.0018\n",
      "Train Epoch: 10\t[16000/117711 (14%)]\tTotal Loss: 28.5792\tAvg Loss: 0.0018\n",
      "Train Epoch: 10\t[18000/117711 (15%)]\tTotal Loss: 31.7582\tAvg Loss: 0.0018\n",
      "Train Epoch: 10\t[20000/117711 (17%)]\tTotal Loss: 35.1950\tAvg Loss: 0.0018\n",
      "Train Epoch: 10\t[22000/117711 (19%)]\tTotal Loss: 38.4828\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[24000/117711 (20%)]\tTotal Loss: 41.6848\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[26000/117711 (22%)]\tTotal Loss: 45.0154\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[28000/117711 (24%)]\tTotal Loss: 48.3844\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[30000/117711 (25%)]\tTotal Loss: 51.8825\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[32000/117711 (27%)]\tTotal Loss: 55.0940\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[34000/117711 (29%)]\tTotal Loss: 58.3605\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[36000/117711 (31%)]\tTotal Loss: 61.6049\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[38000/117711 (32%)]\tTotal Loss: 64.6048\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[40000/117711 (34%)]\tTotal Loss: 68.0513\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[42000/117711 (36%)]\tTotal Loss: 71.2548\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[44000/117711 (37%)]\tTotal Loss: 74.5823\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[46000/117711 (39%)]\tTotal Loss: 77.9606\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[48000/117711 (41%)]\tTotal Loss: 81.0988\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[50000/117711 (42%)]\tTotal Loss: 84.5068\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[52000/117711 (44%)]\tTotal Loss: 87.6082\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[54000/117711 (46%)]\tTotal Loss: 90.9693\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[56000/117711 (48%)]\tTotal Loss: 94.2928\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[58000/117711 (49%)]\tTotal Loss: 97.3998\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[60000/117711 (51%)]\tTotal Loss: 100.7953\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[62000/117711 (53%)]\tTotal Loss: 104.1540\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[64000/117711 (54%)]\tTotal Loss: 107.5301\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[66000/117711 (56%)]\tTotal Loss: 111.0271\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[68000/117711 (58%)]\tTotal Loss: 114.1946\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[70000/117711 (59%)]\tTotal Loss: 117.4473\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[72000/117711 (61%)]\tTotal Loss: 120.9793\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[74000/117711 (63%)]\tTotal Loss: 124.4743\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[76000/117711 (65%)]\tTotal Loss: 127.7921\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[78000/117711 (66%)]\tTotal Loss: 131.3680\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[80000/117711 (68%)]\tTotal Loss: 134.8866\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[82000/117711 (70%)]\tTotal Loss: 138.1148\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[84000/117711 (71%)]\tTotal Loss: 141.4137\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[86000/117711 (73%)]\tTotal Loss: 144.5587\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[88000/117711 (75%)]\tTotal Loss: 147.9065\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[90000/117711 (76%)]\tTotal Loss: 151.0038\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[92000/117711 (78%)]\tTotal Loss: 154.1967\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[94000/117711 (80%)]\tTotal Loss: 157.5634\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[96000/117711 (81%)]\tTotal Loss: 161.0265\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[98000/117711 (83%)]\tTotal Loss: 164.2470\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[100000/117711 (85%)]\tTotal Loss: 167.7182\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[102000/117711 (87%)]\tTotal Loss: 170.6958\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[104000/117711 (88%)]\tTotal Loss: 174.0517\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[106000/117711 (90%)]\tTotal Loss: 176.9678\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[108000/117711 (92%)]\tTotal Loss: 180.3283\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[110000/117711 (93%)]\tTotal Loss: 183.7302\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[112000/117711 (95%)]\tTotal Loss: 186.7001\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[114000/117711 (97%)]\tTotal Loss: 189.7746\tAvg Loss: 0.0017\n",
      "Train Epoch: 10\t[116000/117711 (98%)]\tTotal Loss: 192.8408\tAvg Loss: 0.0017\n",
      "====> Epoch: 10\tTotal Loss: 195.9962\t Avg Loss: 0.0017\tCorrect: 106009/117711\tPercentage Correct: 90.06\n",
      "====> Val Loss: 888.4713\t Avg Loss: 0.0679\tCorrect: 6365/13079\tPercentage Correct: 48.67\n",
      "====> Test Loss: 2231.5860\t Avg Loss: 0.0682\tCorrect: 15846/32698\tPercentage Correct: 48.46\n",
      "Train Epoch: 11\t[2000/117711 (2%)]\tTotal Loss: 3.6248\tAvg Loss: 0.0018\n",
      "Train Epoch: 11\t[4000/117711 (3%)]\tTotal Loss: 6.8535\tAvg Loss: 0.0017\n",
      "Train Epoch: 11\t[6000/117711 (5%)]\tTotal Loss: 10.0353\tAvg Loss: 0.0017\n",
      "Train Epoch: 11\t[8000/117711 (7%)]\tTotal Loss: 13.2607\tAvg Loss: 0.0017\n",
      "Train Epoch: 11\t[10000/117711 (8%)]\tTotal Loss: 16.6225\tAvg Loss: 0.0017\n",
      "Train Epoch: 11\t[12000/117711 (10%)]\tTotal Loss: 19.8563\tAvg Loss: 0.0017\n",
      "Train Epoch: 11\t[14000/117711 (12%)]\tTotal Loss: 22.8495\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[16000/117711 (14%)]\tTotal Loss: 26.3457\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[18000/117711 (15%)]\tTotal Loss: 29.3300\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[20000/117711 (17%)]\tTotal Loss: 32.4492\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[22000/117711 (19%)]\tTotal Loss: 35.6238\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[24000/117711 (20%)]\tTotal Loss: 38.6746\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[26000/117711 (22%)]\tTotal Loss: 41.9449\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[28000/117711 (24%)]\tTotal Loss: 44.9835\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[30000/117711 (25%)]\tTotal Loss: 47.9770\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[32000/117711 (27%)]\tTotal Loss: 51.1100\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[34000/117711 (29%)]\tTotal Loss: 54.0025\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[36000/117711 (31%)]\tTotal Loss: 57.0036\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[38000/117711 (32%)]\tTotal Loss: 60.0570\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[40000/117711 (34%)]\tTotal Loss: 63.3729\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[42000/117711 (36%)]\tTotal Loss: 66.4037\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[44000/117711 (37%)]\tTotal Loss: 69.7416\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[46000/117711 (39%)]\tTotal Loss: 73.2724\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[48000/117711 (41%)]\tTotal Loss: 76.4317\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[50000/117711 (42%)]\tTotal Loss: 79.9105\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[52000/117711 (44%)]\tTotal Loss: 83.3824\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[54000/117711 (46%)]\tTotal Loss: 86.3628\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[56000/117711 (48%)]\tTotal Loss: 89.6643\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[58000/117711 (49%)]\tTotal Loss: 92.7231\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[60000/117711 (51%)]\tTotal Loss: 96.0200\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[62000/117711 (53%)]\tTotal Loss: 99.1083\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[64000/117711 (54%)]\tTotal Loss: 102.4170\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[66000/117711 (56%)]\tTotal Loss: 105.6366\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[68000/117711 (58%)]\tTotal Loss: 109.1923\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[70000/117711 (59%)]\tTotal Loss: 112.5188\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[72000/117711 (61%)]\tTotal Loss: 115.7256\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[74000/117711 (63%)]\tTotal Loss: 119.1302\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[76000/117711 (65%)]\tTotal Loss: 122.4421\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[78000/117711 (66%)]\tTotal Loss: 125.7114\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[80000/117711 (68%)]\tTotal Loss: 129.0636\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[82000/117711 (70%)]\tTotal Loss: 132.3951\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[84000/117711 (71%)]\tTotal Loss: 135.5255\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[86000/117711 (73%)]\tTotal Loss: 138.6614\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[88000/117711 (75%)]\tTotal Loss: 141.9896\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[90000/117711 (76%)]\tTotal Loss: 145.1281\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[92000/117711 (78%)]\tTotal Loss: 148.2631\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[94000/117711 (80%)]\tTotal Loss: 151.5869\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[96000/117711 (81%)]\tTotal Loss: 154.8855\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[98000/117711 (83%)]\tTotal Loss: 158.1436\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[100000/117711 (85%)]\tTotal Loss: 161.3386\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[102000/117711 (87%)]\tTotal Loss: 164.7792\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[104000/117711 (88%)]\tTotal Loss: 168.1095\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[106000/117711 (90%)]\tTotal Loss: 171.2671\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[108000/117711 (92%)]\tTotal Loss: 174.5032\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[110000/117711 (93%)]\tTotal Loss: 177.6166\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[112000/117711 (95%)]\tTotal Loss: 181.1086\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[114000/117711 (97%)]\tTotal Loss: 184.4886\tAvg Loss: 0.0016\n",
      "Train Epoch: 11\t[116000/117711 (98%)]\tTotal Loss: 187.9741\tAvg Loss: 0.0016\n",
      "====> Epoch: 11\tTotal Loss: 191.3631\t Avg Loss: 0.0016\tCorrect: 106070/117711\tPercentage Correct: 90.11\n",
      "====> Val Loss: 33.3031\t Avg Loss: 0.0025\tCorrect: 11409/13079\tPercentage Correct: 87.23\n",
      "====> Test Loss: 80.0387\t Avg Loss: 0.0024\tCorrect: 28529/32698\tPercentage Correct: 87.25\n",
      "--- saved best model ---\n",
      "Train Epoch: 12\t[2000/117711 (2%)]\tTotal Loss: 5.1119\tAvg Loss: 0.0026\n",
      "Train Epoch: 12\t[4000/117711 (3%)]\tTotal Loss: 9.2594\tAvg Loss: 0.0023\n",
      "Train Epoch: 12\t[6000/117711 (5%)]\tTotal Loss: 12.8243\tAvg Loss: 0.0021\n",
      "Train Epoch: 12\t[8000/117711 (7%)]\tTotal Loss: 16.2602\tAvg Loss: 0.0020\n",
      "Train Epoch: 12\t[10000/117711 (8%)]\tTotal Loss: 19.1858\tAvg Loss: 0.0019\n",
      "Train Epoch: 12\t[12000/117711 (10%)]\tTotal Loss: 22.6351\tAvg Loss: 0.0019\n",
      "Train Epoch: 12\t[14000/117711 (12%)]\tTotal Loss: 25.7947\tAvg Loss: 0.0018\n",
      "Train Epoch: 12\t[16000/117711 (14%)]\tTotal Loss: 29.1868\tAvg Loss: 0.0018\n",
      "Train Epoch: 12\t[18000/117711 (15%)]\tTotal Loss: 32.9780\tAvg Loss: 0.0018\n",
      "Train Epoch: 12\t[20000/117711 (17%)]\tTotal Loss: 36.3235\tAvg Loss: 0.0018\n",
      "Train Epoch: 12\t[22000/117711 (19%)]\tTotal Loss: 39.6901\tAvg Loss: 0.0018\n",
      "Train Epoch: 12\t[24000/117711 (20%)]\tTotal Loss: 42.8620\tAvg Loss: 0.0018\n",
      "Train Epoch: 12\t[26000/117711 (22%)]\tTotal Loss: 46.1109\tAvg Loss: 0.0018\n",
      "Train Epoch: 12\t[28000/117711 (24%)]\tTotal Loss: 49.4684\tAvg Loss: 0.0018\n",
      "Train Epoch: 12\t[30000/117711 (25%)]\tTotal Loss: 52.6755\tAvg Loss: 0.0018\n",
      "Train Epoch: 12\t[32000/117711 (27%)]\tTotal Loss: 55.8182\tAvg Loss: 0.0017\n",
      "Train Epoch: 12\t[34000/117711 (29%)]\tTotal Loss: 59.0788\tAvg Loss: 0.0017\n",
      "Train Epoch: 12\t[36000/117711 (31%)]\tTotal Loss: 62.4930\tAvg Loss: 0.0017\n",
      "Train Epoch: 12\t[38000/117711 (32%)]\tTotal Loss: 65.9686\tAvg Loss: 0.0017\n",
      "Train Epoch: 12\t[40000/117711 (34%)]\tTotal Loss: 68.8440\tAvg Loss: 0.0017\n",
      "Train Epoch: 12\t[42000/117711 (36%)]\tTotal Loss: 71.7114\tAvg Loss: 0.0017\n",
      "Train Epoch: 12\t[44000/117711 (37%)]\tTotal Loss: 74.9489\tAvg Loss: 0.0017\n",
      "Train Epoch: 12\t[46000/117711 (39%)]\tTotal Loss: 77.9237\tAvg Loss: 0.0017\n",
      "Train Epoch: 12\t[48000/117711 (41%)]\tTotal Loss: 81.0044\tAvg Loss: 0.0017\n",
      "Train Epoch: 12\t[50000/117711 (42%)]\tTotal Loss: 83.8647\tAvg Loss: 0.0017\n",
      "Train Epoch: 12\t[52000/117711 (44%)]\tTotal Loss: 86.7611\tAvg Loss: 0.0017\n",
      "Train Epoch: 12\t[54000/117711 (46%)]\tTotal Loss: 89.8980\tAvg Loss: 0.0017\n",
      "Train Epoch: 12\t[56000/117711 (48%)]\tTotal Loss: 93.0556\tAvg Loss: 0.0017\n",
      "Train Epoch: 12\t[58000/117711 (49%)]\tTotal Loss: 96.2111\tAvg Loss: 0.0017\n",
      "Train Epoch: 12\t[60000/117711 (51%)]\tTotal Loss: 99.1344\tAvg Loss: 0.0017\n",
      "Train Epoch: 12\t[62000/117711 (53%)]\tTotal Loss: 102.2452\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[64000/117711 (54%)]\tTotal Loss: 105.4208\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[66000/117711 (56%)]\tTotal Loss: 108.4911\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[68000/117711 (58%)]\tTotal Loss: 112.0982\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[70000/117711 (59%)]\tTotal Loss: 115.2235\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[72000/117711 (61%)]\tTotal Loss: 118.3011\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[74000/117711 (63%)]\tTotal Loss: 121.4645\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[76000/117711 (65%)]\tTotal Loss: 124.3681\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[78000/117711 (66%)]\tTotal Loss: 127.4261\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[80000/117711 (68%)]\tTotal Loss: 130.6114\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[82000/117711 (70%)]\tTotal Loss: 133.7601\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[84000/117711 (71%)]\tTotal Loss: 136.5674\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[86000/117711 (73%)]\tTotal Loss: 139.7084\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[88000/117711 (75%)]\tTotal Loss: 142.7302\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[90000/117711 (76%)]\tTotal Loss: 145.8308\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[92000/117711 (78%)]\tTotal Loss: 149.0001\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[94000/117711 (80%)]\tTotal Loss: 151.9493\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[96000/117711 (81%)]\tTotal Loss: 154.9323\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[98000/117711 (83%)]\tTotal Loss: 158.0919\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[100000/117711 (85%)]\tTotal Loss: 161.6096\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[102000/117711 (87%)]\tTotal Loss: 164.9838\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[104000/117711 (88%)]\tTotal Loss: 168.3630\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[106000/117711 (90%)]\tTotal Loss: 171.4745\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[108000/117711 (92%)]\tTotal Loss: 174.9378\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[110000/117711 (93%)]\tTotal Loss: 177.9070\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[112000/117711 (95%)]\tTotal Loss: 181.1613\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[114000/117711 (97%)]\tTotal Loss: 184.4721\tAvg Loss: 0.0016\n",
      "Train Epoch: 12\t[116000/117711 (98%)]\tTotal Loss: 187.7169\tAvg Loss: 0.0016\n",
      "====> Epoch: 12\tTotal Loss: 190.5232\t Avg Loss: 0.0016\tCorrect: 106162/117711\tPercentage Correct: 90.19\n",
      "====> Val Loss: 35.5633\t Avg Loss: 0.0027\tCorrect: 11349/13079\tPercentage Correct: 86.77\n",
      "====> Test Loss: 86.6626\t Avg Loss: 0.0027\tCorrect: 28256/32698\tPercentage Correct: 86.42\n",
      "Train Epoch: 13\t[2000/117711 (2%)]\tTotal Loss: 3.3263\tAvg Loss: 0.0017\n",
      "Train Epoch: 13\t[4000/117711 (3%)]\tTotal Loss: 6.5619\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[6000/117711 (5%)]\tTotal Loss: 9.9133\tAvg Loss: 0.0017\n",
      "Train Epoch: 13\t[8000/117711 (7%)]\tTotal Loss: 13.0850\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[10000/117711 (8%)]\tTotal Loss: 16.2994\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[12000/117711 (10%)]\tTotal Loss: 19.3208\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[14000/117711 (12%)]\tTotal Loss: 22.2953\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[16000/117711 (14%)]\tTotal Loss: 25.2937\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[18000/117711 (15%)]\tTotal Loss: 28.4989\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[20000/117711 (17%)]\tTotal Loss: 31.4537\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[22000/117711 (19%)]\tTotal Loss: 34.6835\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[24000/117711 (20%)]\tTotal Loss: 37.3405\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[26000/117711 (22%)]\tTotal Loss: 40.2667\tAvg Loss: 0.0015\n",
      "Train Epoch: 13\t[28000/117711 (24%)]\tTotal Loss: 43.0744\tAvg Loss: 0.0015\n",
      "Train Epoch: 13\t[30000/117711 (25%)]\tTotal Loss: 46.1381\tAvg Loss: 0.0015\n",
      "Train Epoch: 13\t[32000/117711 (27%)]\tTotal Loss: 49.0996\tAvg Loss: 0.0015\n",
      "Train Epoch: 13\t[34000/117711 (29%)]\tTotal Loss: 51.8980\tAvg Loss: 0.0015\n",
      "Train Epoch: 13\t[36000/117711 (31%)]\tTotal Loss: 54.6698\tAvg Loss: 0.0015\n",
      "Train Epoch: 13\t[38000/117711 (32%)]\tTotal Loss: 57.8358\tAvg Loss: 0.0015\n",
      "Train Epoch: 13\t[40000/117711 (34%)]\tTotal Loss: 60.8252\tAvg Loss: 0.0015\n",
      "Train Epoch: 13\t[42000/117711 (36%)]\tTotal Loss: 64.2522\tAvg Loss: 0.0015\n",
      "Train Epoch: 13\t[44000/117711 (37%)]\tTotal Loss: 67.4921\tAvg Loss: 0.0015\n",
      "Train Epoch: 13\t[46000/117711 (39%)]\tTotal Loss: 70.5971\tAvg Loss: 0.0015\n",
      "Train Epoch: 13\t[48000/117711 (41%)]\tTotal Loss: 74.1560\tAvg Loss: 0.0015\n",
      "Train Epoch: 13\t[50000/117711 (42%)]\tTotal Loss: 77.4117\tAvg Loss: 0.0015\n",
      "Train Epoch: 13\t[52000/117711 (44%)]\tTotal Loss: 80.7147\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[54000/117711 (46%)]\tTotal Loss: 83.8727\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[56000/117711 (48%)]\tTotal Loss: 86.8076\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[58000/117711 (49%)]\tTotal Loss: 89.8173\tAvg Loss: 0.0015\n",
      "Train Epoch: 13\t[60000/117711 (51%)]\tTotal Loss: 93.1826\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[62000/117711 (53%)]\tTotal Loss: 96.6727\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[64000/117711 (54%)]\tTotal Loss: 99.7913\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[66000/117711 (56%)]\tTotal Loss: 103.3488\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[68000/117711 (58%)]\tTotal Loss: 106.5888\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[70000/117711 (59%)]\tTotal Loss: 110.0204\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[72000/117711 (61%)]\tTotal Loss: 113.5037\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[74000/117711 (63%)]\tTotal Loss: 116.5426\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[76000/117711 (65%)]\tTotal Loss: 119.7076\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[78000/117711 (66%)]\tTotal Loss: 122.9467\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[80000/117711 (68%)]\tTotal Loss: 126.2233\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[82000/117711 (70%)]\tTotal Loss: 129.6616\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[84000/117711 (71%)]\tTotal Loss: 132.7713\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[86000/117711 (73%)]\tTotal Loss: 135.9882\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[88000/117711 (75%)]\tTotal Loss: 139.3876\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[90000/117711 (76%)]\tTotal Loss: 142.6403\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[92000/117711 (78%)]\tTotal Loss: 145.9013\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[94000/117711 (80%)]\tTotal Loss: 149.0688\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[96000/117711 (81%)]\tTotal Loss: 152.1213\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[98000/117711 (83%)]\tTotal Loss: 155.4659\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[100000/117711 (85%)]\tTotal Loss: 158.5508\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[102000/117711 (87%)]\tTotal Loss: 161.5835\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[104000/117711 (88%)]\tTotal Loss: 164.6656\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[106000/117711 (90%)]\tTotal Loss: 167.7317\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[108000/117711 (92%)]\tTotal Loss: 171.0186\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[110000/117711 (93%)]\tTotal Loss: 174.1606\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[112000/117711 (95%)]\tTotal Loss: 177.2122\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[114000/117711 (97%)]\tTotal Loss: 180.3779\tAvg Loss: 0.0016\n",
      "Train Epoch: 13\t[116000/117711 (98%)]\tTotal Loss: 183.6621\tAvg Loss: 0.0016\n",
      "====> Epoch: 13\tTotal Loss: 186.6683\t Avg Loss: 0.0016\tCorrect: 106166/117711\tPercentage Correct: 90.19\n",
      "====> Val Loss: 224.6124\t Avg Loss: 0.0172\tCorrect: 8779/13079\tPercentage Correct: 67.12\n",
      "====> Test Loss: 580.9308\t Avg Loss: 0.0178\tCorrect: 21763/32698\tPercentage Correct: 66.56\n",
      "Train Epoch: 14\t[2000/117711 (2%)]\tTotal Loss: 3.4382\tAvg Loss: 0.0017\n",
      "Train Epoch: 14\t[4000/117711 (3%)]\tTotal Loss: 6.5430\tAvg Loss: 0.0016\n",
      "Train Epoch: 14\t[6000/117711 (5%)]\tTotal Loss: 9.6285\tAvg Loss: 0.0016\n",
      "Train Epoch: 14\t[8000/117711 (7%)]\tTotal Loss: 12.7621\tAvg Loss: 0.0016\n",
      "Train Epoch: 14\t[10000/117711 (8%)]\tTotal Loss: 15.7868\tAvg Loss: 0.0016\n",
      "Train Epoch: 14\t[12000/117711 (10%)]\tTotal Loss: 18.6239\tAvg Loss: 0.0016\n",
      "Train Epoch: 14\t[14000/117711 (12%)]\tTotal Loss: 21.8735\tAvg Loss: 0.0016\n",
      "Train Epoch: 14\t[16000/117711 (14%)]\tTotal Loss: 25.0452\tAvg Loss: 0.0016\n",
      "Train Epoch: 14\t[18000/117711 (15%)]\tTotal Loss: 27.9848\tAvg Loss: 0.0016\n",
      "Train Epoch: 14\t[20000/117711 (17%)]\tTotal Loss: 30.7654\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[22000/117711 (19%)]\tTotal Loss: 33.9774\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[24000/117711 (20%)]\tTotal Loss: 36.7919\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[26000/117711 (22%)]\tTotal Loss: 40.0489\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[28000/117711 (24%)]\tTotal Loss: 43.1133\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[30000/117711 (25%)]\tTotal Loss: 46.0614\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[32000/117711 (27%)]\tTotal Loss: 49.1774\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[34000/117711 (29%)]\tTotal Loss: 52.0469\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[36000/117711 (31%)]\tTotal Loss: 54.8959\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[38000/117711 (32%)]\tTotal Loss: 57.9791\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[40000/117711 (34%)]\tTotal Loss: 60.7999\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[42000/117711 (36%)]\tTotal Loss: 63.7705\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[44000/117711 (37%)]\tTotal Loss: 66.8500\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[46000/117711 (39%)]\tTotal Loss: 69.7580\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[48000/117711 (41%)]\tTotal Loss: 72.6852\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[50000/117711 (42%)]\tTotal Loss: 75.8868\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[52000/117711 (44%)]\tTotal Loss: 78.9786\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[54000/117711 (46%)]\tTotal Loss: 82.0727\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[56000/117711 (48%)]\tTotal Loss: 85.1240\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[58000/117711 (49%)]\tTotal Loss: 88.2079\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[60000/117711 (51%)]\tTotal Loss: 91.3771\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[62000/117711 (53%)]\tTotal Loss: 94.5279\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[64000/117711 (54%)]\tTotal Loss: 97.8401\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[66000/117711 (56%)]\tTotal Loss: 100.8349\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[68000/117711 (58%)]\tTotal Loss: 104.0351\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[70000/117711 (59%)]\tTotal Loss: 107.3499\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[72000/117711 (61%)]\tTotal Loss: 110.4595\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[74000/117711 (63%)]\tTotal Loss: 113.5875\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[76000/117711 (65%)]\tTotal Loss: 116.9319\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[78000/117711 (66%)]\tTotal Loss: 120.3794\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[80000/117711 (68%)]\tTotal Loss: 123.4984\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[82000/117711 (70%)]\tTotal Loss: 126.8026\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[84000/117711 (71%)]\tTotal Loss: 129.7869\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[86000/117711 (73%)]\tTotal Loss: 133.0049\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[88000/117711 (75%)]\tTotal Loss: 135.7615\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[90000/117711 (76%)]\tTotal Loss: 139.0529\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[92000/117711 (78%)]\tTotal Loss: 142.2325\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[94000/117711 (80%)]\tTotal Loss: 145.3985\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[96000/117711 (81%)]\tTotal Loss: 148.6500\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[98000/117711 (83%)]\tTotal Loss: 151.6994\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[100000/117711 (85%)]\tTotal Loss: 154.9167\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[102000/117711 (87%)]\tTotal Loss: 157.6730\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[104000/117711 (88%)]\tTotal Loss: 160.9883\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[106000/117711 (90%)]\tTotal Loss: 164.2844\tAvg Loss: 0.0015\n",
      "Train Epoch: 14\t[108000/117711 (92%)]\tTotal Loss: 167.7192\tAvg Loss: 0.0016\n",
      "Train Epoch: 14\t[110000/117711 (93%)]\tTotal Loss: 170.8355\tAvg Loss: 0.0016\n",
      "Train Epoch: 14\t[112000/117711 (95%)]\tTotal Loss: 174.2094\tAvg Loss: 0.0016\n",
      "Train Epoch: 14\t[114000/117711 (97%)]\tTotal Loss: 177.1820\tAvg Loss: 0.0016\n",
      "Train Epoch: 14\t[116000/117711 (98%)]\tTotal Loss: 180.2770\tAvg Loss: 0.0016\n",
      "====> Epoch: 14\tTotal Loss: 184.5208\t Avg Loss: 0.0016\tCorrect: 106429/117711\tPercentage Correct: 90.42\n",
      "====> Val Loss: 992.8431\t Avg Loss: 0.0759\tCorrect: 6360/13079\tPercentage Correct: 48.63\n",
      "====> Test Loss: 2493.7479\t Avg Loss: 0.0763\tCorrect: 15867/32698\tPercentage Correct: 48.53\n",
      "Train Epoch: 15\t[2000/117711 (2%)]\tTotal Loss: 6.6134\tAvg Loss: 0.0033\n",
      "Train Epoch: 15\t[4000/117711 (3%)]\tTotal Loss: 10.5846\tAvg Loss: 0.0026\n",
      "Train Epoch: 15\t[6000/117711 (5%)]\tTotal Loss: 14.8324\tAvg Loss: 0.0025\n",
      "Train Epoch: 15\t[8000/117711 (7%)]\tTotal Loss: 18.0836\tAvg Loss: 0.0023\n",
      "Train Epoch: 15\t[10000/117711 (8%)]\tTotal Loss: 21.8718\tAvg Loss: 0.0022\n",
      "Train Epoch: 15\t[12000/117711 (10%)]\tTotal Loss: 25.0764\tAvg Loss: 0.0021\n",
      "Train Epoch: 15\t[14000/117711 (12%)]\tTotal Loss: 28.4080\tAvg Loss: 0.0020\n",
      "Train Epoch: 15\t[16000/117711 (14%)]\tTotal Loss: 31.4481\tAvg Loss: 0.0020\n",
      "Train Epoch: 15\t[18000/117711 (15%)]\tTotal Loss: 34.4521\tAvg Loss: 0.0019\n",
      "Train Epoch: 15\t[20000/117711 (17%)]\tTotal Loss: 37.4579\tAvg Loss: 0.0019\n",
      "Train Epoch: 15\t[22000/117711 (19%)]\tTotal Loss: 40.5117\tAvg Loss: 0.0018\n",
      "Train Epoch: 15\t[24000/117711 (20%)]\tTotal Loss: 43.4685\tAvg Loss: 0.0018\n",
      "Train Epoch: 15\t[26000/117711 (22%)]\tTotal Loss: 46.2169\tAvg Loss: 0.0018\n",
      "Train Epoch: 15\t[28000/117711 (24%)]\tTotal Loss: 49.0250\tAvg Loss: 0.0018\n",
      "Train Epoch: 15\t[30000/117711 (25%)]\tTotal Loss: 52.1919\tAvg Loss: 0.0017\n",
      "Train Epoch: 15\t[32000/117711 (27%)]\tTotal Loss: 55.2842\tAvg Loss: 0.0017\n",
      "Train Epoch: 15\t[34000/117711 (29%)]\tTotal Loss: 58.0961\tAvg Loss: 0.0017\n",
      "Train Epoch: 15\t[36000/117711 (31%)]\tTotal Loss: 61.1366\tAvg Loss: 0.0017\n",
      "Train Epoch: 15\t[38000/117711 (32%)]\tTotal Loss: 64.1354\tAvg Loss: 0.0017\n",
      "Train Epoch: 15\t[40000/117711 (34%)]\tTotal Loss: 67.1453\tAvg Loss: 0.0017\n",
      "Train Epoch: 15\t[42000/117711 (36%)]\tTotal Loss: 70.4015\tAvg Loss: 0.0017\n",
      "Train Epoch: 15\t[44000/117711 (37%)]\tTotal Loss: 73.1961\tAvg Loss: 0.0017\n",
      "Train Epoch: 15\t[46000/117711 (39%)]\tTotal Loss: 76.2691\tAvg Loss: 0.0017\n",
      "Train Epoch: 15\t[48000/117711 (41%)]\tTotal Loss: 79.1971\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[50000/117711 (42%)]\tTotal Loss: 82.3424\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[52000/117711 (44%)]\tTotal Loss: 85.2932\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[54000/117711 (46%)]\tTotal Loss: 88.3644\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[56000/117711 (48%)]\tTotal Loss: 91.2646\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[58000/117711 (49%)]\tTotal Loss: 94.2925\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[60000/117711 (51%)]\tTotal Loss: 97.3911\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[62000/117711 (53%)]\tTotal Loss: 100.4544\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[64000/117711 (54%)]\tTotal Loss: 103.1291\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[66000/117711 (56%)]\tTotal Loss: 106.2009\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[68000/117711 (58%)]\tTotal Loss: 109.2816\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[70000/117711 (59%)]\tTotal Loss: 112.2931\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[72000/117711 (61%)]\tTotal Loss: 115.5534\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[74000/117711 (63%)]\tTotal Loss: 118.7307\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[76000/117711 (65%)]\tTotal Loss: 121.8133\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[78000/117711 (66%)]\tTotal Loss: 124.8694\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[80000/117711 (68%)]\tTotal Loss: 128.1445\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[82000/117711 (70%)]\tTotal Loss: 131.2298\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[84000/117711 (71%)]\tTotal Loss: 134.3904\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[86000/117711 (73%)]\tTotal Loss: 137.3478\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[88000/117711 (75%)]\tTotal Loss: 140.4057\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[90000/117711 (76%)]\tTotal Loss: 143.0468\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[92000/117711 (78%)]\tTotal Loss: 145.9346\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[94000/117711 (80%)]\tTotal Loss: 148.7571\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[96000/117711 (81%)]\tTotal Loss: 151.7346\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[98000/117711 (83%)]\tTotal Loss: 154.8840\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[100000/117711 (85%)]\tTotal Loss: 157.8695\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[102000/117711 (87%)]\tTotal Loss: 160.9868\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[104000/117711 (88%)]\tTotal Loss: 164.0521\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[106000/117711 (90%)]\tTotal Loss: 167.3146\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[108000/117711 (92%)]\tTotal Loss: 170.3266\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[110000/117711 (93%)]\tTotal Loss: 173.1454\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[112000/117711 (95%)]\tTotal Loss: 176.1204\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[114000/117711 (97%)]\tTotal Loss: 179.1867\tAvg Loss: 0.0016\n",
      "Train Epoch: 15\t[116000/117711 (98%)]\tTotal Loss: 182.2509\tAvg Loss: 0.0016\n",
      "====> Epoch: 15\tTotal Loss: 184.9273\t Avg Loss: 0.0016\tCorrect: 106409/117711\tPercentage Correct: 90.40\n",
      "====> Val Loss: 132.4287\t Avg Loss: 0.0101\tCorrect: 9424/13079\tPercentage Correct: 72.05\n",
      "====> Test Loss: 343.0485\t Avg Loss: 0.0105\tCorrect: 23394/32698\tPercentage Correct: 71.55\n",
      "Train Epoch: 16\t[2000/117711 (2%)]\tTotal Loss: 3.0266\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[4000/117711 (3%)]\tTotal Loss: 6.0682\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[6000/117711 (5%)]\tTotal Loss: 9.2511\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[8000/117711 (7%)]\tTotal Loss: 12.0580\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[10000/117711 (8%)]\tTotal Loss: 14.9522\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[12000/117711 (10%)]\tTotal Loss: 17.8619\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[14000/117711 (12%)]\tTotal Loss: 20.7453\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[16000/117711 (14%)]\tTotal Loss: 23.7456\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[18000/117711 (15%)]\tTotal Loss: 26.4402\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[20000/117711 (17%)]\tTotal Loss: 29.1223\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[22000/117711 (19%)]\tTotal Loss: 32.1380\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[24000/117711 (20%)]\tTotal Loss: 35.2338\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[26000/117711 (22%)]\tTotal Loss: 38.1506\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[28000/117711 (24%)]\tTotal Loss: 40.9713\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[30000/117711 (25%)]\tTotal Loss: 43.8413\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[32000/117711 (27%)]\tTotal Loss: 46.7070\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[34000/117711 (29%)]\tTotal Loss: 49.4744\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[36000/117711 (31%)]\tTotal Loss: 52.3210\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[38000/117711 (32%)]\tTotal Loss: 55.1729\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[40000/117711 (34%)]\tTotal Loss: 58.0598\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[42000/117711 (36%)]\tTotal Loss: 61.1477\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[44000/117711 (37%)]\tTotal Loss: 64.0942\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[46000/117711 (39%)]\tTotal Loss: 66.8492\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[48000/117711 (41%)]\tTotal Loss: 70.2019\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[50000/117711 (42%)]\tTotal Loss: 73.4958\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[52000/117711 (44%)]\tTotal Loss: 76.3241\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[54000/117711 (46%)]\tTotal Loss: 79.4828\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[56000/117711 (48%)]\tTotal Loss: 82.6230\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[58000/117711 (49%)]\tTotal Loss: 85.8759\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[60000/117711 (51%)]\tTotal Loss: 88.8141\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[62000/117711 (53%)]\tTotal Loss: 91.6627\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[64000/117711 (54%)]\tTotal Loss: 94.7060\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[66000/117711 (56%)]\tTotal Loss: 97.7139\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[68000/117711 (58%)]\tTotal Loss: 100.9753\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[70000/117711 (59%)]\tTotal Loss: 104.1414\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[72000/117711 (61%)]\tTotal Loss: 107.0301\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[74000/117711 (63%)]\tTotal Loss: 110.1974\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[76000/117711 (65%)]\tTotal Loss: 113.1746\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[78000/117711 (66%)]\tTotal Loss: 116.1219\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[80000/117711 (68%)]\tTotal Loss: 119.1446\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[82000/117711 (70%)]\tTotal Loss: 122.0930\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[84000/117711 (71%)]\tTotal Loss: 125.3071\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[86000/117711 (73%)]\tTotal Loss: 128.2860\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[88000/117711 (75%)]\tTotal Loss: 131.2466\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[90000/117711 (76%)]\tTotal Loss: 133.9608\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[92000/117711 (78%)]\tTotal Loss: 136.9221\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[94000/117711 (80%)]\tTotal Loss: 139.9873\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[96000/117711 (81%)]\tTotal Loss: 143.0672\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[98000/117711 (83%)]\tTotal Loss: 146.0480\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[100000/117711 (85%)]\tTotal Loss: 149.1933\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[102000/117711 (87%)]\tTotal Loss: 152.0009\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[104000/117711 (88%)]\tTotal Loss: 155.1513\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[106000/117711 (90%)]\tTotal Loss: 158.3530\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[108000/117711 (92%)]\tTotal Loss: 161.5145\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[110000/117711 (93%)]\tTotal Loss: 164.4949\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[112000/117711 (95%)]\tTotal Loss: 167.7228\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[114000/117711 (97%)]\tTotal Loss: 171.0130\tAvg Loss: 0.0015\n",
      "Train Epoch: 16\t[116000/117711 (98%)]\tTotal Loss: 174.2597\tAvg Loss: 0.0015\n",
      "====> Epoch: 16\tTotal Loss: 176.9272\t Avg Loss: 0.0015\tCorrect: 106610/117711\tPercentage Correct: 90.57\n",
      "====> Val Loss: 103.9080\t Avg Loss: 0.0079\tCorrect: 9908/13079\tPercentage Correct: 75.76\n",
      "====> Test Loss: 267.2843\t Avg Loss: 0.0082\tCorrect: 24834/32698\tPercentage Correct: 75.95\n",
      "Train Epoch: 17\t[2000/117711 (2%)]\tTotal Loss: 4.5648\tAvg Loss: 0.0023\n",
      "Train Epoch: 17\t[4000/117711 (3%)]\tTotal Loss: 8.3062\tAvg Loss: 0.0021\n",
      "Train Epoch: 17\t[6000/117711 (5%)]\tTotal Loss: 11.2409\tAvg Loss: 0.0019\n",
      "Train Epoch: 17\t[8000/117711 (7%)]\tTotal Loss: 14.1011\tAvg Loss: 0.0018\n",
      "Train Epoch: 17\t[10000/117711 (8%)]\tTotal Loss: 17.0997\tAvg Loss: 0.0017\n",
      "Train Epoch: 17\t[12000/117711 (10%)]\tTotal Loss: 20.7267\tAvg Loss: 0.0017\n",
      "Train Epoch: 17\t[14000/117711 (12%)]\tTotal Loss: 23.7953\tAvg Loss: 0.0017\n",
      "Train Epoch: 17\t[16000/117711 (14%)]\tTotal Loss: 26.7082\tAvg Loss: 0.0017\n",
      "Train Epoch: 17\t[18000/117711 (15%)]\tTotal Loss: 29.7388\tAvg Loss: 0.0017\n",
      "Train Epoch: 17\t[20000/117711 (17%)]\tTotal Loss: 32.6227\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[22000/117711 (19%)]\tTotal Loss: 35.6487\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[24000/117711 (20%)]\tTotal Loss: 38.7339\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[26000/117711 (22%)]\tTotal Loss: 41.8611\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[28000/117711 (24%)]\tTotal Loss: 44.8405\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[30000/117711 (25%)]\tTotal Loss: 48.1478\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[32000/117711 (27%)]\tTotal Loss: 51.2318\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[34000/117711 (29%)]\tTotal Loss: 54.2994\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[36000/117711 (31%)]\tTotal Loss: 57.5365\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[38000/117711 (32%)]\tTotal Loss: 60.5084\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[40000/117711 (34%)]\tTotal Loss: 63.2475\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[42000/117711 (36%)]\tTotal Loss: 66.3682\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[44000/117711 (37%)]\tTotal Loss: 69.1289\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[46000/117711 (39%)]\tTotal Loss: 72.0186\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[48000/117711 (41%)]\tTotal Loss: 75.0814\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[50000/117711 (42%)]\tTotal Loss: 78.0328\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[52000/117711 (44%)]\tTotal Loss: 80.8607\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[54000/117711 (46%)]\tTotal Loss: 84.0224\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[56000/117711 (48%)]\tTotal Loss: 87.1300\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[58000/117711 (49%)]\tTotal Loss: 90.0382\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[60000/117711 (51%)]\tTotal Loss: 93.2492\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[62000/117711 (53%)]\tTotal Loss: 96.0973\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[64000/117711 (54%)]\tTotal Loss: 99.1830\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[66000/117711 (56%)]\tTotal Loss: 102.3126\tAvg Loss: 0.0016\n",
      "Train Epoch: 17\t[68000/117711 (58%)]\tTotal Loss: 105.3854\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[70000/117711 (59%)]\tTotal Loss: 108.2325\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[72000/117711 (61%)]\tTotal Loss: 111.1751\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[74000/117711 (63%)]\tTotal Loss: 114.1398\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[76000/117711 (65%)]\tTotal Loss: 117.1109\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[78000/117711 (66%)]\tTotal Loss: 120.5768\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[80000/117711 (68%)]\tTotal Loss: 123.5780\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[82000/117711 (70%)]\tTotal Loss: 126.5518\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[84000/117711 (71%)]\tTotal Loss: 129.8268\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[86000/117711 (73%)]\tTotal Loss: 132.9216\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[88000/117711 (75%)]\tTotal Loss: 136.3000\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[90000/117711 (76%)]\tTotal Loss: 139.1905\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[92000/117711 (78%)]\tTotal Loss: 142.2670\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[94000/117711 (80%)]\tTotal Loss: 145.3898\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[96000/117711 (81%)]\tTotal Loss: 148.5726\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[98000/117711 (83%)]\tTotal Loss: 151.4567\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[100000/117711 (85%)]\tTotal Loss: 154.6982\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[102000/117711 (87%)]\tTotal Loss: 157.7275\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[104000/117711 (88%)]\tTotal Loss: 160.6939\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[106000/117711 (90%)]\tTotal Loss: 163.6124\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[108000/117711 (92%)]\tTotal Loss: 166.7230\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[110000/117711 (93%)]\tTotal Loss: 169.5947\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[112000/117711 (95%)]\tTotal Loss: 172.3424\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[114000/117711 (97%)]\tTotal Loss: 175.4285\tAvg Loss: 0.0015\n",
      "Train Epoch: 17\t[116000/117711 (98%)]\tTotal Loss: 178.5351\tAvg Loss: 0.0015\n",
      "====> Epoch: 17\tTotal Loss: 181.0610\t Avg Loss: 0.0015\tCorrect: 106511/117711\tPercentage Correct: 90.49\n",
      "====> Val Loss: 37.6192\t Avg Loss: 0.0029\tCorrect: 11248/13079\tPercentage Correct: 86.00\n",
      "====> Test Loss: 91.6994\t Avg Loss: 0.0028\tCorrect: 28310/32698\tPercentage Correct: 86.58\n",
      "Train Epoch: 18\t[2000/117711 (2%)]\tTotal Loss: 3.0439\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[4000/117711 (3%)]\tTotal Loss: 5.8972\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[6000/117711 (5%)]\tTotal Loss: 8.9324\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[8000/117711 (7%)]\tTotal Loss: 11.9934\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[10000/117711 (8%)]\tTotal Loss: 14.8905\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[12000/117711 (10%)]\tTotal Loss: 17.9341\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[14000/117711 (12%)]\tTotal Loss: 20.9330\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[16000/117711 (14%)]\tTotal Loss: 23.6855\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[18000/117711 (15%)]\tTotal Loss: 26.6543\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[20000/117711 (17%)]\tTotal Loss: 29.5300\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[22000/117711 (19%)]\tTotal Loss: 32.3057\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[24000/117711 (20%)]\tTotal Loss: 35.0785\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[26000/117711 (22%)]\tTotal Loss: 38.1167\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[28000/117711 (24%)]\tTotal Loss: 41.1865\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[30000/117711 (25%)]\tTotal Loss: 44.0887\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[32000/117711 (27%)]\tTotal Loss: 47.1147\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[34000/117711 (29%)]\tTotal Loss: 50.0390\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[36000/117711 (31%)]\tTotal Loss: 53.0255\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[38000/117711 (32%)]\tTotal Loss: 55.9057\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[40000/117711 (34%)]\tTotal Loss: 58.9056\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[42000/117711 (36%)]\tTotal Loss: 61.9352\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[44000/117711 (37%)]\tTotal Loss: 64.8866\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[46000/117711 (39%)]\tTotal Loss: 67.5813\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[48000/117711 (41%)]\tTotal Loss: 70.5757\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[50000/117711 (42%)]\tTotal Loss: 73.6824\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[52000/117711 (44%)]\tTotal Loss: 76.7884\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[54000/117711 (46%)]\tTotal Loss: 79.6637\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[56000/117711 (48%)]\tTotal Loss: 82.9701\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[58000/117711 (49%)]\tTotal Loss: 85.9872\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[60000/117711 (51%)]\tTotal Loss: 88.7909\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[62000/117711 (53%)]\tTotal Loss: 91.7334\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[64000/117711 (54%)]\tTotal Loss: 94.8488\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[66000/117711 (56%)]\tTotal Loss: 97.8777\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[68000/117711 (58%)]\tTotal Loss: 100.9158\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[70000/117711 (59%)]\tTotal Loss: 103.9738\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[72000/117711 (61%)]\tTotal Loss: 107.2030\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[74000/117711 (63%)]\tTotal Loss: 110.4303\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[76000/117711 (65%)]\tTotal Loss: 113.6310\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[78000/117711 (66%)]\tTotal Loss: 116.7688\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[80000/117711 (68%)]\tTotal Loss: 119.6149\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[82000/117711 (70%)]\tTotal Loss: 122.3581\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[84000/117711 (71%)]\tTotal Loss: 125.2029\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[86000/117711 (73%)]\tTotal Loss: 128.1727\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[88000/117711 (75%)]\tTotal Loss: 130.8732\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[90000/117711 (76%)]\tTotal Loss: 133.8125\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[92000/117711 (78%)]\tTotal Loss: 136.5654\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[94000/117711 (80%)]\tTotal Loss: 139.8179\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[96000/117711 (81%)]\tTotal Loss: 142.7482\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[98000/117711 (83%)]\tTotal Loss: 145.6574\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[100000/117711 (85%)]\tTotal Loss: 149.2235\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[102000/117711 (87%)]\tTotal Loss: 152.3742\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[104000/117711 (88%)]\tTotal Loss: 155.6675\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[106000/117711 (90%)]\tTotal Loss: 158.7317\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[108000/117711 (92%)]\tTotal Loss: 161.7410\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[110000/117711 (93%)]\tTotal Loss: 164.9921\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[112000/117711 (95%)]\tTotal Loss: 167.8343\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[114000/117711 (97%)]\tTotal Loss: 170.9346\tAvg Loss: 0.0015\n",
      "Train Epoch: 18\t[116000/117711 (98%)]\tTotal Loss: 173.6455\tAvg Loss: 0.0015\n",
      "====> Epoch: 18\tTotal Loss: 176.3709\t Avg Loss: 0.0015\tCorrect: 106683/117711\tPercentage Correct: 90.63\n",
      "====> Val Loss: 33.2743\t Avg Loss: 0.0025\tCorrect: 11435/13079\tPercentage Correct: 87.43\n",
      "====> Test Loss: 80.4135\t Avg Loss: 0.0025\tCorrect: 28508/32698\tPercentage Correct: 87.19\n",
      "--- saved best model ---\n",
      "Train Epoch: 19\t[2000/117711 (2%)]\tTotal Loss: 3.5833\tAvg Loss: 0.0018\n",
      "Train Epoch: 19\t[4000/117711 (3%)]\tTotal Loss: 6.8137\tAvg Loss: 0.0017\n",
      "Train Epoch: 19\t[6000/117711 (5%)]\tTotal Loss: 10.1423\tAvg Loss: 0.0017\n",
      "Train Epoch: 19\t[8000/117711 (7%)]\tTotal Loss: 13.2166\tAvg Loss: 0.0017\n",
      "Train Epoch: 19\t[10000/117711 (8%)]\tTotal Loss: 16.0157\tAvg Loss: 0.0016\n",
      "Train Epoch: 19\t[12000/117711 (10%)]\tTotal Loss: 18.8821\tAvg Loss: 0.0016\n",
      "Train Epoch: 19\t[14000/117711 (12%)]\tTotal Loss: 21.6431\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[16000/117711 (14%)]\tTotal Loss: 24.5325\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[18000/117711 (15%)]\tTotal Loss: 27.6994\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[20000/117711 (17%)]\tTotal Loss: 30.6055\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[22000/117711 (19%)]\tTotal Loss: 33.6421\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[24000/117711 (20%)]\tTotal Loss: 36.8857\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[26000/117711 (22%)]\tTotal Loss: 39.9221\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[28000/117711 (24%)]\tTotal Loss: 42.5629\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[30000/117711 (25%)]\tTotal Loss: 45.2954\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[32000/117711 (27%)]\tTotal Loss: 47.9995\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[34000/117711 (29%)]\tTotal Loss: 50.9871\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[36000/117711 (31%)]\tTotal Loss: 53.8746\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[38000/117711 (32%)]\tTotal Loss: 56.6609\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[40000/117711 (34%)]\tTotal Loss: 59.4422\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[42000/117711 (36%)]\tTotal Loss: 62.1524\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[44000/117711 (37%)]\tTotal Loss: 65.1045\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[46000/117711 (39%)]\tTotal Loss: 67.9253\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[48000/117711 (41%)]\tTotal Loss: 70.8858\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[50000/117711 (42%)]\tTotal Loss: 73.7946\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[52000/117711 (44%)]\tTotal Loss: 76.5839\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[54000/117711 (46%)]\tTotal Loss: 79.3680\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[56000/117711 (48%)]\tTotal Loss: 82.2953\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[58000/117711 (49%)]\tTotal Loss: 85.1521\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[60000/117711 (51%)]\tTotal Loss: 88.1909\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[62000/117711 (53%)]\tTotal Loss: 91.2946\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[64000/117711 (54%)]\tTotal Loss: 94.1086\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[66000/117711 (56%)]\tTotal Loss: 96.7751\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[68000/117711 (58%)]\tTotal Loss: 99.5633\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[70000/117711 (59%)]\tTotal Loss: 102.5293\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[72000/117711 (61%)]\tTotal Loss: 105.3138\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[74000/117711 (63%)]\tTotal Loss: 108.1355\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[76000/117711 (65%)]\tTotal Loss: 110.9852\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[78000/117711 (66%)]\tTotal Loss: 113.9124\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[80000/117711 (68%)]\tTotal Loss: 116.7337\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[82000/117711 (70%)]\tTotal Loss: 119.5845\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[84000/117711 (71%)]\tTotal Loss: 122.3313\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[86000/117711 (73%)]\tTotal Loss: 125.2868\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[88000/117711 (75%)]\tTotal Loss: 128.1017\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[90000/117711 (76%)]\tTotal Loss: 130.9568\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[92000/117711 (78%)]\tTotal Loss: 133.7911\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[94000/117711 (80%)]\tTotal Loss: 136.5798\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[96000/117711 (81%)]\tTotal Loss: 139.4855\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[98000/117711 (83%)]\tTotal Loss: 142.8911\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[100000/117711 (85%)]\tTotal Loss: 146.1425\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[102000/117711 (87%)]\tTotal Loss: 149.0461\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[104000/117711 (88%)]\tTotal Loss: 151.9627\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[106000/117711 (90%)]\tTotal Loss: 155.0273\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[108000/117711 (92%)]\tTotal Loss: 158.0735\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[110000/117711 (93%)]\tTotal Loss: 161.1209\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[112000/117711 (95%)]\tTotal Loss: 164.1313\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[114000/117711 (97%)]\tTotal Loss: 167.4184\tAvg Loss: 0.0015\n",
      "Train Epoch: 19\t[116000/117711 (98%)]\tTotal Loss: 170.4777\tAvg Loss: 0.0015\n",
      "====> Epoch: 19\tTotal Loss: 173.3171\t Avg Loss: 0.0015\tCorrect: 106708/117711\tPercentage Correct: 90.65\n",
      "====> Val Loss: 26.9955\t Avg Loss: 0.0021\tCorrect: 11570/13079\tPercentage Correct: 88.46\n",
      "====> Test Loss: 63.6378\t Avg Loss: 0.0019\tCorrect: 29264/32698\tPercentage Correct: 89.50\n",
      "--- saved best model ---\n",
      "Train Epoch: 20\t[2000/117711 (2%)]\tTotal Loss: 4.0244\tAvg Loss: 0.0020\n",
      "Train Epoch: 20\t[4000/117711 (3%)]\tTotal Loss: 7.8520\tAvg Loss: 0.0020\n",
      "Train Epoch: 20\t[6000/117711 (5%)]\tTotal Loss: 11.6237\tAvg Loss: 0.0019\n",
      "Train Epoch: 20\t[8000/117711 (7%)]\tTotal Loss: 14.7795\tAvg Loss: 0.0018\n",
      "Train Epoch: 20\t[10000/117711 (8%)]\tTotal Loss: 18.2595\tAvg Loss: 0.0018\n",
      "Train Epoch: 20\t[12000/117711 (10%)]\tTotal Loss: 21.2667\tAvg Loss: 0.0018\n",
      "Train Epoch: 20\t[14000/117711 (12%)]\tTotal Loss: 23.8557\tAvg Loss: 0.0017\n",
      "Train Epoch: 20\t[16000/117711 (14%)]\tTotal Loss: 26.9605\tAvg Loss: 0.0017\n",
      "Train Epoch: 20\t[18000/117711 (15%)]\tTotal Loss: 29.8472\tAvg Loss: 0.0017\n",
      "Train Epoch: 20\t[20000/117711 (17%)]\tTotal Loss: 32.9186\tAvg Loss: 0.0016\n",
      "Train Epoch: 20\t[22000/117711 (19%)]\tTotal Loss: 35.8432\tAvg Loss: 0.0016\n",
      "Train Epoch: 20\t[24000/117711 (20%)]\tTotal Loss: 38.8800\tAvg Loss: 0.0016\n",
      "Train Epoch: 20\t[26000/117711 (22%)]\tTotal Loss: 41.8504\tAvg Loss: 0.0016\n",
      "Train Epoch: 20\t[28000/117711 (24%)]\tTotal Loss: 44.6805\tAvg Loss: 0.0016\n",
      "Train Epoch: 20\t[30000/117711 (25%)]\tTotal Loss: 47.5324\tAvg Loss: 0.0016\n",
      "Train Epoch: 20\t[32000/117711 (27%)]\tTotal Loss: 50.5608\tAvg Loss: 0.0016\n",
      "Train Epoch: 20\t[34000/117711 (29%)]\tTotal Loss: 53.3444\tAvg Loss: 0.0016\n",
      "Train Epoch: 20\t[36000/117711 (31%)]\tTotal Loss: 56.2661\tAvg Loss: 0.0016\n",
      "Train Epoch: 20\t[38000/117711 (32%)]\tTotal Loss: 59.1094\tAvg Loss: 0.0016\n",
      "Train Epoch: 20\t[40000/117711 (34%)]\tTotal Loss: 62.0579\tAvg Loss: 0.0016\n",
      "Train Epoch: 20\t[42000/117711 (36%)]\tTotal Loss: 64.9540\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[44000/117711 (37%)]\tTotal Loss: 67.7531\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[46000/117711 (39%)]\tTotal Loss: 71.0329\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[48000/117711 (41%)]\tTotal Loss: 74.1369\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[50000/117711 (42%)]\tTotal Loss: 77.0729\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[52000/117711 (44%)]\tTotal Loss: 80.1925\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[54000/117711 (46%)]\tTotal Loss: 83.0114\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[56000/117711 (48%)]\tTotal Loss: 85.9632\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[58000/117711 (49%)]\tTotal Loss: 88.7193\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[60000/117711 (51%)]\tTotal Loss: 91.6617\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[62000/117711 (53%)]\tTotal Loss: 94.4546\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[64000/117711 (54%)]\tTotal Loss: 97.3136\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[66000/117711 (56%)]\tTotal Loss: 100.2709\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[68000/117711 (58%)]\tTotal Loss: 103.1914\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[70000/117711 (59%)]\tTotal Loss: 105.9351\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[72000/117711 (61%)]\tTotal Loss: 108.5507\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[74000/117711 (63%)]\tTotal Loss: 111.2672\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[76000/117711 (65%)]\tTotal Loss: 114.2554\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[78000/117711 (66%)]\tTotal Loss: 117.1608\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[80000/117711 (68%)]\tTotal Loss: 120.0291\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[82000/117711 (70%)]\tTotal Loss: 122.7846\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[84000/117711 (71%)]\tTotal Loss: 126.0390\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[86000/117711 (73%)]\tTotal Loss: 129.1707\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[88000/117711 (75%)]\tTotal Loss: 131.9827\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[90000/117711 (76%)]\tTotal Loss: 134.6707\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[92000/117711 (78%)]\tTotal Loss: 137.6467\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[94000/117711 (80%)]\tTotal Loss: 140.9214\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[96000/117711 (81%)]\tTotal Loss: 144.0796\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[98000/117711 (83%)]\tTotal Loss: 147.0770\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[100000/117711 (85%)]\tTotal Loss: 149.9419\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[102000/117711 (87%)]\tTotal Loss: 152.7743\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[104000/117711 (88%)]\tTotal Loss: 155.7014\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[106000/117711 (90%)]\tTotal Loss: 158.4351\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[108000/117711 (92%)]\tTotal Loss: 161.4048\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[110000/117711 (93%)]\tTotal Loss: 164.1174\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[112000/117711 (95%)]\tTotal Loss: 166.9258\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[114000/117711 (97%)]\tTotal Loss: 169.6633\tAvg Loss: 0.0015\n",
      "Train Epoch: 20\t[116000/117711 (98%)]\tTotal Loss: 172.7908\tAvg Loss: 0.0015\n",
      "====> Epoch: 20\tTotal Loss: 175.3240\t Avg Loss: 0.0015\tCorrect: 106745/117711\tPercentage Correct: 90.68\n",
      "====> Val Loss: 515.3747\t Avg Loss: 0.0394\tCorrect: 6437/13079\tPercentage Correct: 49.22\n",
      "====> Test Loss: 1312.6320\t Avg Loss: 0.0401\tCorrect: 16074/32698\tPercentage Correct: 49.16\n",
      "Train Epoch: 21\t[2000/117711 (2%)]\tTotal Loss: 3.1097\tAvg Loss: 0.0016\n",
      "Train Epoch: 21\t[4000/117711 (3%)]\tTotal Loss: 5.9569\tAvg Loss: 0.0015\n",
      "Train Epoch: 21\t[6000/117711 (5%)]\tTotal Loss: 8.5084\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[8000/117711 (7%)]\tTotal Loss: 11.3961\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[10000/117711 (8%)]\tTotal Loss: 14.0465\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[12000/117711 (10%)]\tTotal Loss: 16.7236\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[14000/117711 (12%)]\tTotal Loss: 19.4518\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[16000/117711 (14%)]\tTotal Loss: 22.2257\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[18000/117711 (15%)]\tTotal Loss: 25.1025\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[20000/117711 (17%)]\tTotal Loss: 27.9806\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[22000/117711 (19%)]\tTotal Loss: 30.7459\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[24000/117711 (20%)]\tTotal Loss: 33.5025\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[26000/117711 (22%)]\tTotal Loss: 36.0999\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[28000/117711 (24%)]\tTotal Loss: 38.8195\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[30000/117711 (25%)]\tTotal Loss: 41.5208\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[32000/117711 (27%)]\tTotal Loss: 44.3895\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[34000/117711 (29%)]\tTotal Loss: 46.9900\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[36000/117711 (31%)]\tTotal Loss: 49.8991\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[38000/117711 (32%)]\tTotal Loss: 52.5951\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[40000/117711 (34%)]\tTotal Loss: 55.1672\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[42000/117711 (36%)]\tTotal Loss: 57.7908\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[44000/117711 (37%)]\tTotal Loss: 60.8123\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[46000/117711 (39%)]\tTotal Loss: 63.6400\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[48000/117711 (41%)]\tTotal Loss: 66.3859\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[50000/117711 (42%)]\tTotal Loss: 69.0997\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[52000/117711 (44%)]\tTotal Loss: 72.2906\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[54000/117711 (46%)]\tTotal Loss: 75.1132\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[56000/117711 (48%)]\tTotal Loss: 78.1767\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[58000/117711 (49%)]\tTotal Loss: 81.0601\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[60000/117711 (51%)]\tTotal Loss: 83.9735\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[62000/117711 (53%)]\tTotal Loss: 86.9923\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[64000/117711 (54%)]\tTotal Loss: 89.9023\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[66000/117711 (56%)]\tTotal Loss: 92.6895\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[68000/117711 (58%)]\tTotal Loss: 96.2183\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[70000/117711 (59%)]\tTotal Loss: 99.3746\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[72000/117711 (61%)]\tTotal Loss: 102.1471\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[74000/117711 (63%)]\tTotal Loss: 105.3142\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[76000/117711 (65%)]\tTotal Loss: 108.3773\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[78000/117711 (66%)]\tTotal Loss: 111.3800\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[80000/117711 (68%)]\tTotal Loss: 114.3892\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[82000/117711 (70%)]\tTotal Loss: 117.5446\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[84000/117711 (71%)]\tTotal Loss: 120.6415\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[86000/117711 (73%)]\tTotal Loss: 123.7151\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[88000/117711 (75%)]\tTotal Loss: 127.0731\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[90000/117711 (76%)]\tTotal Loss: 130.3744\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[92000/117711 (78%)]\tTotal Loss: 133.2064\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[94000/117711 (80%)]\tTotal Loss: 136.0339\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[96000/117711 (81%)]\tTotal Loss: 138.9100\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[98000/117711 (83%)]\tTotal Loss: 142.0202\tAvg Loss: 0.0014\n",
      "Train Epoch: 21\t[100000/117711 (85%)]\tTotal Loss: 145.0455\tAvg Loss: 0.0015\n",
      "Train Epoch: 21\t[102000/117711 (87%)]\tTotal Loss: 148.0044\tAvg Loss: 0.0015\n",
      "Train Epoch: 21\t[104000/117711 (88%)]\tTotal Loss: 150.8886\tAvg Loss: 0.0015\n",
      "Train Epoch: 21\t[106000/117711 (90%)]\tTotal Loss: 153.9511\tAvg Loss: 0.0015\n",
      "Train Epoch: 21\t[108000/117711 (92%)]\tTotal Loss: 157.0083\tAvg Loss: 0.0015\n",
      "Train Epoch: 21\t[110000/117711 (93%)]\tTotal Loss: 159.8873\tAvg Loss: 0.0015\n",
      "Train Epoch: 21\t[112000/117711 (95%)]\tTotal Loss: 162.8738\tAvg Loss: 0.0015\n",
      "Train Epoch: 21\t[114000/117711 (97%)]\tTotal Loss: 165.8479\tAvg Loss: 0.0015\n",
      "Train Epoch: 21\t[116000/117711 (98%)]\tTotal Loss: 168.7363\tAvg Loss: 0.0015\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e09882d584ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     train_loss, train_correct, train_results = trainer.train_fx_net(\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfxnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_fxnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Marco/Documents/GOOGLE DRIVE/PHD/REPOS/gfx_classifier/src/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain_fx_net\u001b[0;34m(model, optimizer, train_loader, train_sampler, epoch, loss_function, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# pass batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m# loss = F.cross_entropy(preds, labels) # calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Marco/Documents/GOOGLE DRIVE/PHD/REPOS/gfx_classifier/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Marco/Documents/GOOGLE DRIVE/PHD/REPOS/gfx_classifier/src/model/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# (4) hidden dense layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m29\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchNorm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# t = F.relu(t)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Marco/Documents/GOOGLE DRIVE/PHD/REPOS/gfx_classifier/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Marco/Documents/GOOGLE DRIVE/PHD/REPOS/gfx_classifier/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Marco/Documents/GOOGLE DRIVE/PHD/REPOS/gfx_classifier/venv/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TRAIN and TEST FxNet OVER MULTIPLE EPOCHS\n",
    "train_set_size = len(split.train_sampler)\n",
    "val_set_size = len(split.val_sampler)\n",
    "test_set_size = len(split.test_sampler)\n",
    "\n",
    "all_train_losses, all_val_losses, all_test_losses = [],[],[]\n",
    "all_train_correct, all_val_correct, all_test_correct = [],[],[]\n",
    "all_train_results, all_val_results, all_test_results = [],[],[]\n",
    "\n",
    "best_val_correct = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(50):\n",
    "    train_loss, train_correct, train_results = trainer.train_fx_net(\n",
    "        model=fxnet,\n",
    "        optimizer=optimizer_fxnet, \n",
    "        train_loader=train_loader, \n",
    "        train_sampler=split.train_sampler, \n",
    "        epoch=epoch, \n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    val_loss, val_correct, val_results = trainer.val_fx_net(\n",
    "        model=fxnet, \n",
    "        val_loader=val_loader, \n",
    "        val_sampler=split.val_sampler, \n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    test_loss, test_correct, test_results = trainer.test_fx_net(\n",
    "        model=fxnet, \n",
    "        test_loader=test_loader, \n",
    "        test_sampler=split.test_sampler, \n",
    "        device=device\n",
    "    )\n",
    "    # save models\n",
    "    if val_correct > best_val_correct:\n",
    "        best_val_correct = val_correct\n",
    "        torch.save(fxnet, '%s/%s' % (models_folder, model_name))\n",
    "        print('--- saved best model ---')\n",
    "        \n",
    "    # append results\n",
    "    all_train_losses.append(train_loss)\n",
    "    all_val_losses.append(val_loss)\n",
    "    all_test_losses.append(test_loss)\n",
    "    \n",
    "    all_train_correct.append(train_correct)\n",
    "    all_val_correct.append(val_correct)\n",
    "    all_test_correct.append(test_correct)\n",
    "    \n",
    "    all_train_results.append(train_results)\n",
    "    all_val_results.append(val_results)\n",
    "    all_test_results.append(test_results)\n",
    "\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy:  91.10703332738656\nEpoch:  47\n\nAccuracy:  90.54209037388179\nEpoch:  39\n\nAccuracy:  90.38779130222032\nEpoch:  42\n\n"
    }
   ],
   "source": [
    "# BEST RESULTS\n",
    "print('Accuracy: ', 100 * max(all_train_correct) / train_set_size)\n",
    "print('Epoch: ', np.argmax(all_train_correct))\n",
    "print()\n",
    "print('Accuracy: ', 100 * max(all_val_correct) / val_set_size)\n",
    "print('Epoch: ', np.argmax(all_val_correct))\n",
    "print()\n",
    "print('Accuracy: ', 100 * max(all_test_correct) / test_set_size)\n",
    "print('Epoch: ', np.argmax(all_test_correct))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE RESULTS\n",
    "all_train_losses_npy = np.array(all_train_losses)\n",
    "all_train_correct_npy = np.array(all_train_correct)\n",
    "all_train_results_npy = np.array(all_train_results)\n",
    "\n",
    "all_val_losses_npy = np.array(all_val_losses)\n",
    "all_val_correct_npy = np.array(all_val_correct)\n",
    "all_val_results_npy = np.array(all_val_results)\n",
    "\n",
    "all_test_losses_npy = np.array(all_test_losses)\n",
    "all_test_correct_npy = np.array(all_test_correct)\n",
    "all_test_results_npy = np.array(all_test_results)\n",
    "\n",
    "fx_labels_npy = np.array(list(dataset.fx_to_label.keys()))\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, model_name, 'all_train_losses')), arr=all_train_losses_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, model_name, 'all_train_correct')), arr=all_train_correct_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, model_name, 'all_train_results')), arr=all_train_results_npy)\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, model_name, 'all_val_losses')), arr=all_val_losses_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, model_name, 'all_val_correct')), arr=all_val_correct_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, model_name, 'all_val_results')), arr=all_val_results_npy)\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, model_name, 'all_test_losses')), arr=all_test_losses_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, model_name, 'all_test_correct')), arr=all_test_correct_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, model_name, 'all_test_results')), arr=all_test_results_npy)\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, model_name, 'fx_labels')), arr=fx_labels_npy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('venv')",
   "display_name": "Python 3.8.5 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "a7a805fa6ca9da60fb7b6b6395736daa5b09e73fa3d86545b482a0c8fc26d334"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}