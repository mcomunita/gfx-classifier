{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dataset.dataset as dataset\n",
    "import datasplit.datasplit as datasplit\n",
    "import model.models as models\n",
    "import trainer.trainer as trainer\n",
    "import utils.utils as utils\n",
    "\n",
    "torch.cuda.device_count()\n",
    "\n",
    "cuda0 = torch.device('cuda:0')\n",
    "cuda1 = torch.device('cuda:1')\n",
    "cuda2 = torch.device('cuda:2')\n",
    "cuda3 = torch.device('cuda:3')\n",
    "\n",
    "device = torch.device(cuda0 if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "# dataset\n",
    "root = '/Volumes/Macintosh HD/DATASETS/GUITAR-FX/Mono_Discrete'\n",
    "excl_folders = ['MT2']\n",
    "spectra_folder= 'mel_22050_1024_512'\n",
    "proc_settings_csv = 'proc_settings.csv'\n",
    "max_num_settings=3\n",
    "\n",
    "dataset = dataset.FxDataset(root=root,\n",
    "                            excl_folders=excl_folders, \n",
    "                            spectra_folder=spectra_folder, \n",
    "                            processed_settings_csv=proc_settings_csv,\n",
    "                            max_num_settings=max_num_settings,\n",
    "                            transform=transform)\n",
    "dataset.init_dataset()\n",
    "# dataset.generate_mel()\n",
    "\n",
    "# split\n",
    "split = datasplit.DataSplit(dataset, shuffle=True)\n",
    "\n",
    "# loaders\n",
    "train_loader, val_loader, test_loader = split.get_split(batch_size=100)\n",
    "\n",
    "print('dataset size: ', len(dataset))\n",
    "print('train set size: ', len(split.train_sampler))\n",
    "print('val set size: ', len(split.val_sampler))\n",
    "print('test set size: ', len(split.test_sampler))\n",
    "dataset.fx_to_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN FxNET and SetNetCond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "fxnet = models.FxNet(n_classes=dataset.num_fx).to(device)\n",
    "# optimizer\n",
    "optimizer_fxnet = optim.Adam(fxnet.parameters(), lr=0.001)\n",
    "# loss function\n",
    "loss_func_fxnet = nn.CrossEntropyLoss()\n",
    "\n",
    "# model\n",
    "setnet = models.SettingsNetCond(n_settings= dataset.max_num_settings,\n",
    "                                mel_shape=dataset.mel_shape, \n",
    "                                num_embeddings=dataset.num_fx, \n",
    "                                embedding_dim=50)\n",
    "# optimizer\n",
    "optimizer_setnet = optim.Adam(setnet.parameters(), lr=0.001)\n",
    "# loss function\n",
    "loss_func_setnet = nn.MSELoss(reduction='mean')\n",
    "\n",
    "print(fxnet)\n",
    "print(setnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE\n",
    "models_folder = '../../saved/models'\n",
    "model_name_fx = '20201001_fxnet_mono_disc_best'\n",
    "model_name_set = '20201001_setnetcond_mono_disc_best'\n",
    "results_folder = '../../saved_results'\n",
    "results_subfolder = '20201001_fxnet_and_setnetcond_mono_disc_best'"
   ]
  },
  {
   "source": [
    "# TRAIN and TEST FxNet and SettingsNetCond OVER MULTIPLE EPOCHS\n",
    "train_set_size = len(split.train_sampler)\n",
    "val_set_size = len(split.val_sampler)\n",
    "test_set_size = len(split.test_sampler)\n",
    "\n",
    "all_train_losses, all_val_losses, all_test_losses = [],[],[]\n",
    "all_train_correct, all_val_correct, all_test_correct = [],[],[]\n",
    "all_train_results, all_val_results, all_test_results = [],[],[]\n",
    "\n",
    "best_val_correct = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(50):\n",
    "    train_loss, train_correct, train_results = trainer.train_cond_nets(\n",
    "        model_fx=fxnet, \n",
    "        model_set=setnet,\n",
    "        optimizer_fx=optimizer_fxnet, \n",
    "        optimizer_set=optimizer_setnet, \n",
    "        train_loader=train_loader, \n",
    "        train_sampler=split.train_sampler, \n",
    "        epoch=epoch,\n",
    "        loss_function_fx=loss_func_fxnet,\n",
    "        loss_function_set=loss_func_setnet, \n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    val_loss, val_correct, val_results = trainer.val_cond_nets(\n",
    "        model_fx=fxnet, \n",
    "        model_set=setnet, \n",
    "        val_loader=val_loader, \n",
    "        val_sampler=split.val_sampler,\n",
    "        loss_function_fx=loss_func_fxnet, \n",
    "        loss_function_set=loss_func_setnet, \n",
    "        device='cpu'\n",
    "    )\n",
    "    \n",
    "    test_loss, test_correct, test_results = trainer.test_cond_nets(\n",
    "        model_fx=fxnet, \n",
    "        model_set=setnet, \n",
    "        test_loader=test_loader, \n",
    "        test_sampler=split.test_sampler,\n",
    "        loss_function_fx=loss_func_fxnet, \n",
    "        loss_function_set=loss_func_setnet, \n",
    "        device='cpu'\n",
    "    )\n",
    "    # save model\n",
    "    if val_correct > best_val_correct:\n",
    "        best_val_correct = val_correct\n",
    "        torch.save(fxnet, '%s/%s' % (models_folder, model_name_fx))\n",
    "        torch.save(setnet, '%s/%s' % (models_folder, model_name_set))\n",
    "        print('\\n=== saved best model ===\\n')\n",
    "\n",
    "    # append results\n",
    "    all_train_losses.append(train_loss)\n",
    "    all_val_losses.append(val_loss)\n",
    "    all_test_losses.append(test_loss)\n",
    "    \n",
    "    all_train_correct.append(train_correct)\n",
    "    all_val_correct.append(val_correct)\n",
    "    all_test_correct.append(test_correct)\n",
    "    \n",
    "    all_train_results.append(train_results)\n",
    "    all_val_results.append(val_results)\n",
    "    all_test_results.append(test_results)\n",
    "\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BEST RESULTS\n",
    "print('Accuracy: ', 100 * max(all_train_correct) / train_set_size)\n",
    "print('Epoch: ', np.argmax(all_train_correct))\n",
    "print()\n",
    "print('Accuracy: ', 100 * max(all_val_correct) / val_set_size)\n",
    "print('Epoch: ', np.argmax(all_val_correct))\n",
    "print()\n",
    "print('Accuracy: ', 100 * max(all_test_correct) / test_set_size)\n",
    "print('Epoch: ', np.argmax(all_test_correct))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE RESULTS - all losses, all correct, best results\n",
    "all_train_losses_npy = np.array(all_train_losses)\n",
    "all_train_correct_npy = np.array(all_train_correct)\n",
    "best_train_results_npy = np.array(all_train_results[40])\n",
    "\n",
    "all_val_losses_npy = np.array(all_val_losses)\n",
    "all_val_correct_npy = np.array(all_val_correct)\n",
    "best_val_results_npy = np.array(all_val_results[40])\n",
    "\n",
    "all_test_losses_npy = np.array(all_test_losses)\n",
    "all_test_correct_npy = np.array(all_test_correct)\n",
    "best_test_results_npy = np.array(all_test_results[40])\n",
    "\n",
    "fx_labels_npy = np.array(list(dataset.fx_to_label.keys()))\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_train_losses_fx')), arr=all_train_losses_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_train_correct_fx')), arr=all_train_correct_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'best_train_results_fx')), arr=best_train_results_npy)\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_val_losses_fx')), arr=all_val_losses_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_val_correct_fx')), arr=all_val_correct_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'best_val_results_fx')), arr=best_val_results_npy)\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_test_losses_fx')), arr=all_test_losses_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_test_correct_fx')), arr=all_test_correct_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'best_test_results_fx')), arr=best_test_results_npy)\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'fx_labels')), arr=fx_labels_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('venv')",
   "display_name": "Python 3.8.5 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "a7a805fa6ca9da60fb7b6b6395736daa5b09e73fa3d86545b482a0c8fc26d334"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}